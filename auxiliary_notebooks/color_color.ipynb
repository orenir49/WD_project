{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from astropy import table\n",
    "from astroquery.gaia import Gaia\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import scoreatpercentile\n",
    "from scipy.interpolate import LinearNDInterpolator, NearestNDInterpolator, RBFInterpolator\n",
    "import stam\n",
    "from tqdm import tqdm\n",
    "import WD_models\n",
    "from os import path\n",
    "import extinction\n",
    "from astropy.constants import R_sun, G, M_sun\n",
    "import astropy.units as u\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "# clusters = Table.read('../data/hunt_clusters/clusters.csv')\n",
    "# members = Table.read('../data/hunt_clusters/members.csv')\n",
    "sources = Table.read('../table_C.fits', format='fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from astroquery.vizier import Vizier\n",
    "# clstrs = Vizier(catalog='J/MNRAS/504/356',columns=['Cluster','N','logage','e_logage','[Fe/H]','e_[Fe/H]','Av','e_Av','FileName'],row_limit=-1).query_constraints()[0]\n",
    "\n",
    "# clstrs.rename_columns(clstrs.colnames,['Cluster','N','logage','e_logage','Fe/H','e_Fe/H','Av','e_Av','FileName'])\n",
    "# # sources = Table.read('../table_extra.fits')\n",
    "# sources['idx'] = np.full(len(sources),'---',dtype=object)\n",
    "\n",
    "# cut = (sources['nss_solution_type'] == 'Orbital') | (sources['nss_solution_type'] == 'AstroSpectroSB1')\n",
    "# sources = sources[cut]\n",
    "\n",
    "# nms = np.unique(sources['cluster'])\n",
    "# for n in nms:\n",
    "#     for i, s in enumerate(sources[sources['cluster'] == n]):\n",
    "#         j = np.where(sources['source_id'] == s['source_id'])[0][0]\n",
    "#         tbl[j]['idx'] = n+'_'+str(i)\n",
    "\n",
    "# sources['idx'] = sources['idx'].astype(str)\n",
    "# sources['age'] = np.full(len(sources),np.nan)\n",
    "# sources['[Fe/H]'] = np.full(len(sources),np.nan)\n",
    "# sources['Av'] = np.full(len(sources),np.nan)\n",
    "\n",
    "# for j in range(len(sources)):\n",
    "#     if sources[j]['cluster'] == 'Hyades':\n",
    "#         sources[j]['age'] = 680\n",
    "#         sources[j]['[Fe/H]'] = 0.14\n",
    "#         sources[j]['Av'] = 0.01 * 3.1\n",
    "#     if sources[j]['cluster'] == 'IC_2602':\n",
    "#         sources[j]['age'] = 60\n",
    "#         sources[j]['[Fe/H]'] = -0.02\n",
    "#         sources[j]['Av'] = 0.05 * 3.1\n",
    "#     if sources[j]['cluster'] == 'NGC_2287':\n",
    "#         sources[j]['age'] = 200\n",
    "#         sources[j]['[Fe/H]'] = -0.11\n",
    "#         sources[j]['Av'] = 0.03 * 3.1\n",
    "#     if sources[j]['cluster'] == 'NGC_2547':\n",
    "#         sources[j]['mh'] = 60\n",
    "#         sources[j]['[Fe/H]'] = 0.01\n",
    "#         sources[j]['Av'] = 0.06 * 3.1\n",
    "\n",
    "# for j in range(len(sources)):\n",
    "#     clstr = sources[j]['cluster']\n",
    "#     if clstr in clstrs['cluster']:\n",
    "#         i = np.where(clstrs['cluster'] == clstr)[0][0]\n",
    "#         sources[j]['age'] = clstrs[i]['age']\n",
    "#         sources[j]['[Fe/H]'] = clstrs[i]['Fe_H']\n",
    "#         sources[j]['Av'] = clstrs[i]['ebv'] * 3.1\n",
    "    \n",
    "# sources.sort('idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARSEC functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "PARSEC_path = '../OCFit/gaiaDR2/grids/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "\n",
    "\n",
    "def choose_model(mh):\n",
    "    if (-0.6 <= mh) and (mh <= 0.05):\n",
    "        PARSEC_path = '../data/PARSECv2.0/w_i=0.6/'\n",
    "        models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "    else:\n",
    "        PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "        models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "    return PARSEC_path,models\n",
    "\n",
    "def get_tracks(mh,age):\n",
    "    \n",
    "    color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation    \n",
    "    if PARSEC_path == '../data/PARSECv2.0/w_i=0.6/':\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP_i45\", \"G_RP_i45\", \"G_i45\" ## with rotation\n",
    "    age_res = np.min(abs(10**np.unique(models['logAge'].data) * 1e-9 - age * 1e-3)) * 1.05 + 1e-3\n",
    "    mh_res = np.min(abs(np.unique(models['MH'].data) - mh)) + 0.005\n",
    "   \n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 5  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 30  # [Msun]\n",
    "    tracks = stam.gentracks.get_isotrack(models, [age * 1e-3, mh], params=(\"age\", \"mh\"), return_table=True,\n",
    "                                    age_res=age_res, mass_min=mass_min, mass_max=mass_max, mh_res = mh_res,\n",
    "                                    stage=None, stage_min=stage_min, stage_max=stage_max, sort_by=\"age\", color_filter1=color_fil_1, color_filter2=color_fil_2,\n",
    "                mag_filter=mag_fil)\n",
    "    return tracks\n",
    "\n",
    "def get_track_idx(mh,age):\n",
    "    color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation    \n",
    "    age_res = np.min(abs(10**np.unique(models['logAge'].data) * 1e-9 - age * 1e-3)) * 1.05\n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 5  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 8  # [Msun]\n",
    "    track_idx = stam.gentracks.get_isotrack(models, [age * 1e-3, mh], params=(\"age\", \"mh\"), return_idx=True,\n",
    "                                    age_res=age_res, mass_min=mass_min, mass_max=mass_max, mh_res = 0.025,\n",
    "                                    stage=None, stage_min=stage_min, stage_max=stage_max, sort_by=\"age\", color_filter1=color_fil_1, color_filter2=color_fil_2,\n",
    "                mag_filter=mag_fil)   \n",
    "    return track_idx\n",
    "\n",
    "def get_age_mh_grid():\n",
    "    age = 10**np.unique(models['logAge'].data) * 1e-6\n",
    "    mh = np.unique(models['MH'].data)\n",
    "    age,mh = np.meshgrid(age,mh)\n",
    "    return age,mh\n",
    "\n",
    "\n",
    "# c = (models['label'] <= 5) & (models['Mini']<=8)\n",
    "# p1 = models[c]['Mass']\n",
    "# p2 = models[c]['logAge']\n",
    "# p3 = models[c]['MH']\n",
    "# pdep1 = models[c]['G_BPmag'] - models[c]['G_RPmag']\n",
    "# pdep2 = models[c]['Gmag']\n",
    "\n",
    "# mass_to_mag = LinearNDInterpolator(np.vstack(list(zip(p1,p2,p3))), pdep2)\n",
    "# mass_to_color = LinearNDInterpolator(np.vstack(list(zip(p1,p2,p3))), pdep1)\n",
    "\n",
    "# def get_isochrone(mh,age):\n",
    "#     mass_arr = get_tracks(mh,age)['mass']\n",
    "#     gmag = mass_to_mag(mass_arr,np.log10(age*1e6),mh)\n",
    "#     bprp = mass_to_color(mass_arr,np.log10(age*1e6),mh)\n",
    "#     return Table([mass_arr,bprp,gmag],names=['mass','bp_rp','mg'])\n",
    "\n",
    "# _ = get_isochrone(0,101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster parameters and primary mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mass interpolations, cluster cmd plots\n",
    "\n",
    "def tracks2grid(tracks, xparam = \"bp_rp\", yparam = \"mg\", xstep=0.05, ystep=0.05):\n",
    "    # auxiliary to interp_mass_realization\n",
    "    xmin = np.min(np.around(tracks[xparam], -int(np.round(np.log10(xstep)))))\n",
    "    xmax = np.max(np.around(tracks[xparam], -int(np.round(np.log10(xstep)))))\n",
    "    ymin = np.min(np.around(tracks[yparam], -int(np.round(np.log10(ystep)))))\n",
    "    ymax = np.max(np.around(tracks[yparam], -int(np.round(np.log10(ystep)))))\n",
    "    x, y = np.meshgrid(np.arange(xmin, xmax, xstep), np.arange(ymin, ymax, ystep))\n",
    "            \n",
    "    return x, y, xmin, xmax, ymin, ymax\n",
    "\n",
    "def interp_mass_realization(age,mh,av,bp_rp,mg):\n",
    "    # For a single realization of cluster and source parameters, interpolate the mass\n",
    "\n",
    "    # get the isotrack for this realization of the cluster parameters\n",
    "    tracks = get_tracks(mh,age)\n",
    "    x = np.array(tracks[\"bp_rp\"])\n",
    "    y = np.array(tracks[\"mg\"])\n",
    "    z = np.array(tracks[\"mass\"])\n",
    "    # Add small noise to the isochrone (to avoid singularity problems)\n",
    "    x = x + np.random.normal(0, 0.0001, len(x))\n",
    "    y = y + np.random.normal(0, 0.0001, len(y))\n",
    "    z = z + np.random.normal(0, 0.0001, len(z))\n",
    "    # apply extinction to the isochrone\n",
    "    ag, e_bprp = extinction.get_AG_EBPRP(av,x)\n",
    "    y = y + ag\n",
    "    x = x + e_bprp\n",
    "    # interpolate this instance of color and magnitude along the isochrone\n",
    "    xstep, ystep = 0.05, 0.05\n",
    "    grid_x, grid_y, xmin, xmax, ymin, ymax = tracks2grid(tracks, xstep=xstep, ystep=ystep)    \n",
    "    fun_type = \"linear\"\n",
    "    interp = RBFInterpolator(np.array([x, y]).T, z, kernel=fun_type)\n",
    "    grid = np.array([grid_x, grid_y])\n",
    "    grid_flat = grid.reshape(2, -1).T\n",
    "    grid_z = interp(grid_flat).reshape(grid_x.shape)\n",
    "    mass = interp(np.array([[bp_rp, mg]]))[0]\n",
    "    return mass\n",
    "\n",
    "def photometric_mass(idx,save=False,plot=False,n_realizations=100):        \n",
    "    # Run monte carlo simulation to estimate primary pass and error\n",
    "    j = np.where(sources['idx'] == idx)[0][0]\n",
    "    age, e_age = sources[j]['age'], sources[j]['e_age']\n",
    "    mh, e_mh = sources[j]['[Fe/H]'], sources[j]['e_[Fe/H]']\n",
    "    av, e_av = sources[j]['Av'], sources[j]['e_Av']\n",
    "    mg = sources[j]['mg']\n",
    "    bp_rp = sources[j]['bp_rp']\n",
    "\n",
    "    # estimate photometric errors\n",
    "    e_g= 2.5*np.log(10)*sources[j]['phot_g_mean_flux_error']/sources[j]['phot_g_mean_flux']\n",
    "    e_mg = np.sqrt(e_g**2 + (2.17 / sources[j]['parallax_over_error'])**2)\n",
    "    e_bp = 2.5 * np.log(10) * sources[j]['phot_bp_mean_flux_error'] / sources[j]['phot_bp_mean_flux']\n",
    "    e_rp = 2.5 * np.log(10) * sources[j]['phot_rp_mean_flux_error'] / sources[j]['phot_rp_mean_flux']\n",
    "    e_bp_rp = np.sqrt(e_bp**2 + e_rp**2)\n",
    "\n",
    "    # run monte carlo simulation\n",
    "    age_vec = np.random.normal(age,e_age,n_realizations)\n",
    "    mh_vec = np.random.normal(mh,e_mh,n_realizations)\n",
    "    av_vec = np.random.normal(av,e_av,n_realizations)\n",
    "    bp_rp_vec = np.random.normal(bp_rp,e_bp_rp,n_realizations)\n",
    "    mg_vec = np.random.normal(mg,e_mg,n_realizations)\n",
    "    mass_vec = np.zeros(n_realizations)\n",
    "    for i in range(n_realizations):\n",
    "        try:\n",
    "            mass_vec[i] = interp_mass_realization(age_vec[i],mh_vec[i],av_vec[i],bp_rp_vec[i],mg_vec[i])\n",
    "        except:\n",
    "            mass_vec[i] = np.nan\n",
    "    m1 = np.nanmean(mass_vec)\n",
    "    m1_err = np.nanstd(mass_vec)\n",
    "    plot_mass_interp(age,mh,av,bp_rp,mg,m1,m1_err,idx,sources[j]['cluster'],save,plot)\n",
    "    return m1,m1_err\n",
    "\n",
    "def get_cluster_members(cluster):\n",
    "    # read the cluster member data from our premade files, apply quality cuts\n",
    "\n",
    "    filepath = path.join('..','OCFit','gaiaDR2','data',cluster+'.dat')\n",
    "    obs = np.genfromtxt(filepath,names=True,delimiter=',',dtype=None)\n",
    "    if path.exists(filepath.replace('.dat','_D.dat')):\n",
    "        obsD = np.genfromtxt(filepath.replace('.dat','_D.dat'),names=True,delimiter=',',dtype=None)\n",
    "        obs = np.concatenate((obs,obsD))\n",
    "\n",
    "    mg = obs['Gmag'] - 5 * np.log10(1000/obs['Plx']) + 5\n",
    "    #remove nans para fazer os plots\n",
    "    cond1 = np.isfinite(obs['Gmag'])\n",
    "    cond2 = np.isfinite(obs['BPmag'])\n",
    "    cond3 = np.isfinite(obs['RPmag'])\n",
    "    \n",
    "    cond4 = obs['RFG'] > 50.0\n",
    "    cond5 = obs['RFBP'] > 20.0\n",
    "    cond6 = obs['RFRP'] > 20.0\n",
    "    cond7 = obs['E_BR_RP_'] < 1.3+0.06*(obs['BPRP'])**2\n",
    "    cond8 = obs['E_BR_RP_'] > 1.0+0.015*(obs['BPRP'])**2\n",
    "    cond9 = obs['Nper'] > 8\n",
    "    cond10 = obs['fidelity_v2'] > 0.5\n",
    "    cond11 = (mg < 9) | (obs['BPRP'] > 0)       \n",
    "    ind  = np.where(cond1&cond2&cond3&cond4&cond5&cond6&cond7&cond8&cond9&cond10&cond11)\n",
    "    obs = obs[ind]\n",
    "    obs = Table(obs)\n",
    "    obs = table.unique(obs,keys='source_id')\n",
    "    return obs\n",
    "    \n",
    "def plot_cmd(idx,cluster,age,mh,ebv,save,plot):\n",
    "        memb = get_cluster_members(cluster)\n",
    "        memb['mg'] = memb['Gmag'] - 5 * np.log10(1000/memb['Plx']) + 5\n",
    "\n",
    "        mg = memb['mg']\n",
    "        bp_rp = memb['BPRP']\n",
    "        mg0 = sources[sources['idx']== idx]['mg']\n",
    "        bp_rp0= sources[sources['idx']== idx]['bp_rp']\n",
    "\n",
    "        track = get_tracks(mh,age)\n",
    "        bp_rp_model = np.array(track['bp_rp'])\n",
    "        mg_model = np.array(track['mg'])\n",
    "        ag, e_bprp = extinction.get_AG_EBPRP(3.1*ebv,bp_rp_model)\n",
    "        mg_model = mg_model + ag\n",
    "        bp_rp_model = bp_rp_model + e_bprp\n",
    "\n",
    "        fig,ax = plt.subplots(dpi=300)\n",
    "        ax.scatter(bp_rp,mg,s=5,c='r',label='Cluster members',zorder=5)\n",
    "        ax.scatter(bp_rp0,mg0,s=25,c='g',label='Candidate',zorder = 10)\n",
    "        ax.plot(bp_rp_model,mg_model, 'ko', markersize=1,label=f'PARSEC age={int(age)} Myr, [Fe/H]={mh:.2f}, E(B-V)={ebv:.3f}')\n",
    "        ax.set_xlabel('BP-RP')\n",
    "        ax.set_ylabel('G')\n",
    "        ax.invert_yaxis()\n",
    "        ax.legend(loc='lower left',frameon=False)\n",
    "        ax.set_title('Candidate '+ str(idx) + ' in cluster ' + cluster)\n",
    "        if save:\n",
    "            fig.savefig(f'../img/cmd/{idx}_'+cluster+'.png')\n",
    "        if not plot:\n",
    "            plt.close()\n",
    "\n",
    "def plot_mass_interp(age,mh,av,bp_rp,mg,m1,m1_err,idx,clstr,save,plot):\n",
    "    # For the final mass estimate, plot the mass interpolation\n",
    "    tracks = get_tracks(mh,age)\n",
    "    x = np.array(tracks[\"bp_rp\"])\n",
    "    y = np.array(tracks[\"mg\"])\n",
    "    z = np.array(tracks[\"mass\"])\n",
    "    # Add small noise to the isochrone (to avoid singularity problems)\n",
    "    x = x + np.random.normal(0, 0.0001, len(x))\n",
    "    y = y + np.random.normal(0, 0.0001, len(y))\n",
    "    z = z + np.random.normal(0, 0.0001, len(z))\n",
    "    # apply extinction to the isochrone\n",
    "    ag, e_bprp = extinction.get_AG_EBPRP(av,x)\n",
    "    y = y + ag\n",
    "    x = x + e_bprp\n",
    "    # interpolate this instance of color and magnitude along the isochrone\n",
    "    xstep, ystep = 0.05, 0.05\n",
    "    grid_x, grid_y, xmin, xmax, ymin, ymax = tracks2grid(tracks, xstep=xstep, ystep=ystep)    \n",
    "    fun_type = \"linear\"\n",
    "    interp = RBFInterpolator(np.array([x, y]).T, z, kernel=fun_type)\n",
    "    grid = np.array([grid_x, grid_y])\n",
    "    grid_flat = grid.reshape(2, -1).T\n",
    "    grid_z = interp(grid_flat).reshape(grid_x.shape)\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(dpi=300, layout='constrained')\n",
    "    ax.plot(x[z>0.3], y[z>0.3], 'ko', markersize=1,label=f'PARSEC age={int(age)} Myr, [Fe/H]={mh:.2f}, E(B-V)={av/3.1:.3f}')\n",
    "    h = ax.imshow(grid_z, origin=\"lower\", extent=[xmin, xmax, ymin, ymax], cmap='Oranges', aspect='auto')\n",
    "    ax.scatter(bp_rp,mg,s=50,c='b',label=f'Candidate {idx} $M_1$={m1:.2f} $\\pm$ {m1_err:.2f} $M_\\odot$',zorder = 10)\n",
    "    cbar = plt.colorbar(h)\n",
    "    cbar.set_label('Mass [$M_\\odot$]',fontsize = 12)\n",
    "    ax.set_xlabel(r\"$G_\\text{BP}-G_\\text{RP}$\", fontsize=12)\n",
    "    ax.set_ylabel(r\"$G$\", fontsize=12)\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    # ax.set_title(f'Candidate {idx} in cluster {clstr}')\n",
    "    ax.invert_yaxis()\n",
    "    ax.legend(loc='lower left',frameon=False,fontsize=11)\n",
    "    \n",
    "    if save:\n",
    "        fig.savefig(f'../img/mass_interp/{idx}_'+clstr+'.png')\n",
    "    if not plot:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "plot = False\n",
    "save = True\n",
    "sources = Table.read('../table_C.fits')\n",
    "new_sources = sources.copy()\n",
    "m1_col = []\n",
    "m1_err_col = []\n",
    "\n",
    "# fitting all with parsec v1.2S\n",
    "# PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "PARSEC_path = '../OCFit/gaiaDR2/grids/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "# for idx in new_sources['idx']:\n",
    "for idx in sources['idx']:\n",
    "    age = new_sources[new_sources['idx'] == idx]['age'][0]\n",
    "    mh = new_sources[new_sources['idx'] == idx]['[Fe/H]'][0]\n",
    "    ebv = new_sources[new_sources['idx'] == idx]['Av'][0] / 3.1\n",
    "    cluster = new_sources[new_sources['idx'] == idx]['cluster'][0]\n",
    "    if np.isnan(age):\n",
    "        # if unable to fit age, skip the candidate\n",
    "        # new_sources.remove_row(np.where(new_sources['idx'] == idx)[0][0])\n",
    "        m1_col.append(np.nan)\n",
    "        m1_err_col.append(np.nan)\n",
    "    else:\n",
    "        try:\n",
    "            # print(f'Photometric mass for candidate {idx}...')\n",
    "            # m1, m1_err = photometric_mass(idx,save=True,plot=False,n_realizations=100)\n",
    "            m1, m1_err = sources[sources['idx'] == idx]['m1'][0], sources[sources['idx'] == idx]['m1_err'][0]\n",
    "            plot_mass_interp(age,mh,ebv,new_sources[new_sources['idx'] == idx]['bp_rp'],new_sources[new_sources['idx'] == idx]['mg'],m1,m1_err,idx,cluster,save,plot)\n",
    "            m1_col.append(m1)\n",
    "            m1_err_col.append(m1_err)\n",
    "        except:\n",
    "            print(f'Error in photometric mass for candidate {idx}')\n",
    "            m1_col.append(np.nan)\n",
    "            m1_err_col.append(np.nan)\n",
    "        # plot_cmd(idx,cluster,age,mh,ebv,save,plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "new_sources['m1'] = m1_col\n",
    "new_sources['m1_err'] = m1_err_col\n",
    "\n",
    "# new_sources.write('../table_B.fits',overwrite=True)\n",
    "sources = new_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions, gaia passbands\n",
    "\n",
    "# ------------ AMRF limits ----------------\n",
    "from astropy.io import ascii\n",
    "from synphot import SourceSpectrum, ReddeningLaw\n",
    "from synphot.models import BlackBodyNorm1D\n",
    "from synphot.units import convert_flux\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "import json \n",
    "from uncertainties import unumpy as unp, ufloat\n",
    "from uncertainties import correlated_values_norm, correlation_matrix\n",
    "import warnings\n",
    "\n",
    "def blackbody(temperature, wavelength, ebv=None, extinction_model='mwavg'):\n",
    "    bb = SourceSpectrum(BlackBodyNorm1D, temperature=temperature*u.K)  # [photons s^-1 cm^-2 A^-1]\n",
    "    # if ebv is not None:\n",
    "    #     # apply extinction\n",
    "    #     ext = ReddeningLaw.from_extinction_model(extinction_model).extinction_curve(ebv)\n",
    "    #     bb = bb * ext\n",
    "    bb = bb(wavelength)/(const.R_sun / const.kpc) ** 2  # undo synphot normalization (but leave the pi factor from integration over half a sphere)\n",
    "    bb = convert_flux(wavelength, bb, 'flam')  # [flam] = [erg s^-1 cm^-2 A^-1]\n",
    "    bb = bb.to(u.erg/u.s/u.cm**2/u.angstrom)  # express in normal astropy units\n",
    "    return bb\n",
    "\n",
    "\n",
    "def mlogg2radius(m, logg):\n",
    "    g = 10**logg*u.cm/u.s**2\n",
    "    r = np.sqrt(const.G*m/g)\n",
    "    return r.to(u.Rsun).value\n",
    "\n",
    "\n",
    "def calc_synth_phot(wavelength, flux, bandpass):\n",
    "    dlambda = np.diff(wavelength)\n",
    "    dlambda = np.concatenate([dlambda, np.array([dlambda[-1]])])\n",
    "\n",
    "    # assuming a photon-counting device\n",
    "    phot = np.sum(dlambda*bandpass*wavelength*flux)/np.sum(dlambda*bandpass*wavelength)\n",
    "    \n",
    "    return phot\n",
    "\n",
    "\n",
    "amrf = lambda q, S : q/(1+q)**(2/3)*(1 - S*(1+q)/(q*(1+S)))\n",
    "\n",
    "gaia_passband = ascii.read('../data/other/passband.dat', names=[\"wl\", \"gPb\", \"gPbError\", \"bpPb\", \"bpPbError\", \"rpPb\", \"rpPbError\"])\n",
    "\n",
    "# replace missing values with NaNs\n",
    "for col in gaia_passband.itercols():\n",
    "    col[col == 99.99] = 0\n",
    "    \n",
    "gaia_passband['wl'] *= 10  # [A]\n",
    "\n",
    "# ---------- AMRF -------------------\n",
    "\n",
    "limiting_curves = Table.read('../data/other/AMRF_limiting_curves.fits')\n",
    "# Retrieve the conservative limiting AMRF values for some primary mass\n",
    "# --------------\n",
    "def Atr(m1):\n",
    "    j = np.argmin(np.abs(m1 - limiting_curves['m1'].data))\n",
    "    return limiting_curves['Atr'][j]\n",
    "def Ams(m1):\n",
    "    j = np.argmin(np.abs(m1 - limiting_curves['m1'].data))\n",
    "    return limiting_curves['Ams'][j]\n",
    "\n",
    "# =============================================================================\n",
    "#                Auxil routines to obtain the covariance matrix\n",
    "# =============================================================================\n",
    "\n",
    "# 1) get the list of parameters from the solution type\n",
    "def get_par_list(solution_type=None):\n",
    "    if (solution_type is None) or (solution_type=='Orbital'):\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'eccentricity', 'period', 't_periastron')\n",
    "\n",
    "    elif (solution_type=='OrbitalAlternative') or (solution_type=='OrbitalAlternativeValidated') \\\n",
    "            or (solution_type=='OrbitalTargetedSearch') or (solution_type=='OrbitalTargetedSearchValidated'):\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'period', 'eccentricity', 't_periastron')\n",
    "\n",
    "    elif solution_type=='AstroSpectroSB1':\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'c_thiele_innes', 'h_thiele_innes', 'center_of_mass_velocity',\n",
    "                'eccentricity', 'period', 't_periastron')\n",
    "\n",
    "\n",
    "# 2) Get the order of parameters in the covariance matrix, for a given bit index.\n",
    "def bit_index_map(bit_index):\n",
    "    if bit_index==8191:\n",
    "        return ['ra','dec','parallax','pmra','pmdec','A','B','F','G', 'e','P', 'T']\n",
    "    elif bit_index==8179:\n",
    "        return ['ra','dec','parallax','pmra','pmdec','A','B','F','P', 'T']\n",
    "    elif bit_index==65535:\n",
    "        return ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'A', 'B', 'F', 'G', 'C', 'H', 'gamma','e', 'P', 'T']\n",
    "    elif bit_index==65435:\n",
    "        return ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'A', 'B', 'F', 'H', 'gamma', 'P', 'T']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# 3) Generate the correlation matrix\n",
    "def make_corr_matrix(input_table, pars=None):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    input_table nss_two_body_orbit table.\n",
    "    pars : list\n",
    "            list of parameters for the corresponding solution of the desired\n",
    "              target, in the same order as they appear in the Gaia table.\n",
    "      \"\"\"\n",
    "    if pars is None:\n",
    "        pars = get_par_list()\n",
    "\n",
    "    # read the correlation vector\n",
    "    s1 = input_table['corr_vec'].replace('\\n','')   \n",
    "    s1 = s1.replace(' ',',')\n",
    "    s1 = s1.replace('--','0')\n",
    "    corr_vec = list(json.loads(s1))\n",
    "    # set the number of parameters in the table\n",
    "    n_pars = len(pars)\n",
    "    # define the correlation matrix.\n",
    "    corr_mat = np.ones([n_pars, n_pars], dtype=float)\n",
    "\n",
    "    # Read the matrix (lower triangle)\n",
    "    ind = 0\n",
    "    for i in range(n_pars):\n",
    "        for j in range(i):\n",
    "            corr_mat[j][i] = corr_vec[ind]\n",
    "            corr_mat[i][j] = corr_vec[ind]\n",
    "            ind += 1\n",
    "\n",
    "    return corr_mat\n",
    "\n",
    "\n",
    "# 4) Get the NSS data \n",
    "def get_nss_data(input_table, source_id):\n",
    "\n",
    "    target_idx = np.argwhere(input_table['source_id'] == source_id)[0][0]\n",
    "    pars = get_par_list(input_table['nss_solution_type'][target_idx])\n",
    "    corr_mat = make_corr_matrix(input_table[target_idx], pars=pars)\n",
    "\n",
    "    mu, std = np.zeros(len(pars)), np.zeros(len(pars))\n",
    "    for i, par in enumerate(pars):\n",
    "        try:\n",
    "            mu[i] = input_table[par][target_idx]\n",
    "            std[i] = input_table[par + '_error'][target_idx]\n",
    "        except KeyError:\n",
    "            mu[i], std[i] = np.nan, np.nan\n",
    "\n",
    "    nan_idxs = np.argwhere(np.isnan(corr_mat))\n",
    "    corr_mat[nan_idxs[:, 0], nan_idxs[:, 1]] = 0.0\n",
    "\n",
    "    return mu, std, corr_mat\n",
    "\n",
    "def multivar_sample(mu, sigma, corr, n):\n",
    "    cov = corr*(sigma[:, None] * sigma[None, :])\n",
    "    # l = spla.cholesky(cov)\n",
    "    # z = np.random.normal(size=(n, mu.shape[0]))\n",
    "    # return z.dot(l) + mu\n",
    "    return np.random.multivariate_normal(mu, cov, size=n)\n",
    "\n",
    "# =============================================================================\n",
    "#                      calc parameters.\n",
    "# =============================================================================\n",
    "# Here we calculate the AMRF, qmin, etc, assuming that the mass of the luminous star \n",
    "# is exactly one solar mass. This is just for the red-clump stars...\n",
    "def calc_AMRF(par_in, par_in_errors, corr_matrix, m1, bit_index=8191):\n",
    "    \"\"\"\n",
    "    For the given set of orbital parameters by Gaia, this function calculates\n",
    "    the standard geometrical elements (a, omega, Omega, and i). If the error\n",
    "    estimates and covariance matrix are prodived, the error estimates on the\n",
    "    calculated parameters are returned as well.\n",
    "\n",
    "    Input: thiele_innes: Thiele Innes parameters [A,B,F,G] in milli-arcsec\n",
    "           thiele_innes_errors : Corresponding errors.\n",
    "           corr_matrix : Corresponding  4X4 correlation matrix.\n",
    "\n",
    "  Output: class-III probability via monte carlo\n",
    "    \"\"\"\n",
    "    # Read the coefficients and assign the correlation matrix.\n",
    "    # Create correlated quantities. If the error is nan we assume 1e-6...\n",
    "    par_in_errors[np.isnan(par_in_errors)] = 1e-6\n",
    "    par_list = correlated_values_norm([(par_in[i], par_in_errors[i]) for i in np.arange(len(par_in))], corr_matrix)\n",
    "    key_list = bit_index_map(bit_index)\n",
    "\n",
    "    par = {key_list[i]: par_list[i] for i in np.arange(len(key_list))}\n",
    "    par['mass'] = m1\n",
    "\n",
    "    # Add the G Thiele-Innes parameter if needed.\n",
    "    if (bit_index == 8179) | (bit_index == 65435):\n",
    "        G = -par['A']*par['F']/par['B']\n",
    "    else:\n",
    "        G = par['G']\n",
    "\n",
    "    # This in an intermediate step in the formulae...\n",
    "    p = (par['A'] ** 2 + par['B'] ** 2 + G ** 2 + par['F'] ** 2) / 2.\n",
    "    q = par['A'] * G - par['B'] * par['F']\n",
    "\n",
    "    # Calculate the angular semimajor axis (already in mas)\n",
    "    a_mas = unp.sqrt(p + unp.sqrt(p ** 2 - q ** 2))\n",
    "\n",
    "    # Calculate the inclination and convert from radians to degrees\n",
    "    i_deg = unp.arccos(q / (a_mas ** 2.)) * (180 / np.pi)\n",
    "    \n",
    "    try:\n",
    "        if par.get(\"d\") is not None:\n",
    "            K_kms = 4.74372*unp.sqrt(par['C'] ** 2 + par['H'] ** 2)*(2*np.pi)/(par['P']/ 365.25)/np.sqrt(1-par['e']**2)\n",
    "            acc   = 2*K_kms/par['P']\n",
    "        else:\n",
    "            K_kms = 4.74372*unp.sqrt(par['C'] ** 2 + par['H'] ** 2)*(2*np.pi)/(par['P']/ 365.25)\n",
    "            acc   = K_kms/par['P']/4\n",
    "    except:\n",
    "        K_kms = ufloat(999, 999) \n",
    "        acc   = ufloat(999,999)\n",
    "\n",
    "    # Calculate the AMRF\n",
    "    try:\n",
    "        AMRF = a_mas / par['parallax'] * par['mass'] ** (-1 / 3)  * (par['P']/ 365.25) ** (-2 / 3)\n",
    "\n",
    "        # Calculate AMRF q\n",
    "        y = AMRF ** 3\n",
    "        h = (y/2 + (y**2)/3 + (y**3)/27\n",
    "             + np.sqrt(3)/18*y*unp.sqrt(4*y+27))**(1/3)\n",
    "        q = h + (2*y/3 + (y**2)/9)/h + y/3\n",
    "    except:\n",
    "        AMRF = ufloat(np.nan, np.inf) \n",
    "        q    = ufloat(np.nan, np.inf) \n",
    "        \n",
    "    # Extract expectancy values and standard deviations\n",
    "    pars = np.array([unp.nominal_values(AMRF),\n",
    "                         unp.nominal_values(q),\n",
    "                         unp.nominal_values(a_mas),\n",
    "                         unp.nominal_values(i_deg),\n",
    "                         unp.nominal_values(K_kms),\n",
    "                         unp.nominal_values(acc)])\n",
    "\n",
    "    pars_error = np.array([unp.std_devs(AMRF),\n",
    "                               unp.std_devs(q),\n",
    "                               unp.std_devs(a_mas),\n",
    "                               unp.std_devs(i_deg),\n",
    "                               unp.std_devs(K_kms),\n",
    "                               unp.std_devs(acc)])\n",
    "\n",
    "    return pars, pars_error\n",
    "\n",
    "def class_probs(Atr,Ams,par_in, par_in_errors,\n",
    "                  m1, m1_error, corr_matrix, bit_index=8191, n=1e2, factor=1.0):\n",
    "    \"\"\"\n",
    "    For the given set of orbital parameters by Gaia, this function calculates\n",
    "    the standard geometrical elements (a, omega, Omega, and i). If the error\n",
    "    estimates and covariance matrix are prodived, the error estimates on the\n",
    "    calculated parameters are returned as well.\n",
    "\n",
    "    Input: thiele_innes: Thiele Innes parameters [A,B,F,G] in milli-arcsec\n",
    "           thiele_innes_errors : Corresponding errors.\n",
    "           corr_matrix : Corresponding  4X4 correlation matrix.\n",
    "\n",
    "  Output: physical and geometrical parameters\n",
    "    \"\"\"\n",
    "    r_3 = 0\n",
    "    r_2 = 0\n",
    "    par_in_errors[np.isnan(par_in_errors)] = 1e-6\n",
    "    vecs = multivar_sample(par_in, par_in_errors, corr_matrix, int(n))\n",
    "    key_list = bit_index_map(bit_index)\n",
    "\n",
    "    for vec in vecs:\n",
    "        par = {key_list[i]: vec[i] for i in np.arange(len(key_list))}\n",
    "        par['mass'] = m1_error*np.random.randn() + m1\n",
    "\n",
    "        # Add the G Thiele-Innes parameter if needed.\n",
    "        if (bit_index == 8179) | (bit_index == 65435):\n",
    "            par['G'] = -par['A'] * par['F'] / par['B']\n",
    "\n",
    "        # This in an intermediate step in the formulae...\n",
    "        p = (par['A'] ** 2 + par['B'] ** 2 + par['G'] ** 2 + par['F'] ** 2) / 2.\n",
    "        q = par['A'] * par['G'] - par['B'] * par['F']\n",
    "\n",
    "        # Calculate the semimajor axis (already in mas)\n",
    "        a_mas = np.sqrt(p + np.sqrt(p ** 2 - q ** 2))\n",
    "\n",
    "        # Calculate the AMRF\n",
    "        AMRF = a_mas / par['parallax'] * par['mass'] ** (-1 / 3) * (par['P']/ 365.25) ** (-2 / 3)\n",
    "\n",
    "        try:\n",
    "            if 0 < par['e'] < 1:\n",
    "                if AMRF > Atr * factor:\n",
    "                    r_3 += 1\n",
    "                elif Ams * factor < AMRF < Atr * factor:\n",
    "                    r_2 += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return (n-r_2-r_3)/n, r_2/n, r_3/n #(no_detections + detections)\n",
    "\n",
    "# =============================================================================\n",
    "#                       Read the data from the NSS table\n",
    "# =============================================================================\n",
    "def add_astrometric_parameters(data):\n",
    "    # Here we only calculate (but don't assign class 3 probabilities!\n",
    "    # We get the data table, arrange the arrays, calculate the astrometric\n",
    "    # coefficients and plug it all back into the table.\n",
    "\n",
    "    # Initialize the arrays\n",
    "    # ---------------------\n",
    "    # We need to calculate the AMRF, mass ratio, angular semi-major axis, orbtial inclination\n",
    "    # and order-of-magnitude acceleration. We also want their uncertainties.\n",
    "    count_good, count_bad = 0, 0\n",
    "    A, q, a_mas, i_deg, K_kms, acc, P1, P2, P3 = np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan), np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan), np.full(len(data), np.nan), np.full(len(data), np.nan) \n",
    "\n",
    "    Ae, qe, a_mase, i_dege, K_kmse, acce = np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                                   np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                                   np.full(len(data), np.nan),  np.full(len(data), np.nan)\n",
    "\n",
    "    # Now go one by one and calculate the AMRF\n",
    "    # ----------------------------------------\n",
    "    for idx in tqdm(range(len(data['source_id']))):\n",
    "        if data[idx]['nss_solution_type'] not in ['Orbital','AstroSpectroSB1']:\n",
    "            continue\n",
    "        # Read the NSS solutin values.\n",
    "        sid = data['source_id'][idx]\n",
    "        mu, std, corr_mat = get_nss_data(data, sid)\n",
    "        m1 = data['m1'][idx]\n",
    "        m1_error = data['m1_err'][idx]\n",
    "        if np.ma.is_masked(m1):\n",
    "            print(idx)\n",
    "            pass\n",
    "        Ams_idx = data['Ams'][idx]\n",
    "        Atr_idx = data['Atr'][idx]\n",
    "        if np.ma.is_masked(Ams_idx) | np.ma.is_masked(Atr_idx):\n",
    "            Ams_idx = Ams(m1)\n",
    "            Atr_idx = Atr(m1)\n",
    "            \n",
    "        vals, stds = calc_AMRF(mu, std, corr_mat, m1, bit_index=data['bit_index'][idx])\n",
    "        p1, p2, p3 = class_probs(data['Atr'][idx],data['Ams'][idx],mu, std, m1, m1_error, corr_mat, bit_index=data['bit_index'][idx], n = 1e4)\n",
    "        try:\n",
    "            A[idx], Ae[idx]  = vals[0], stds[0]\n",
    "            q[idx], qe[idx]  = vals[1], stds[1]\n",
    "            a_mas[idx], a_mase[idx]  = vals[2], stds[2]\n",
    "            i_deg[idx], i_dege[idx]  = vals[3], stds[3]\n",
    "            K_kms[idx], K_kmse[idx]  = vals[4], stds[4]\n",
    "            acc[idx],   acce[idx]    = vals[5], stds[5]\n",
    "            P1[idx], P2[idx], P3[idx] = p1, p2, p3\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Store it all back in the original data structure.\n",
    "    data['AMRF'], data['AMRF_error'] = A, Ae\n",
    "    data['AMRF_q'], data['AMRF_q_error'] = q, qe\n",
    "    data['a_mas'], data['a_mas_error'] = a_mas, a_mase\n",
    "    data['i_deg'], data['i_deg_error'] = i_deg, i_dege\n",
    "    data['K_kms'], data['K_kms_error'] = K_kms, K_kmse\n",
    "    data['acc_kmsd'], data['acc_kmsd_error'] = acc, acce\n",
    "    data['classI_prob'] = P1\n",
    "    data['classII_prob'] = P2\n",
    "    data['classIII_prob'] = P3\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:01<00:00, 22.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calc AMRF limits\n",
    "\n",
    "# sources['Ams'] = np.full(len(sources),np.nan)\n",
    "# sources['Atr'] = np.full(len(sources),np.nan)\n",
    "\n",
    "## calculating for all sources\n",
    "\n",
    "stage_min = 0  # pre-main sequence\n",
    "stage_max = 5  # red giant branch\n",
    "mass_min = 0  # [Msun]\n",
    "mass_max = 8  # [Msun]\n",
    "\n",
    "m2_vec = np.arange(0.1, 10, 0.1)\n",
    "\n",
    "wavelength = gaia_passband['wl'].value  # [A]\n",
    "\n",
    "Gflux1 = np.zeros(len(sources))\n",
    "Gflux2 = np.zeros((len(sources), len(m2_vec)))\n",
    "Ag1 = np.zeros(len(sources))\n",
    "Ag2 = np.zeros((len(sources), len(m2_vec)))\n",
    "q = np.zeros((len(sources), len(m2_vec)))\n",
    "# PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "PARSEC_path = '../OCFit/gaiaDR2/grids/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "for i in tqdm(range(len(sources))):\n",
    "    idx = sources['idx'][i]\n",
    "    # only for candidate 110. for rest, skip\n",
    "    if idx != 110:\n",
    "        continue\n",
    "    if sources[i]['nss_solution_type'] not in ['Orbital','AstroSpectroSB1']:\n",
    "        continue\n",
    "    mh = sources['[Fe/H]'][i]\n",
    "    age = sources['age'][i]\n",
    "    ebv = sources['Av'][i]/3.1\n",
    "    m1 = sources['m1'][i]\n",
    "    \n",
    "    try:\n",
    "        track_idx = get_track_idx(mh,age)[-1]\n",
    "        tracks = models[track_idx].copy()\n",
    "        tracks.sort('Mini')\n",
    "        idx = np.argmin(np.abs(tracks['Mass'] - m1))\n",
    "\n",
    "        teff1 = 10**tracks['logTe'][idx]  # [K]\n",
    "        logg1 = tracks['logg'][idx]\n",
    "        r1 = mlogg2radius(m1*u.Msun, logg1)  # [Rsun]\n",
    "        flux1 = blackbody(teff1, wavelength)*4*np.pi*r1**2\n",
    "        Gflux1[i] = calc_synth_phot(wavelength, flux1, gaia_passband['gPb'].value).value\n",
    "        Ag1[i],_ = extinction.get_AG_EBPRP(3.1*ebv,0,teff1)\n",
    "        q[i, :] = m2_vec/m1  # mass ratio\n",
    "\n",
    "        for j in range(len(m2_vec)):\n",
    "            m2 = m2_vec[j]\n",
    "            idx = np.argmin(np.abs(tracks['Mass'] - m2))\n",
    "            teff2 = 10**tracks['logTe'][idx]  # [K]\n",
    "            logg2 = tracks['logg'][idx]\n",
    "            r2 = mlogg2radius(m2*u.Msun, logg2)  # [Rsun]\n",
    "            flux2 = blackbody(teff2, wavelength, ebv=ebv)*4*np.pi*r2**2\n",
    "            Gflux2[i,j] = calc_synth_phot(wavelength, flux2, gaia_passband['gPb'].value).value\n",
    "            Ag2[i,j],_ = extinction.get_AG_EBPRP(3.1*ebv,0,teff2)\n",
    "\n",
    "        Sms = Gflux2[i,:]/Gflux1[i]*10**(-0.4*(Ag2[i,:]-Ag1[i]))\n",
    "        Ams = amrf(q[i, :], Sms)\n",
    "        valid_idx = Sms < 1\n",
    "        Ams = np.max(Ams[valid_idx]) \n",
    "        sources['Ams'][i] = Ams\n",
    "        Str = 2*Gflux2[i,:]/Gflux1[i]\n",
    "        Atr = amrf(2*q[i, :], Str)\n",
    "        valid_idx = Str < 1\n",
    "        Atr = np.max(Atr[valid_idx])\n",
    "        sources['Atr'][i] = Atr\n",
    "    except:\n",
    "        print(f'i = {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:03<00:00, 11.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calc AMRF and class probabilities\n",
    "new_sources = add_astrometric_parameters(sources)\n",
    "new_sources['m2'] = new_sources['m1'] * new_sources['AMRF_q']\n",
    "new_sources['m2_err'] = ((new_sources['m1_err'] * new_sources['AMRF_q'])**2 + (new_sources['m1'] * new_sources['AMRF_q_error'])**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = new_sources\n",
    "cut1 = sources['significance'] > 158 * sources['period'].data**(-0.5)\n",
    "cut2 = (sources['parallax_over_error'] > 20,000 *sources['period']**(-1))[0]\n",
    "cut3 = sources['eccentricity_error'] < 0.079 * np.log(sources['period'].data) - 0.244\n",
    "\n",
    "cut = cut1 & cut2 & cut3\n",
    "\n",
    "sources = sources[cut]\n",
    "\n",
    "# sources.write('../table_B.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "cut1 = sources['m1'] / sources['m1_err'] > 50\n",
    "cut2 = sources['classI_prob'] < 0.1\n",
    "cut3 = sources['m2'] <= 1.4\n",
    "\n",
    "cut = cut1 & cut2 & cut3\n",
    "\n",
    "sources[cut].write('../table_C.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "tbl = Table.read('../table_C.fits')\n",
    "\n",
    "for i in range(len(tbl)):\n",
    "    idx = tbl['idx'][i]\n",
    "    cluster = tbl['cluster'][i]\n",
    "    # cmd_fig_name = f'../img/cmd/{idx}_{cluster}.png'\n",
    "    # cmd_new_name = f'../img/cmd_tableC/{idx}_{cluster}.png'\n",
    "    # shutil.move(cmd_fig_name, cmd_new_name)\n",
    "    interp_fig_name = f'../img/mass_interp/{idx}_{cluster}.png'\n",
    "    interp_new_name = f'../img/mass_interpC/{idx}_{cluster}.png'\n",
    "    shutil.move(interp_fig_name, interp_new_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating IFMR, Kroupa distributions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_life vs m from evolutionary tracks/M_i from t_cluster, t_cool\n",
    "from os import walk,path\n",
    "\n",
    "def get_zarr(): # metallicities of parsec evol tracks\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = []\n",
    "    for n in filenames:\n",
    "        z = n.split('Y')[0]\n",
    "        z_arr.append(float(z[1:]))\n",
    "    return np.unique(z_arr)\n",
    "\n",
    "def get_mdict(mh): # masses of evol tracks for a given metallicity\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = get_zarr()\n",
    "    z = 0.01524 * 10**mh\n",
    "    z_nearest = z_arr[np.argmin(np.abs(z_arr - z))]\n",
    "    z_str = 'Z'+f'{z_nearest}'\n",
    "\n",
    "    m_arr = []\n",
    "    s_arr = []\n",
    "    for n in filenames:\n",
    "        if z_str in n:\n",
    "            m = n.split('M')[1].removesuffix('.DAT')\n",
    "            if m.endswith('.HB'):\n",
    "                m = m.removesuffix('.HB')\n",
    "            m_arr.append(float(m))\n",
    "            s_arr.append(m)\n",
    "    tbl = Table({'mass':m_arr,'str':s_arr})\n",
    "    # tbl = tbl[tbl['mass'] <= 10]\n",
    "    return tbl\n",
    "\n",
    "def get_marr(mh): # masses of evol tracks for a given metallicity\n",
    "    return np.unique(get_mdict(mh)['mass'])\n",
    "\n",
    "def get_lifetime(mass,mh): # MS lifetime for given mass (>0.8) and metallicity\n",
    "    ## lifetime for m>0.8\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = get_zarr()\n",
    "\n",
    "    z = 0.01524 * 10**mh\n",
    "    z_nearest = z_arr[np.argmin(np.abs(z_arr - z))]\n",
    "    m_dict = get_mdict(mh)\n",
    "    mass_str = m_dict[m_dict['mass'] == mass]['str']\n",
    "    z_str = 'Z'+f'{z_nearest}'\n",
    "\n",
    "    trackpath = ''\n",
    "    for n in filenames:\n",
    "        m1 = n.split('M')[1].removesuffix('.DAT')\n",
    "        if m1.endswith('HB'):\n",
    "            continue\n",
    "        for m2 in mass_str:\n",
    "            if m1 == m2 and z_str in n:\n",
    "                trackpath = path.join(basedir,n)\n",
    "                break\n",
    "\n",
    "    if trackpath == '':\n",
    "        print(f'No track found for '+m2+' '+z_str)\n",
    "\n",
    "    trck = Table(np.genfromtxt(trackpath,names=True,dtype=None))\n",
    "    # return trck[trck['PHASE'] == 6]['AGE'][0] ## end of MS\n",
    "    if len(trck[trck['PHASE'] == 14]['AGE']) == 0:\n",
    "        return trck[trck['PHASE'] == 11]['AGE'][0] ## TRGB\n",
    "    return trck[trck['PHASE'] == 14]['AGE'][0] ## start of AGB\n",
    "\n",
    "def lifetime_vs_mass(mh): # MS lifetime for different masses (>0.8), fixed metallicity\n",
    "    m_arr = get_marr(mh)\n",
    "    m_arr = m_arr[m_arr > 0.8]\n",
    "    t_arr = []\n",
    "    for m in m_arr:\n",
    "        t_arr.append(get_lifetime(m,mh))\n",
    "    return m_arr,t_arr\n",
    "\n",
    "def create_lifetime_vs_mass_tables(): # create csv files for MS lifetime vs mass for different metallicities\n",
    "    z_arr = get_zarr()\n",
    "    mh_arr = np.log10(z_arr/0.01524)\n",
    "\n",
    "    for mh in mh_arr:\n",
    "        m_arr,t_arr = lifetime_vs_mass(mh)\n",
    "        tbl = Table({'mass':m_arr,'lifetime':t_arr})\n",
    "        tbl.write(path.join('..','data','MS_lifetime','parsec_V1.2S',f'lifetime_vs_mass{mh:.2f}.csv'),overwrite=True)\n",
    "\n",
    "    return ''\n",
    "\n",
    "def get_initial_mass(age,mh,phase='AGB'): # from MS lifetime and metallicity, get progenitor mass (invert get_lifetime)\n",
    "    ## age in Myr\n",
    "    ## phase either MSTO (main sequence turnoff) or AGB (start of asymptotic giant branch, helium depletion in core)\n",
    "    ## For a given lifetime, AGB gives larger mass than MSTO (more evolved). As lifetime increases, this difference becomes negligible.\n",
    "    ## returns mass in solar mass\n",
    "    basedir = path.join('..','data','MS_lifetime',phase)\n",
    "    z_arr = get_zarr()\n",
    "    mh_arr = np.log10(z_arr/0.01524)\n",
    "    mh = mh_arr[np.argmin(np.abs(mh_arr - mh))]\n",
    "    filename = f'lifetime_vs_mass{mh:.2f}.csv'   \n",
    "    df = pd.read_csv(path.join(basedir,filename))\n",
    "    df.sort_values('lifetime',inplace=True)\n",
    "    return np.interp(age*1e6,df['lifetime'],df['mass'])\n",
    "    \n",
    "def get_cooling_age(teff,m,core='CO',atm='H'): # WD cooling age for given teff, mass, core, atm\n",
    "    if core =='He':\n",
    "        model = np.genfromtxt('../data/WD_models/He_wd.dat',names=True,dtype=None)\n",
    "    elif core == 'CO':\n",
    "        if atm == 'H':\n",
    "            model = np.genfromtxt('../data/WD_models/CO_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            model = np.genfromtxt('../data/WD_models/CO_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    elif core == 'ONe':\n",
    "        if atm == 'H':\n",
    "            model = np.genfromtxt('../data/WD_models/ONe_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            model = np.genfromtxt('../data/WD_models/ONe_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    # logg = logg_from_MR_relation(teff,m,core,atm)\n",
    "    interp = LinearNDInterpolator(np.array([model['Teff'],model['Mass']]).T,model['Age'])\n",
    "    age = interp([teff,m])[0]\n",
    "    if np.isnan(age):\n",
    "        return np.nan\n",
    "    return age\n",
    "\n",
    "def get_cooling_temp(age,m,core='CO',atm='H'): # WD cooling temp for given age, mass, core, atm\n",
    "    if core =='He':\n",
    "        model = np.genfromtxt('../data/WD_models/He_wd.dat',names=True,dtype=None)\n",
    "    elif core == 'CO':\n",
    "        if atm == 'H':\n",
    "            model = np.genfromtxt('../data/WD_models/CO_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            model = np.genfromtxt('../data/WD_models/CO_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    elif core == 'ONe':\n",
    "        if atm == 'H':\n",
    "            model = np.genfromtxt('../data/WD_models/ONe_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            model = np.genfromtxt('../data/WD_models/ONe_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    interp = LinearNDInterpolator(np.array([model['Age'],model['Mass']]).T,model['Teff'])\n",
    "    teff_init = interp([age,m])[0]\n",
    "    teff_vec = np.linspace(teff_init+10000,teff_init-10000,20)\n",
    "    age_vec = [get_cooling_age(teff,m,core,atm) for teff in teff_vec]\n",
    "    teff = np.interp(age,age_vec,teff_vec)\n",
    "    return teff\n",
    "\n",
    "def logg_from_MR_relation(teff,m,core='CO',atm='H'):\n",
    "    ## teff in K, m in solar masses\n",
    "    ## returns log_g in cm/s^2\n",
    "    if core == 'He':\n",
    "        wd = np.genfromtxt('../data/WD_models/He_wd.dat',names=True,dtype=None)\n",
    "    elif core == 'CO':\n",
    "        if atm == 'H':\n",
    "            wd = np.genfromtxt('../data/WD_models/CO_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            wd = np.genfromtxt('../data/WD_models/CO_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    elif core == 'ONe':\n",
    "        if atm == 'H':\n",
    "            wd = np.genfromtxt('../data/WD_models/ONe_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            wd = np.genfromtxt('../data/WD_models/ONe_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    interp = LinearNDInterpolator(np.array([wd['Teff'],wd['Mass']]).T,wd['log_g'])\n",
    "    logg = interp([teff,m])[0]\n",
    "    return logg\n",
    "\n",
    "def logg_from_agecool_m(age,m,core='CO',atm='H'):\n",
    "    ## teff in K, m in solar masses\n",
    "    ## returns log_g in cm/s^2\n",
    "    if core == 'He':\n",
    "        wd = np.genfromtxt('../data/WD_models/He_wd.dat',names=True,dtype=None)\n",
    "    elif core == 'CO':\n",
    "        if atm == 'H':\n",
    "            wd = np.genfromtxt('../data/WD_models/CO_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            wd = np.genfromtxt('../data/WD_models/CO_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    elif core == 'ONe':\n",
    "        if atm == 'H':\n",
    "            wd = np.genfromtxt('../data/WD_models/ONe_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            wd = np.genfromtxt('../data/WD_models/ONe_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    interp = LinearNDInterpolator(np.array([wd['Age'],wd['Mass']]).T,wd['log_g'])\n",
    "    logg = interp([age,m])[0]\n",
    "    return logg\n",
    "\n",
    "def get_temp_from_mag(m,mag,parallax,av,band='NUV',atm='H'): # for apparent UV mag/WD mass/parallax/av, get WD temp\n",
    "    if band not in ['NUV','FUV']:\n",
    "        print('band must be either NUV or FUV')\n",
    "        return None\n",
    "    if atm == 'H':\n",
    "        model = np.genfromtxt(f'../data/WD_models/CO_DA.dat',names=True,dtype=None)\n",
    "    elif atm == 'He':\n",
    "        model = np.genfromtxt(f'../data/WD_models/CO_DB.dat',names=True,dtype=None)\n",
    "    interp = LinearNDInterpolator(np.array([model['Mass'],model[band]]).T,model['Teff'])\n",
    "    abs_mag = mag - 5*np.log10(1000/parallax) + 5\n",
    "    teff_init = interp([m,abs_mag])[0] # rough temperature for dereddening the observed mag\n",
    "    if np.isnan(teff_init):\n",
    "        interp = NearestNDInterpolator(np.array([model['Mass'],model[band]]).T,model['Teff'])\n",
    "        teff_init = interp([m,abs_mag])[0] # rough temperature for dereddening the observed mag\n",
    "    ANUV,_ = extinction.get_Galex_extinction(av,0,teff_init)\n",
    "    abs_mag = abs_mag - ANUV # dereddened mag\n",
    "    teff = interp([m,abs_mag])[0] # final temperature\n",
    "    if np.isnan(teff):\n",
    "        interp = NearestNDInterpolator(np.array([model['Mass'],model[band]]).T,model['Teff'])\n",
    "        teff = interp([m,abs_mag])[0]\n",
    "    return int(teff)\n",
    "\n",
    "def add_temperature_limits_to_table(tbl): # Use cluster age and observed UV to constrain teff2\n",
    "\n",
    "    tbl['teff2_max'] = np.full(len(tbl),np.nan)\n",
    "    tbl['teff2_min'] = np.full(len(tbl),np.nan)\n",
    "\n",
    "    for idx in tbl['idx']:\n",
    "        j = np.argwhere(tbl['idx'] == idx)[0][0]\n",
    "        age = tbl['age'][j]\n",
    "        av = tbl['Av'][j]\n",
    "        mh = tbl['[Fe/H]'][j]\n",
    "        parallax = tbl['parallax'][j]\n",
    "        m2 = tbl['m2'][j]\n",
    "        nuv_mag = tbl['nuv_mag'][j]\n",
    "        fuv_mag = tbl['fuv_mag'][j]\n",
    "        \n",
    "        if m2<0.45: core = 'He'\n",
    "        elif m2<1.1: core = 'CO'\n",
    "        else: core = 'ONe'\n",
    "\n",
    "        # if UV photometry exists, UV excess can give strict limits on Teff2\n",
    "        # if no UV excess, we can still put upper bound on Teff2: the highest possible Teff2 must provide less than 10% of the observed UV flux, or else there'd be excess\n",
    "        if not np.ma.is_masked(fuv_mag): \n",
    "            tbl[j]['teff2_max'] = get_temp_from_mag(m2,fuv_mag+2.5,parallax,av,band='FUV',atm='H')\n",
    "        elif not np.ma.is_masked(nuv_mag): \n",
    "            tbl[j]['teff2_max'] = get_temp_from_mag(m2,nuv_mag+2.5,parallax,av,band='NUV',atm='H')\n",
    "        tbl[j]['teff2_min'] = get_cooling_temp(age,m2,core,'H')\n",
    "\n",
    "    tbl['teff2'] = np.full(len(tbl),np.nan)\n",
    "    excess = [53,174,175,236,249,281,283]\n",
    "    for idx in excess:\n",
    "        j = np.argwhere(tbl['idx'] == idx)[0][0]\n",
    "        t_best, t_min, t_max = get_fit_results(idx)\n",
    "        tbl[j]['teff2'] = t_best\n",
    "        tbl[j]['teff2_min'] = t_min\n",
    "        tbl[j]['teff2_max'] = t_max\n",
    "\n",
    "def get_fit_results(idx): # get median and 16th, 84th percentiles of teff2 chain\n",
    "    filepath = f'../data/chains/chains_{idx}.csv'\n",
    "    chain = Table.read(filepath)['teff2']\n",
    "    return np.median(chain),np.percentile(chain,16),np.percentile(chain,84)\n",
    "\n",
    "def sample_teff2_posterior(idx,n=1e4,tclstr=None): # sample teff2 from posterior using rejection sampling\n",
    "    filepath = f'../data/chains/chains_{idx}.csv'\n",
    "    chain = Table.read(filepath)['teff2']\n",
    "    counts,bins = np.histogram(chain,bins=100)\n",
    "    tmax = bins[-1]\n",
    "    tmin = bins[0]\n",
    "    teff2 = []\n",
    "    if tclstr is not None:\n",
    "        tmin = np.max([tmin,tclstr])\n",
    "    while len(teff2) < n:\n",
    "        t = np.random.uniform(tmin,tmax)\n",
    "        if np.random.uniform(0,1) < np.interp(t,bins[:-1],counts)/np.max(counts):\n",
    "            teff2.append(t)\n",
    "    return np.array(teff2)\n",
    "\n",
    "def sample_m_init_posterior(tbl,idx,n=1e4): # sample m_init from teff2 posterior, age, mh, m2 \n",
    "    j = np.argwhere(tbl['idx'] == idx)[0][0]\n",
    "    age, e_age = tbl[j]['age'],tbl[j]['e_age']\n",
    "    mh, e_mh = tbl[j]['[Fe/H]'],tbl[j]['e_[Fe/H]']\n",
    "    m2, m2_err = tbl[j]['m2'],tbl[j]['m2_err']\n",
    "\n",
    "    atm = 'H'\n",
    "    if m2<0.45: core = 'He'\n",
    "    elif m2<1.1: core = 'CO'\n",
    "    else: core = 'ONe'\n",
    "\n",
    "    # tclstr = get_cooling_temp(age,m2,core,atm)\n",
    "    teff2_vec = sample_teff2_posterior(idx,n=10*n)\n",
    "    age_vec = []\n",
    "    mh_vec = []\n",
    "    m2_vec = []\n",
    "    t2_vec = []\n",
    "    m_i_vec = []\n",
    "    k = 0\n",
    "    with tqdm(total=int(n)) as pbar:\n",
    "        while (np.count_nonzero(~np.isnan(m_i_vec) & (np.array(m_i_vec) < 8)) < n):\n",
    "            age_vec.append(np.random.normal(age,e_age))\n",
    "            mh_vec.append(np.random.normal(mh,e_mh))\n",
    "            m2_vec.append(np.random.normal(m2,m2_err))\n",
    "\n",
    "            # t_ms_min = get_lifetime(8.0,mh_vec[-1])\n",
    "            # age_wd_max = age_vec[-1] - t_ms_min\n",
    "        \n",
    "            t2_vec.append(np.random.choice(teff2_vec))\n",
    "\n",
    "            age_wd = get_cooling_age(t2_vec[-1],m2_vec[-1],core,atm)\n",
    "            t_ms = age_vec[-1] - age_wd\n",
    "            if t_ms > 0:\n",
    "                m_i = get_initial_mass(t_ms,mh_vec[-1],phase='AGB')\n",
    "                m_i_vec.append(m_i)\n",
    "                if not np.isnan(m_i) and m_i < 8:\n",
    "                    pbar.update(1)\n",
    "            else:\n",
    "                m_i_vec.append(np.nan)\n",
    "    return Table({'m_i':m_i_vec,'age':age_vec,'[Fe/H]':mh_vec,'m2':m2_vec,'teff2':t2_vec})\n",
    "\n",
    "def weight_m_init_posterior(idx,n=1e4): # weight m_init chain using kroupa IMF\n",
    "    filepath = f'../data/chains/mchain_{idx}.csv'\n",
    "    chain_tbl = Table.read(filepath)\n",
    "    m_chain = chain_tbl['m_i']\n",
    "    age_chain = chain_tbl['age']\n",
    "    mh_chain = chain_tbl['[Fe/H]']\n",
    "    m2_chain = chain_tbl['m2']\n",
    "    teff2_chain = chain_tbl['teff2']\n",
    "\n",
    "    cut = ~np.isnan(m_chain) & (m_chain < 8)\n",
    "    m_chain = m_chain[cut]\n",
    "    age_chain = age_chain[cut]\n",
    "    mh_chain = mh_chain[cut]\n",
    "\n",
    "    n = len(m_chain)\n",
    "    m_chain_w, age_chain_w, mh_chain_w, m2_chain_w, teff2_chain_w = [],[],[],[],[]\n",
    "\n",
    "\n",
    "    kroupa = lambda m,m0: (m/m0)**(-2.3) # peak normalized to 1\n",
    "    while len(m_chain_w) < n:\n",
    "        i = np.random.randint(0,n)\n",
    "        m = m_chain[i]\n",
    "        age = age_chain[i]\n",
    "        mh = mh_chain[i]\n",
    "        m2 = m2_chain[i]\n",
    "        teff2 = teff2_chain[i]\n",
    "\n",
    "        m_min = get_initial_mass(age,mh,phase='MSTO') # to define kroupa lower cut-off.\n",
    "        p = np.random.random()\n",
    "        if p < kroupa(m,m_min) and m > m_min and m < 8: # rejection sampling on truncated kroupa IMF\n",
    "            m_chain_w.append(m)\n",
    "            age_chain_w.append(age)\n",
    "            mh_chain_w.append(mh)\n",
    "            m2_chain_w.append(m2)\n",
    "            teff2_chain_w.append(teff2)\n",
    "\n",
    "    return Table({'m_i':m_chain_w,'age':age_chain_w,'[Fe/H]':mh_chain_w,'m2':m2_chain_w,'teff2':teff2_chain_w})\n",
    "\n",
    "def sample_kroupa_uniform(m_min,m_max,n=1e4): # sample m from kroupa IMF with no prior\n",
    "    kroupa = lambda m,m0: (m/m0)**(-2.3) # peak normalized to 1\n",
    "    m_arr = []\n",
    "    while len(m_arr) < n:\n",
    "        m = np.random.uniform(m_min,m_max)\n",
    "        p = np.random.random()\n",
    "        if p < kroupa(m,m_min) and m > m_min and m < m_max: # rejection sampling on truncated kroupa IMF\n",
    "            m_arr.append(m)\n",
    "    return np.array(m_arr)\n",
    "\n",
    "def create_ifmr_tbl(tbl): # create m_i vs. m_f table, with all levels of bounds\n",
    "    ifmr = Table({'idx':tbl['idx'],'source_id':tbl['source_id'],'m1':tbl['m1'],'m2':tbl['m2'], 'm2_err':tbl['m2_err'], 'age':tbl['age'],\n",
    "                  '[Fe/H]':tbl['[Fe/H]'], 'e_[Fe/H]':tbl['e_[Fe/H]'] ,'period':tbl['period'],'period_error':tbl['period_error'],\n",
    "                  'age':tbl['age'], 'e_age':tbl['e_age'], 'eccentricity':tbl['eccentricity'],'eccentricity_error':tbl['eccentricity_error'],\n",
    "                  'm_i_min_abs':np.full(len(tbl),np.nan),'m_i_min1':np.full(len(tbl),np.nan),'m_i_1':np.full(len(tbl),np.nan),'m_i_max1':np.full(len(tbl),np.nan),\n",
    "                  'm_i_min2':np.full(len(tbl),np.nan),'m_i_2':np.full(len(tbl),np.nan),'m_i_max2':np.full(len(tbl),np.nan),\n",
    "                  'm_i_min3':np.full(len(tbl),np.nan),'m_i_3':np.full(len(tbl),np.nan),'m_i_max3':np.full(len(tbl),np.nan)})\n",
    "    # add_temperature_limits_to_table(tbl)\n",
    "\n",
    "    for j in tqdm(range(len(ifmr))):\n",
    "        idx = tbl[j]['idx']\n",
    "        age = tbl[j]['age']\n",
    "        mh = tbl[j]['[Fe/H]']\n",
    "        \n",
    "        # Loose bounds on m_init from kroupa IMF\n",
    "        filepath = f'../data/chains/kroupa_{ifmr[j][\"idx\"]}.npy'\n",
    "        if path.exists(filepath): \n",
    "            kchain = np.load(filepath)\n",
    "            kchain = kchain[kchain < 8]\n",
    "            if len(kchain)>0:\n",
    "                ifmr[j]['m_i_min_abs'] = np.percentile(kchain,1)\n",
    "                ifmr[j]['m_i_min1'] = np.percentile(kchain,16)\n",
    "                ifmr[j]['m_i_max1'] = np.percentile(kchain,84)\n",
    "                ifmr[j]['m_i_1'] = np.percentile(kchain,50)\n",
    "            else:\n",
    "                print(f'No kroupa chain for {idx}')\n",
    "\n",
    "        # If no UV excess, use maximal teff2 to narrow down m_init\n",
    "        uv = ~(np.isnan(tbl['nuv_mag']) & np.isnan(tbl['fuv_mag']))\n",
    "        uv_excess = np.isin(tbl['idx'],[53,174,175,236,249,281,283])\n",
    "        no_excess = uv & ~uv_excess\n",
    "        if idx in tbl[no_excess]['idx']: \n",
    "            filepath = f'../data/chains/trunc_kroupa_{idx}.npy'\n",
    "            if path.exists(filepath): # should always exist if no UV excess\n",
    "                tchain = np.load(filepath)\n",
    "                if len(tchain) > 1e4:\n",
    "                    ifmr[j]['m_i_min2'] = np.nanpercentile(tchain,16)\n",
    "                    ifmr[j]['m_i_2'] = np.nanpercentile(tchain,50)\n",
    "                    ifmr[j]['m_i_max2'] = np.nanpercentile(tchain,84)\n",
    "                else:\n",
    "                    ifmr[j]['m_i_2'] = -1 # flag problematic cases. In these cases the cluster age is too young for the results to be meaningful.\n",
    "            \n",
    "\n",
    "\n",
    "        if idx in tbl[uv_excess]['idx']: # Use MCMC bounds on teff2 to get tighter bound on m_init including a best value\n",
    "            filepath = f'../data/chains/wmchain_{idx}.npy'\n",
    "            if path.exists(filepath): # otherwise, leave it as nan\n",
    "                wmchain = np.load(filepath)\n",
    "                ifmr[j]['m_i_min3'] = np.percentile(wmchain,16)\n",
    "                ifmr[j]['m_i_3'] = np.percentile(wmchain,50)\n",
    "                ifmr[j]['m_i_max3'] = np.percentile(wmchain,84)\n",
    "            else:\n",
    "                ifmr[j]['m_i_3'] = -1 # flag problematic cases. In these cases the cluster age is too young for the results to be meaningful.\n",
    "    return ifmr\n",
    "\n",
    "def inverse_cummings_ifmr(m_final):\n",
    "    \"\"\"\n",
    "    Calculate the initial mass (M_i) given the final mass (M_f) using \n",
    "    the inverse of the Cummings et al. (2018) IFMR.\n",
    "    \n",
    "    Parameters:\n",
    "    m_final (float): The final mass of the white dwarf (in solar masses).\n",
    "    \n",
    "    Returns:\n",
    "    float: The initial mass of the progenitor star (in solar masses).\n",
    "    \"\"\"\n",
    "    if m_final < (0.080 * 0.83 + 0.489):  # Check if M_f is too low for this IFMR\n",
    "        # raise ValueError(f\"M_f {m_final:.2f} is outside the valid range for this IFMR.\")\n",
    "        return np.nan\n",
    "    \n",
    "    if m_final < (0.080 * 2.85 + 0.489):  # For range 0.83 <= M_i < 2.85\n",
    "        m_initial = (m_final - 0.489) / 0.080\n",
    "    \n",
    "    elif m_final < (0.187 * 3.60 + 0.184):  # For range 2.85 <= M_i < 3.60\n",
    "        m_initial = (m_final - 0.184) / 0.187\n",
    "    \n",
    "    elif m_final <= (0.107 * 7.20 + 0.471):  # For range 3.60 <= M_i <= 7.20\n",
    "        m_initial = (m_final - 0.471) / 0.107\n",
    "    \n",
    "    else:  # Check if M_f is too high for this IFMR\n",
    "        # raise ValueError(f\"M_f {m_final:.2f} is outside the valid range for this IFMR.\")\n",
    "        return np.nan\n",
    "    \n",
    "    return m_initial\n",
    "\n",
    "def get_cunningham_ifmr_breakpoints():\n",
    "    \"\"\"\n",
    "    Return the breakpoints and endpoints from Table 2 of the Cunningham 2024 paper,\n",
    "    including M_initial, M_final, and their 1-sigma confidence intervals, sorted by M_initial\n",
    "    in an Astropy Table.\n",
    "    \n",
    "    Returns:\n",
    "        astropy.table.Table: A table containing M_initial, M_final, and their 1-sigma confidence intervals\n",
    "                             taken directly from Table 2 of the Cunningham 2024 paper.\n",
    "    \"\"\"\n",
    "   # Data and column names passed as a dictionary\n",
    "    table2_data = {\n",
    "        'M_initial': [1.09, 2.65, 3.42, 5.06, 7.44],\n",
    "        'M_final': [0.561, 0.70, 0.79, 0.91, 1.3],\n",
    "        'M_final_p1sig': [0.559, 0.68, 0.77, 0.88, 1.25],\n",
    "        'M_final_m1sig': [0.563, 0.72, 0.81, 0.94, 1.35],\n",
    "        'M_final_p2sig': [0.557, 0.66, 0.75, 0.85, 1.20],\n",
    "        'M_final_m2sig': [0.565, 0.74, 0.83, 0.97, 1.40],\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to an Astropy Table\n",
    "    table2 = Table(table2_data)\n",
    "\n",
    "    # Sort the table by M_initial\n",
    "    table2.sort('M_initial')\n",
    "\n",
    "    return table2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create chains\n",
    "\n",
    "sources = Table.read('../table_C.fits')\n",
    "\n",
    "cut = ~np.isin(sources['idx'],[101,160,192,194,282])\n",
    "sources = sources[cut]\n",
    "\n",
    "# for idx in tqdm(sources['idx'],total=len(sources)):\n",
    "#     j = np.argwhere(sources['idx'] == idx)[0][0]\n",
    "#     age = sources['age'][j]\n",
    "#     mh = sources['[Fe/H]'][j]\n",
    "#     e_mh = sources['e_[Fe/H]'][j]\n",
    "#     e_age = sources['e_age'][j]\n",
    "    \n",
    "#     age_vec = np.random.normal(age,e_age,int(1e3))\n",
    "#     mh_vec = np.random.normal(mh,e_mh,int(1e3))\n",
    "#     k_chain = []\n",
    "#     for age,mh in zip(age_vec,mh_vec):\n",
    "#         m_min = get_initial_mass(age,mh,phase='MSTO')\n",
    "#         if np.isnan(m_min) or m_min > 8:\n",
    "#             continue\n",
    "#         m_max = 8\n",
    "#         m_arr = sample_kroupa_uniform(m_min,m_max,n = 100)\n",
    "#         k_chain.extend(m_arr)\n",
    "#     np.save(f'../data/chains/kroupa_{idx}.npy',k_chain)\n",
    "\n",
    "# uv = ~(np.isnan(sources['nuv_mag']) & np.isnan(sources['fuv_mag']))\n",
    "# uv_excess = np.isin(sources['idx'],[53,174,175,180,236,249,281,283])\n",
    "# no_excess = uv & ~uv_excess\n",
    "# tbl = sources[uv]\n",
    "# add_temperature_limits_to_table(sources)\n",
    "\n",
    "# for idx in tqdm(sources['idx'][no_excess],total=len(sources[no_excess])):\n",
    "#     j = np.argwhere(sources['idx'] == idx)[0][0]\n",
    "#     age = sources['age'][j]\n",
    "#     mh = sources['[Fe/H]'][j]\n",
    "#     e_age = sources['e_age'][j]\n",
    "#     e_mh = sources['e_[Fe/H]'][j]\n",
    "\n",
    "#     age_vec = np.random.normal(age,e_age,int(1e3))\n",
    "#     mh_vec = np.random.normal(mh,e_mh,int(1e3))\n",
    "#     age_wd = get_cooling_age(sources['teff2_max'][j],sources['m2'][j])\n",
    "#     t_chain = []\n",
    "#     for age,mh in zip(age_vec,mh_vec):\n",
    "#         age_ms = age - age_wd\n",
    "#         if age_ms < 0:\n",
    "#             continue\n",
    "#         m_min = get_initial_mass(age_ms,mh,phase='AGB')\n",
    "#         m_max = 8\n",
    "#         if np.isnan(m_min) or m_min > 8:\n",
    "#             continue\n",
    "#         m_arr = sample_kroupa_uniform(m_min,m_max,n = 100)\n",
    "#         t_chain.extend(m_arr)\n",
    "#     np.save(f'../data/chains/trunc_kroupa_{idx}.npy',t_chain)\n",
    "\n",
    "\n",
    "# uv_excess = [53,174,175,236,249,281,283]\n",
    "# tbl = Table.read('../table_C.fits')\n",
    "\n",
    "# for idx in tqdm(uv_excess,total = len(uv_excess)):\n",
    "#     if path.exists(f'../data/chains/mchain_{idx}.csv'):\n",
    "#         wmchain = weight_m_init_posterior(idx)\n",
    "#         np.save(f'../data/chains/wmchain_{idx}.npy',wmchain['m_i'])\n",
    "#         wmchain.write(f'../data/chains/wmchain_{idx}.csv',overwrite=True)\n",
    "#     else:\n",
    "#         print(f'No mchain for {idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "## plot histograms\n",
    "# sources = Table.read('../table_C.fits')\n",
    "# for idx in sources['idx']:\n",
    "#     if path.exists(f'../data/chains/wmchain_{idx}.npy'):\n",
    "#         kchain = np.load(f'../data/chains/kroupa_{idx}.npy')\n",
    "#         mchain = pd.read_csv(f'../data/chains/mchain_{idx}.csv')['m_i']\n",
    "#         wmchain = np.load(f'../data/chains/wmchain_{idx}.npy')\n",
    "#         mchain = mchain[mchain < 8]\n",
    "\n",
    "#         fig,ax = plt.subplots(dpi = 300,layout='constrained')\n",
    "#         if idx == 175 or idx == 249:\n",
    "#             ax.hist(kchain,bins=30,histtype='step',color='RoyalBlue',label=f'Kroupa prior',density=True,range = (2,5),linestyle='dashed',lw=1.5)    \n",
    "#         else:\n",
    "#             ax.hist(kchain,bins=30,histtype='step',color='RoyalBlue',label=f'Kroupa prior',density=True,linestyle='dashed',lw=1.5)\n",
    "        \n",
    "#         ax.hist(mchain,bins=30,histtype='step',color='Crimson',label=f'Unweighted',density=True,linestyle='dashdot',lw=1.5)\n",
    "#         ax.hist(wmchain,bins=30,histtype='step',color='k',label=f'Weighted,\\ncandidate {idx}',density=True,zorder=5,linestyle='solid')\n",
    "#         # ax.axvline(np.median(kchain),ls='--',color='b',label=f'50% = {np.median(kchain):.1f}M$_\\odot$')\n",
    "\n",
    "#         ax.set_xlabel(r'M$_{\\text{initial}}\\,($M$_{\\odot}$)',fontsize=14,labelpad=0)\n",
    "#         ax.set_ylabel('Normalized counts',fontsize=14)\n",
    "#         ax.legend(fontsize=14)\n",
    "#         fig.savefig(f'../img/mass_hist/mass_posterior_{idx}.png',bbox_inches='tight')\n",
    "#         # fig.savefig(f'../img/kroupa_prior/kroupa_prior_{idx}.png',bbox_inches='tight')\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the IFMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n",
      "100%|██████████| 26/26 [00:00<00:00, 103.65it/s]\n"
     ]
    }
   ],
   "source": [
    "sources = Table.read('../table_C.fits')\n",
    "cut = ~np.isin(sources['idx'],[101,160,192,194,282,114,118,121,48,174,282,283])\n",
    "ifmr = create_ifmr_tbl(sources[cut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifmr.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7d4f24f2b6a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No UV IFMR\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig,ax = plt.subplots(dpi = 300,layout='constrained')\n",
    "\n",
    "lower_error1 = ifmr['m_i_1'] - ifmr['m_i_min1']\n",
    "upper_error1 = ifmr['m_i_max1'] - ifmr['m_i_1']\n",
    "error1 = [lower_error1, upper_error1]\n",
    "cut = np.isnan(ifmr['m_i_2']) & np.isnan(ifmr['m_i_3']) & (ifmr['idx'] != 121) & ~np.isin(ifmr['idx'],[101,160,180,192,194,282])\n",
    "error1 = [lower_error1[cut], upper_error1[cut]]\n",
    "xerror1 = ifmr[cut]['m2_err']\n",
    "\n",
    "\n",
    "lower_error2 = ifmr['m_i_2'] - ifmr['m_i_min2']\n",
    "upper_error2 = ifmr['m_i_max2'] - ifmr['m_i_2']\n",
    "error2 = [lower_error2, upper_error2]\n",
    "cut2 = ~np.isnan(ifmr['m_i_2']) & (ifmr['m_i_2'] > -1)\n",
    "error2 = [lower_error2[cut2], upper_error2[cut2]]\n",
    "xerror2 = ifmr[cut2]['m2_err']\n",
    "\n",
    "lower_error3 = ifmr['m_i_3'] - ifmr['m_i_min3']\n",
    "upper_error3 = ifmr['m_i_max3'] - ifmr['m_i_3']\n",
    "error3 = [lower_error3, upper_error3]\n",
    "cut3 = ~np.isnan(ifmr['m_i_3']) & (ifmr['m_i_3'] > -1) & (ifmr['idx'] != 174)\n",
    "error3 = [lower_error3[cut3], upper_error3[cut3]]\n",
    "xerror3 = ifmr[cut3]['m2_err']\n",
    "\n",
    "\n",
    "kchains = []\n",
    "for idx in ifmr[cut]['idx']:\n",
    "    kchain = np.load(f'../data/chains/kroupa_{idx}.npy')\n",
    "    kchains.append(kchain)\n",
    "\n",
    "ebar = ax.errorbar(ifmr[cut]['m2'], ifmr[cut]['m_i_1'], xerr=xerror1,yerr=error1 ,fmt='s',label='No UV',\n",
    "                   color='b',elinewidth=0.3,capsize=0,markersize=5,\n",
    "            alpha=0.8,zorder=5)\n",
    "ebar2 = ax.errorbar(ifmr[cut2]['m2'], ifmr[cut2]['m_i_2'], xerr=xerror2,yerr=error2 ,fmt='d',label='No Excess',\n",
    "                   color='Crimson',elinewidth=0.3,capsize=0,markersize=5,\n",
    "            alpha=0.8,zorder=5)\n",
    "ebar3 = ax.errorbar(ifmr[cut3]['m2'], ifmr[cut3]['m_i_3'], xerr=xerror3,yerr=error3 ,fmt='o',label='UV Excess',\n",
    "                     color='k',elinewidth=0.3,capsize=0,markersize=5,\n",
    "                alpha=0.8,zorder=5)\n",
    "# cummings = [inverse_cummings_ifmr(x) for x in xvec]\n",
    "# cunningham = get_cunningham_ifmr_breakpoints()\n",
    "# ax.plot(cunningham['M_final'],cunningham['M_initial'],color='Navy',label='Cunningham+2024',lw=1)\n",
    "# ax.fill_betweenx(cunningham['M_initial'],cunningham['M_final_m1sig'],cunningham['M_final_p1sig'],color='Navy',alpha=0.3)\n",
    "# ax.fill_betweenx(cunningham['M_initial'],cunningham['M_final_m2sig'],cunningham['M_final_p2sig'],color='Navy',alpha=0.15)\n",
    "\n",
    "ax.set_xlabel(r'M$_{\\text{final}}\\,$(M$_{\\odot}$)',fontsize=10,labelpad=0)\n",
    "ax.set_ylabel(r'M$_{\\text{initial}}\\,$(M$_{\\odot}$)',fontsize=10)\n",
    "ax.set_ylim(top=8)\n",
    "ax.minorticks_on()\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "# fig.savefig('../img/ifmr_no_uv.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No Excess IFMR\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "ifmr.sort('m2')\n",
    "\n",
    "lower_error1 = ifmr['m_i_1'] - ifmr['m_i_min1']\n",
    "upper_error1 = ifmr['m_i_max1'] - ifmr['m_i_1']\n",
    "error1 = [lower_error1, upper_error1]\n",
    "\n",
    "lower_error2 = ifmr['m_i_2'] - ifmr['m_i_min2']\n",
    "upper_error2 = ifmr['m_i_max2'] - ifmr['m_i_2']\n",
    "error2 = [lower_error2, upper_error2]\n",
    "\n",
    "cut = ~np.isnan(ifmr['m_i_2']) & (ifmr['m_i_2'] > -1)\n",
    "error1 = [lower_error1[cut], upper_error1[cut]]\n",
    "error2 = [lower_error2[cut], upper_error2[cut]]\n",
    "\n",
    "\n",
    "kchains = []\n",
    "tchains = []\n",
    "\n",
    "for idx in ifmr[cut]['idx']:\n",
    "    kchain = np.load(f'../data/chains/kroupa_{idx}.npy')\n",
    "    tchain = np.load(f'../data/chains/trunc_kroupa_{idx}.npy')\n",
    "    kchains.append(kchain)\n",
    "    tchains.append(tchain)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(ifmr[cut]), dpi=300, layout='constrained', sharey=True)\n",
    "axs[0].set_ylabel(r'M$_{\\text{initial}}\\,$(M$_{\\odot}$)', fontsize=10)\n",
    "\n",
    "for i in range(len(ifmr[cut])):\n",
    "    idx = ifmr[cut]['idx'][i]\n",
    "    ax = axs[i]\n",
    "\n",
    "    # Blue violin (right side)\n",
    "    kchain = kchains[i]\n",
    "    parts = ax.violinplot(kchain, positions=[ifmr[cut]['m2'][i]], showmedians=False, showextrema=False, widths=0.03)\n",
    "    for pc in parts['bodies']:\n",
    "        path = pc.get_paths()[0]\n",
    "        vertices = path.vertices\n",
    "        violin_position = ifmr[cut]['m2'][i]\n",
    "        vertices[:, 0] = np.maximum(vertices[:, 0], violin_position)\n",
    "        pc.set_facecolor('RoyalBlue')\n",
    "        pc.set_edgecolor('k')\n",
    "        pc.set_alpha(0.5)\n",
    "\n",
    "    # Red violin (left side)\n",
    "    tchain = tchains[i]\n",
    "    trunc_parts = ax.violinplot(tchain, positions=[ifmr[cut]['m2'][i]], showmedians=False, showextrema=False, widths=0.03)\n",
    "    for pc in trunc_parts['bodies']:\n",
    "        path = pc.get_paths()[0]\n",
    "        vertices = path.vertices\n",
    "        violin_position = ifmr[cut]['m2'][i]\n",
    "        vertices[:, 0] = np.minimum(vertices[:, 0], violin_position)\n",
    "        pc.set_facecolor('Crimson')\n",
    "        pc.set_edgecolor('k')\n",
    "        pc.set_alpha(0.5)\n",
    "        pc.set_zorder(5)\n",
    "\n",
    "    # Error bar\n",
    "    ebar = ax.errorbar(\n",
    "        ifmr[cut]['m2'][i],\n",
    "        ifmr[cut]['m_i_2'][i],\n",
    "        xerr=ifmr[cut]['m2_err'][i],\n",
    "        fmt='d',\n",
    "        color='Crimson',\n",
    "        elinewidth=0.5,\n",
    "        capsize=1,\n",
    "        zorder=10,\n",
    "        markersize=5,\n",
    "        alpha=1,\n",
    "    )\n",
    "\n",
    "    # Add subplot-specific annotations\n",
    "    j = np.argwhere(sources['idx'] == idx)[0][0]\n",
    "    m1 = sources[j]['m1']\n",
    "    period = sources[j]['period']\n",
    "    eccentricity = sources[j]['eccentricity']\n",
    "    cluster_age = sources[j]['age']\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        0.98,\n",
    "        f'Candidate {idx}\\n' +\n",
    "        f'$M_1$={m1:.2f} M$_\\odot$\\nP={int(period)} days\\ne={eccentricity:.2f}\\n' +\n",
    "        r'$\\tau_\\text{tot}$=' + f'{int(cluster_age)} Myr',\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=8,\n",
    "        verticalalignment='top',\n",
    "        horizontalalignment='center',\n",
    "        bbox=dict(facecolor='none', edgecolor='none', alpha=0.5)\n",
    "    )\n",
    "\n",
    "    # Adjust x-limits for each subplot\n",
    "    # ax.set_xlim(ifmr[cut]['m2'][i] - 0.07, ifmr[cut]['m2'][i] + 0.07)\n",
    "    ax.set_xlabel(r'M$_{\\text{final}}\\,$(M$_{\\odot}$)', fontsize=10, labelpad=0)\n",
    "    ax.set_xlim(ifmr[cut][i]['m2']-0.09,ifmr[cut][i]['m2']+0.09)\n",
    "    ax.minorticks_on()\n",
    "# Adjust y-axis limits for all subplots\n",
    "axs[0].set_ylim(1.7, 10)\n",
    "\n",
    "# fig.savefig('../img/ifmr_no_uv_excess.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UV Excess IFMR\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "ifmr.sort('m2')\n",
    "\n",
    "lower_error3 = ifmr['m_i_3'] - ifmr['m_i_min3']\n",
    "upper_error3 = ifmr['m_i_max3'] - ifmr['m_i_3']\n",
    "error3 = [lower_error3, upper_error3]\n",
    "\n",
    "cut = ~np.isnan(ifmr['m_i_3']) & (ifmr['m_i_3'] > -1) \n",
    "cut = cut & (ifmr['idx'] != 174)\n",
    "error3 = [lower_error3[cut], upper_error3[cut]]\n",
    "\n",
    "kchains = []\n",
    "for idx in ifmr[cut]['idx']:\n",
    "    kchain = np.load(f'../data/chains/kroupa_{idx}.npy')\n",
    "    kchains.append(kchain)\n",
    "\n",
    "\n",
    "fig,axs = plt.subplots(nrows=1,ncols=len(ifmr[cut]),dpi = 300,layout='constrained',sharey=True)\n",
    "axs[0].set_ylabel(r'M$_{\\text{initial}}\\,$(M$_{\\odot}$)',fontsize=10)\n",
    "axs[0].set_ylim(1.7,10)\n",
    "for i in range(len(ifmr[cut])):\n",
    "    idx = ifmr[cut]['idx'][i]\n",
    "    kchain = kchains[i]\n",
    "    if len(kchain) > 0:\n",
    "        ax = axs[i]\n",
    "        parts = ax.violinplot(kchain,positions=[ifmr[cut][i]['m2']],showmedians=False,showextrema=False,widths=0.03)\n",
    "        for pc in parts['bodies']:\n",
    "            pc.set_facecolor('RoyalBlue')\n",
    "            pc.set_edgecolor('k')\n",
    "            pc.set_alpha(0.5)\n",
    "        color = parts['bodies'][0].get_facecolor().flatten()\n",
    "        violin = mpatches.Patch(color=color)\n",
    "        ebar = ax.errorbar(ifmr[cut]['m2'][i], ifmr[cut]['m_i_3'][i], yerr=error3[0][i], xerr=ifmr[cut][i]['m2_err'],\n",
    "                    fmt='.', color='k', elinewidth=0.5, capsize=1.5,\n",
    "                    zorder=5, markersize=10,mec='None')\n",
    "        ax.set_xlim(ifmr[cut]['m2'][i]-0.07,ifmr[cut]['m2'][i]+0.07)\n",
    "        ax.set_xlabel(r'M$_{\\text{final}}\\,$(M$_{\\odot}$)',fontsize=10,labelpad=0)\n",
    "        ax.minorticks_on()\n",
    "        j = np.argwhere(sources['idx'] == idx)[0][0]\n",
    "        m1 = sources[j]['m1']\n",
    "        period = sources[j]['period']\n",
    "        eccentricity = sources[j]['eccentricity']\n",
    "        cluster_age = sources[j]['age']\n",
    "        ax.text(0.5, 0.98, f'Candidate {idx}\\n'+f'$M_1$={m1:.2f} M$_\\odot$\\nP={int(period)} days\\ne={eccentricity:.2f}\\n'+r'$\\tau_\\text{tot}$='+f'{int(cluster_age)} Myr',\n",
    "            transform=ax.transAxes, fontsize=8, verticalalignment='top', horizontalalignment='center', bbox=dict(facecolor='none',edgecolor='none', alpha=0.5))\n",
    "\n",
    "fig.savefig('../img/ifmr_uv_excess.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7d4f2538d510>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## groups IFMR\n",
    "\n",
    "ifmr['m_i_4'] = np.zeros(len(ifmr))\n",
    "ifmr['m_i_min4'] = np.zeros(len(ifmr))\n",
    "ifmr['m_i_max4'] = np.zeros(len(ifmr))\n",
    "\n",
    "ifmr['m_i_4'] += np.array([ifmr[k]['m_i_1'] if c else 0 for k, c in enumerate(cut)])\n",
    "ifmr['m_i_min4'] += np.array([ifmr[k]['m_i_min1'] if c else 0 for k, c in enumerate(cut)])\n",
    "ifmr['m_i_max4'] += np.array([ifmr[k]['m_i_max1'] if c else 0 for k, c in enumerate(cut)])\n",
    "\n",
    "ifmr['m_i_4'] += np.array([ifmr[k]['m_i_2'] if c else 0 for k, c in enumerate(cut2)])\n",
    "ifmr['m_i_min4'] += np.array([ifmr[k]['m_i_min2'] if c else 0 for k, c in enumerate(cut2)])\n",
    "ifmr['m_i_max4'] += np.array([ifmr[k]['m_i_max2'] if c else 0 for k, c in enumerate(cut2)])\n",
    "\n",
    "ifmr['m_i_4'] += np.array([ifmr[k]['m_i_3'] if c else 0 for k, c in enumerate(cut3)])\n",
    "ifmr['m_i_min4'] += np.array([ifmr[k]['m_i_min3'] if c else 0 for k, c in enumerate(cut3)])\n",
    "ifmr['m_i_max4'] += np.array([ifmr[k]['m_i_max3'] if c else 0 for k, c in enumerate(cut3)])\n",
    "\n",
    "ifmr['m_i_4'] = [m4 if m4>0 else np.nan for m4 in ifmr['m_i_4']]\n",
    "ifmr['m_i_min4'] = [m4 if m4>0 else np.nan for m4 in ifmr['m_i_min4']]\n",
    "ifmr['m_i_max4'] = [m4 if m4>0 else np.nan for m4 in ifmr['m_i_max4']]\n",
    "error4_low = np.array(ifmr['m_i_4'] - ifmr['m_i_min4'])\n",
    "error4_high = np.array(ifmr['m_i_max4'] - ifmr['m_i_4'])\n",
    "\n",
    "ifmr['mass_loss'] = (ifmr['m_i_4'] - ifmr['m2'])/ifmr['m_i_4']\n",
    "ifmr['mass_loss_err'] = ((ifmr['m2_err']/ifmr['m_i_4'])**2 + (error4_low/ifmr['m_i_4'])**2 * ifmr['mass_loss']**2)**0.5\n",
    "\n",
    "\n",
    "group1 = (ifmr['m2'] < 0.5) & (cut | cut2 | cut3)\n",
    "inverse_cummings = [inverse_cummings_ifmr(x) for x in ifmr['m2']]\n",
    "group2 = (ifmr['m2'] >= 0.5) & (ifmr['m2'] < 0.8) & (ifmr['m_i_4'] > inverse_cummings) & ~np.isnan(inverse_cummings) & (cut | cut2 | cut3)\n",
    "group3 = ~group1 & ~group2 & (cut | cut2 | cut3)\n",
    "\n",
    "fig,ax = plt.subplots(dpi = 300,layout='constrained')\n",
    "ebar = ax.errorbar(ifmr[group1]['m2'], ifmr[group1]['m_i_4'], xerr=ifmr[group1]['m2_err'], yerr=[error4_low[group1],error4_high[group1]],\n",
    "                    fmt='s', color='b', elinewidth=0.4, capsize=0, markersize=5, label='Group 1')\n",
    "ebar2 = ax.errorbar(ifmr[group2]['m2'], ifmr[group2]['m_i_4'], xerr=ifmr[group2]['m2_err'], yerr=[error4_low[group2],error4_high[group2]],\n",
    "                     fmt='d', color='Crimson', elinewidth=0.4, capsize=0, markersize=5, label='Group 2')\n",
    "ax.scatter(ifmr[group2]['m2'],ifmr[group2]['m_i_min_abs'],marker='_',color='Crimson',s=50)\n",
    "ax.vlines(ifmr[group2]['m2'],ifmr[group2]['m_i_min_abs'],ifmr[group2]['m_i_min4'],color='Crimson',lw=0.2,linestyle='dashed',zorder=-1)\n",
    "ebar3 = ax.errorbar(ifmr[group3]['m2'], ifmr[group3]['m_i_4'], xerr=ifmr[group3]['m2_err'], yerr=[error4_low[group3],error4_high[group3]],\n",
    "                     fmt='o', color='k', elinewidth=0.4, capsize=0, markersize=5, label='Group 3')\n",
    "cunningham = get_cunningham_ifmr_breakpoints()\n",
    "ax.plot(cunningham['M_final'],cunningham['M_initial'],color='Navy',label='Cunningham+2024',lw=1)\n",
    "ax.fill_betweenx(cunningham['M_initial'],cunningham['M_final_m1sig'],cunningham['M_final_p1sig'],color='Navy',alpha=0.2)\n",
    "ax.fill_betweenx(cunningham['M_initial'],cunningham['M_final_m2sig'],cunningham['M_final_p2sig'],color='Navy',alpha=0.1)\n",
    "\n",
    "ax.set_xlabel(r'M$_{\\text{final}}\\,$(M$_{\\odot}$)',fontsize=10,labelpad=0)\n",
    "ax.set_ylabel(r'M$_{\\text{initial}}\\,$(M$_{\\odot}$)',fontsize=10)\n",
    "ax.set_ylim(top=9.6)\n",
    "ax.minorticks_on()\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "# fig.savefig('../img/ifmr_groups.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## group 3 IFMR as MS+WD+WD systems\n",
    "\n",
    "mswdwd = np.isin(ifmr['idx'],[110,154,183,260,262])\n",
    "group3_a = group3 & ~mswdwd\n",
    "cunningham = get_cunningham_ifmr_breakpoints()\n",
    "wd2 = np.interp(ifmr[mswdwd]['m_i_4'],cunningham['M_initial'],cunningham['M_final'])\n",
    "wd1 = ifmr[mswdwd]['m2'] - wd2\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(dpi = 300,layout='constrained')\n",
    "ax.plot(cunningham['M_final'],cunningham['M_initial'],color='Navy',label='Cunningham+2024',lw=1)\n",
    "ax.fill_betweenx(cunningham['M_initial'],cunningham['M_final_m1sig'],cunningham['M_final_p1sig'],color='Navy',alpha=0.2)\n",
    "ax.fill_betweenx(cunningham['M_initial'],cunningham['M_final_m2sig'],cunningham['M_final_p2sig'],color='Navy',alpha=0.1)\n",
    "\n",
    "\n",
    "ax.hlines(ifmr[mswdwd]['m_i_4'],wd2,ifmr[mswdwd]['m2'],color='k',lw=0.3,ls='dotted')\n",
    "ax.scatter(ifmr[mswdwd]['m2'],ifmr[mswdwd]['m_i_4'],label='WD$_1$+WD$_2$',color='k',s=20)\n",
    "# ax.errorbar(ifmr[group3_a]['m2'], ifmr[group3_a]['m_i_4'], xerr=ifmr[group3_a]['m2_err'], yerr=[error4_low[group3_a],error4_high[group3_a]],\n",
    "#                         fmt='o', color='k', elinewidth=0.4, capsize=0, markersize=5)\n",
    "# ax.scatter(ifmr[group3_a]['m2'],ifmr[group3_a]['m_i_4'],label='Group 3',color='k',s=20)\n",
    "ax.hlines(ifmr[mswdwd]['m_i_4'],wd1,wd2,color='k',lw=0.5,ls='dashed')\n",
    "ax.scatter(wd1,ifmr[mswdwd]['m_i_4'],marker='*',color='k',s=50,label='WD$_1$',zorder=5)\n",
    "ax.scatter(wd2,ifmr[mswdwd]['m_i_4'],marker='x',color='k',s=50,label='WD$_2$',zorder=5)\n",
    "\n",
    "for idx in ifmr[mswdwd]['idx']:\n",
    "    j = np.argwhere(ifmr['idx'] == idx)[0][0]\n",
    "    k = np.argwhere(ifmr[mswdwd]['idx'] == idx)[0][0]\n",
    "    m2 = ifmr[j]['m2']\n",
    "    yshift = -0.3 if idx==110 else -0.15\n",
    "    ax.text(m2 + 0.09, ifmr[j]['m_i_4']+yshift, f'{idx}', fontsize=10, verticalalignment='bottom', horizontalalignment='right')\n",
    "    \n",
    "\n",
    "ax.set_xlabel(r'M$_{\\text{final}}\\,$(M$_{\\odot}$)',fontsize=14,labelpad=0)\n",
    "ax.set_ylabel(r'M$_{\\text{initial}}\\,$(M$_{\\odot}$)',fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.minorticks_on()\n",
    "ax.legend(loc='upper left',fontsize=12)\n",
    "fig.savefig('../img/ifmr_triples.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations and more fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x76c7bf097fa0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## correlations between mass loss and system properties\n",
    "\n",
    "# fig,ax = plt.subplots(dpi = 300,layout='constrained')\n",
    "\n",
    "# ax.errorbar(ifmr[group1]['m2'], ifmr[group1]['eccentricity'], yerr=ifmr[group1]['eccentricity_error'], xerr = ifmr[group1]['m2_err'],\n",
    "#              fmt='s', color='b', elinewidth=0.5, capsize=0, markersize=3, label='Group 1')\n",
    "# ax.errorbar(ifmr[group2]['m2'], ifmr[group2]['eccentricity'], yerr=ifmr[group2]['eccentricity_error'], xerr = ifmr[group2]['m2_err'],\n",
    "#              fmt='d', color='Crimson', elinewidth=0.5, capsize=0, markersize=3, label='Group 2')\n",
    "# ax.errorbar(ifmr[group3]['m2'], ifmr[group3]['eccentricity'], yerr=ifmr[group3]['eccentricity_error'], xerr = ifmr[group3]['m2_err'],\n",
    "#              fmt='o', color='k', elinewidth=0.5, capsize=0, markersize=3, label='Group 3')\n",
    "\n",
    "# ax.minorticks_on()\n",
    "# ax.set_xlabel(r'M$_{\\text{final}}\\,$(M$_{\\odot}$)',fontsize=10,labelpad=0)\n",
    "# ax.set_ylabel(r'Eccentricity',fontsize=10)\n",
    "# ax.legend()\n",
    "# fig.savefig('../img/eccentricity_groups.png')\n",
    "\n",
    "# ax.errorbar(ifmr[group1]['[Fe/H]'], ifmr[group1]['mass_loss'], yerr=ifmr[group1]['mass_loss_err'], xerr=ifmr[group1]['e_[Fe/H]'],\n",
    "#              fmt='s', color='b', elinewidth=0.5, capsize=0, markersize=3, label='Group 1')\n",
    "# ax.errorbar(ifmr[group2]['[Fe/H]'], ifmr[group2]['mass_loss'], yerr=ifmr[group2]['mass_loss_err'], xerr=ifmr[group2]['e_[Fe/H]'],\n",
    "#              fmt='d', color='Crimson', elinewidth=0.5, capsize=0, markersize=3, label='Group 2')\n",
    "# ax.errorbar(ifmr[group3]['[Fe/H]'], ifmr[group3]['mass_loss'], yerr=ifmr[group3]['mass_loss_err'], xerr=ifmr[group3]['e_[Fe/H]'],\n",
    "#              fmt='o', color='k', elinewidth=0.5, capsize=0, markersize=3, label='Group 3')\n",
    "\n",
    "# ax.minorticks_on()\n",
    "# ax.set_xlabel(r'[Fe/H]', fontsize=10, labelpad=0)\n",
    "# ax.set_ylabel(r'Fractional Mass Loss', fontsize=10)\n",
    "# ax.legend()\n",
    "# fig.savefig('../img/mass_loss_vs_metallicity.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## more correlations\n",
    "\n",
    "# from scipy.optimize import curve_fit\n",
    "# from scipy.stats import chi2\n",
    "\n",
    "# cut = np.isnan(ifmr['m_i_2']) & np.isnan(ifmr['m_i_3']) & (ifmr['idx'] != 121) & ~np.isin(ifmr['idx'],[101,160,180,192,194,282])\n",
    "# cut2 = ~np.isnan(ifmr['m_i_2']) & (ifmr['m_i_2'] > -1)\n",
    "# cut3 = ~np.isnan(ifmr['m_i_3']) & (ifmr['m_i_3'] > -1) & (ifmr['idx'] != 174)\n",
    "\n",
    "\n",
    "# mh1 = [sources[sources['idx'] == j]['[Fe/H]'][0] for j in ifmr[cut]['idx']]\n",
    "# e_mh1 = [sources[sources['idx'] == j]['e_[Fe/H]'][0] for j in ifmr[cut]['idx']]\n",
    "# p1 = [sources[sources['idx'] == j]['period'][0] for j in ifmr[cut]['idx']]\n",
    "# e1 = [sources[sources['idx'] == j]['eccentricity'][0] for j in ifmr[cut]['idx']]\n",
    "# m_i1 = ifmr[cut]['m_i_1']\n",
    "# m_fin1 = ifmr[cut]['m2']\n",
    "# m_prim1 = ifmr[cut]['m1']\n",
    "# # e_m_i1 = (ifmr[cut]['m_i_max1'] - ifmr[cut]['m_i_min1'])/2\n",
    "# e_m_i1 = ifmr[cut]['m_i_1'] - ifmr[cut]['m_i_min1'] # The error is asymmetric. This is the smaller error.\n",
    "# f1 = (ifmr[cut]['m_i_1'] - ifmr[cut]['m2'])/ifmr[cut]['m_i_1']\n",
    "# e_f1 = np.sqrt(f1**2*(e_m_i1/m_i1)**2 + (ifmr[cut]['m2_err']/m_i1)**2)\n",
    "\n",
    "# mh2 = [sources[sources['idx'] == j]['[Fe/H]'][0] for j in ifmr[cut2]['idx']]\n",
    "# e_mh2 = [sources[sources['idx'] == j]['e_[Fe/H]'][0] for j in ifmr[cut2]['idx']]\n",
    "# p2 = [sources[sources['idx'] == j]['period'][0] for j in ifmr[cut2]['idx']]\n",
    "# e2 = [sources[sources['idx'] == j]['eccentricity'][0] for j in ifmr[cut2]['idx']]\n",
    "# m_i2 = ifmr[cut2]['m_i_2']\n",
    "# m_fin2 = ifmr[cut2]['m2']\n",
    "# m_prim2 = ifmr[cut2]['m1']\n",
    "# # e_m_i2 = (ifmr[cut2]['m_i_max2'] - ifmr[cut2]['m_i_min2'])/2\n",
    "# e_m_i2 = ifmr[cut2]['m_i_2'] - ifmr[cut2]['m_i_min2']\n",
    "# f2 = (ifmr[cut2]['m_i_2'] - ifmr[cut2]['m2'])/ifmr[cut2]['m_i_2']\n",
    "# e_f2 = np.sqrt(f2**2*(e_m_i2/m_i2)**2 + (ifmr[cut2]['m2_err']/m_i2)**2)\n",
    "\n",
    "# mh3 = [sources[sources['idx'] == j]['[Fe/H]'][0] for j in ifmr[cut3]['idx']]\n",
    "# e_mh3 = [sources[sources['idx'] == j]['e_[Fe/H]'][0] for j in ifmr[cut3]['idx']]\n",
    "# p3 = [sources[sources['idx'] == j]['period'][0] for j in ifmr[cut3]['idx']]\n",
    "# e3 = [sources[sources['idx'] == j]['eccentricity'][0] for j in ifmr[cut3]['idx']]\n",
    "# m_i3 = ifmr[cut3]['m_i_3']\n",
    "# m_fin3 = ifmr[cut3]['m2']\n",
    "# m_prim3 = ifmr[cut3]['m1']\n",
    "# # e_m_i3 = (ifmr[cut3]['m_i_max3'] - ifmr[cut3]['m_i_min3'])/2\n",
    "# e_m_i3 = ifmr[cut3]['m_i_3'] - ifmr[cut3]['m_i_min3']\n",
    "# f3 = (ifmr[cut3]['m_i_3'] - ifmr[cut3]['m2'])/ifmr[cut3]['m_i_3']\n",
    "# e_f3 = np.sqrt(f3**2*(e_m_i3/m_i3)**2 + (ifmr[cut3]['m2_err']/m_i3)**2)\n",
    "\n",
    "\n",
    "# f = np.concatenate([f1,f2,f3]) ## fractional mass loss\n",
    "# e_f = np.concatenate([e_f1,e_f2,e_f3]) ## fractional mass loss error- ideal case\n",
    "# mh = np.concatenate([mh1,mh2,mh3]) ## metallicity\n",
    "# e_mh = np.concatenate([e_mh1,e_mh2,e_mh3]) ## metallicity error\n",
    "# m_fin = np.concatenate([m_fin1,m_fin2,m_fin3]) ## final mass\n",
    "# m_i = np.concatenate([m_i1,m_i2,m_i3]) ## initial mass\n",
    "# m_prim = np.concatenate([m_prim1,m_prim2,m_prim3]) ## primary mass\n",
    "# p = np.concatenate([p1,p2,p3]) ## period\n",
    "# e = np.concatenate([e1,e2,e3]) ## eccentricity\n",
    "\n",
    "# q_today = m_prim/m_fin ## mass ratio today, M1/M2, we flip the previous notation of M2/M1 to calculate the relevant roche lobe radius\n",
    "# sep_today = (p/365)**(2/3) * (m_prim + m_fin)**(1/3) ## separation today in AU\n",
    "# q_init_wind = m_prim/m_i ## mass ratio at the start of mass transfer, assuming accretor mass unchanged: M_1/M_init\n",
    "# sep_wind = (m_prim+m_fin)/(m_prim+m_i) * sep_today ## separation at the start of mass transfer in AU assuming no accretion\n",
    "\n",
    "# fig,ax = plt.subplots(dpi = 300,layout='constrained')\n",
    "# ax.scatter(sep_today,f,marker='o',label='Today')\n",
    "# ax.scatter(sep_wind,f,marker='d',label='Start of mass transfer')\n",
    "# ax.set_xlabel('Separation (AU)')\n",
    "# ax.set_ylabel(r'$\\frac{M_i - M_f}{M_i}$')\n",
    "# ax.legend()\n",
    "\n",
    "# constant = np.average(f,weights=1/e_f**2)\n",
    "# constant_err = np.sqrt(1/np.sum(1/e_f**2))\n",
    "\n",
    "# chisquared = np.sum((f - constant)**2/e_f**2)\n",
    "# pval = chi2.sf(chisquared,len(f)-1)\n",
    "\n",
    "\n",
    "# def linear(x,m,c):\n",
    "#     return m*x + c\n",
    "\n",
    "# popt,pcov = curve_fit(linear,mh,f,sigma=e_f,absolute_sigma=True)\n",
    "# m,c = popt\n",
    "# m_err,c_err = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# chisquared_lin = np.sum((f - linear(mh,m,c))**2/e_f**2)\n",
    "# pval_lin = chi2.sf(chisquared_lin,len(f)-2)\n",
    "\n",
    "# print(chisquared , len(f) - 1)\n",
    "# print(chisquared_lin, len(f) - 2)\n",
    "# # Calculate Akaike Information Criterion (AIC)\n",
    "# aic_constant = 2 * 1 + chisquared + (2 * 1 * (1 + 1)) / (len(f) - 1 - 1)\n",
    "# aic_linear = 2 * 2 + chisquared_lin + (2 * 2 * (2 + 1)) / (len(f) - 2 - 1)\n",
    "\n",
    "# print(f\"AIC (constant model): {aic_constant}\")\n",
    "# print(f\"AIC (linear model): {aic_linear}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
