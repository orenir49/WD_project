{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from astropy import table\n",
    "from astroquery.gaia import Gaia\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import scoreatpercentile\n",
    "from scipy.interpolate import LinearNDInterpolator, NearestNDInterpolator, RBFInterpolator\n",
    "import stam\n",
    "from tqdm import tqdm\n",
    "import WD_models\n",
    "from os import path\n",
    "import extinction\n",
    "from astropy.constants import R_sun, G, M_sun\n",
    "import astropy.units as u\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "# clusters = Table.read('../data/hunt_clusters/clusters.csv')\n",
    "# members = Table.read('../data/hunt_clusters/members.csv')\n",
    "sources = Table.read('../table_C.fits', format='fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from astroquery.vizier import Vizier\n",
    "# clstrs = Vizier(catalog='J/MNRAS/504/356',columns=['Cluster','N','logage','e_logage','[Fe/H]','e_[Fe/H]','Av','e_Av','FileName'],row_limit=-1).query_constraints()[0]\n",
    "\n",
    "# clstrs.rename_columns(clstrs.colnames,['Cluster','N','logage','e_logage','Fe/H','e_Fe/H','Av','e_Av','FileName'])\n",
    "# # sources = Table.read('../table_extra.fits')\n",
    "# sources['idx'] = np.full(len(sources),'---',dtype=object)\n",
    "\n",
    "# cut = (sources['nss_solution_type'] == 'Orbital') | (sources['nss_solution_type'] == 'AstroSpectroSB1')\n",
    "# sources = sources[cut]\n",
    "\n",
    "# nms = np.unique(sources['cluster'])\n",
    "# for n in nms:\n",
    "#     for i, s in enumerate(sources[sources['cluster'] == n]):\n",
    "#         j = np.where(sources['source_id'] == s['source_id'])[0][0]\n",
    "#         tbl[j]['idx'] = n+'_'+str(i)\n",
    "\n",
    "# sources['idx'] = sources['idx'].astype(str)\n",
    "# sources['age'] = np.full(len(sources),np.nan)\n",
    "# sources['[Fe/H]'] = np.full(len(sources),np.nan)\n",
    "# sources['Av'] = np.full(len(sources),np.nan)\n",
    "\n",
    "# for j in range(len(sources)):\n",
    "#     if sources[j]['cluster'] == 'Hyades':\n",
    "#         sources[j]['age'] = 680\n",
    "#         sources[j]['[Fe/H]'] = 0.14\n",
    "#         sources[j]['Av'] = 0.01 * 3.1\n",
    "#     if sources[j]['cluster'] == 'IC_2602':\n",
    "#         sources[j]['age'] = 60\n",
    "#         sources[j]['[Fe/H]'] = -0.02\n",
    "#         sources[j]['Av'] = 0.05 * 3.1\n",
    "#     if sources[j]['cluster'] == 'NGC_2287':\n",
    "#         sources[j]['age'] = 200\n",
    "#         sources[j]['[Fe/H]'] = -0.11\n",
    "#         sources[j]['Av'] = 0.03 * 3.1\n",
    "#     if sources[j]['cluster'] == 'NGC_2547':\n",
    "#         sources[j]['mh'] = 60\n",
    "#         sources[j]['[Fe/H]'] = 0.01\n",
    "#         sources[j]['Av'] = 0.06 * 3.1\n",
    "\n",
    "# for j in range(len(sources)):\n",
    "#     clstr = sources[j]['cluster']\n",
    "#     if clstr in clstrs['cluster']:\n",
    "#         i = np.where(clstrs['cluster'] == clstr)[0][0]\n",
    "#         sources[j]['age'] = clstrs[i]['age']\n",
    "#         sources[j]['[Fe/H]'] = clstrs[i]['Fe_H']\n",
    "#         sources[j]['Av'] = clstrs[i]['ebv'] * 3.1\n",
    "    \n",
    "# sources.sort('idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARSEC functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "PARSEC_path = '../OCFit/gaiaDR2/grids/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "\n",
    "\n",
    "def choose_model(mh):\n",
    "    if (-0.6 <= mh) and (mh <= 0.05):\n",
    "        PARSEC_path = '../data/PARSECv2.0/w_i=0.6/'\n",
    "        models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "    else:\n",
    "        PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "        models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "    return PARSEC_path,models\n",
    "\n",
    "def get_tracks(mh,age):\n",
    "    \n",
    "    color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation    \n",
    "    age_res = np.min(abs(10**np.unique(models['logAge'].data) * 1e-9 - age * 1e-3)) * 1.05 + 1e-3\n",
    "    mh_res = np.min(abs(np.unique(models['MH'].data) - mh)) + 0.005\n",
    "   \n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 5  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 8  # [Msun]\n",
    "    tracks = stam.gentracks.get_isotrack(models, [age * 1e-3, mh], params=(\"age\", \"mh\"), return_table=True,\n",
    "                                    age_res=age_res, mass_min=mass_min, mass_max=mass_max, mh_res = mh_res,\n",
    "                                    stage=None, stage_min=stage_min, stage_max=stage_max, sort_by=\"age\", color_filter1=color_fil_1, color_filter2=color_fil_2,\n",
    "                mag_filter=mag_fil)\n",
    "    return tracks\n",
    "\n",
    "def get_track_idx(mh,age):\n",
    "    color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation    \n",
    "    age_res = np.min(abs(10**np.unique(models['logAge'].data) * 1e-9 - age * 1e-3)) * 1.05\n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 5  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 8  # [Msun]\n",
    "    track_idx = stam.gentracks.get_isotrack(models, [age * 1e-3, mh], params=(\"age\", \"mh\"), return_idx=True,\n",
    "                                    age_res=age_res, mass_min=mass_min, mass_max=mass_max, mh_res = 0.025,\n",
    "                                    stage=None, stage_min=stage_min, stage_max=stage_max, sort_by=\"age\", color_filter1=color_fil_1, color_filter2=color_fil_2,\n",
    "                mag_filter=mag_fil)   \n",
    "    return track_idx\n",
    "\n",
    "def get_age_mh_grid():\n",
    "    age = 10**np.unique(models['logAge'].data) * 1e-6\n",
    "    mh = np.unique(models['MH'].data)\n",
    "    age,mh = np.meshgrid(age,mh)\n",
    "    return age,mh\n",
    "\n",
    "\n",
    "# c = (models['label'] <= 5) & (models['Mini']<=8)\n",
    "# p1 = models[c]['Mass']\n",
    "# p2 = models[c]['logAge']\n",
    "# p3 = models[c]['MH']\n",
    "# pdep1 = models[c]['G_BPmag'] - models[c]['G_RPmag']\n",
    "# pdep2 = models[c]['Gmag']\n",
    "\n",
    "# mass_to_mag = LinearNDInterpolator(np.vstack(list(zip(p1,p2,p3))), pdep2)\n",
    "# mass_to_color = LinearNDInterpolator(np.vstack(list(zip(p1,p2,p3))), pdep1)\n",
    "\n",
    "# def get_isochrone(mh,age):\n",
    "#     mass_arr = get_tracks(mh,age)['mass']\n",
    "#     gmag = mass_to_mag(mass_arr,np.log10(age*1e6),mh)\n",
    "#     bprp = mass_to_color(mass_arr,np.log10(age*1e6),mh)\n",
    "#     return Table([mass_arr,bprp,gmag],names=['mass','bp_rp','mg'])\n",
    "\n",
    "# _ = get_isochrone(0,101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster parameters and primary mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mass interpolations, cluster cmd plots\n",
    "\n",
    "def tracks2grid(tracks, xparam = \"bp_rp\", yparam = \"mg\", xstep=0.05, ystep=0.05):\n",
    "    # auxiliary to interp_mass_realization\n",
    "    xmin = np.min(np.around(tracks[xparam], -int(np.round(np.log10(xstep)))))\n",
    "    xmax = np.max(np.around(tracks[xparam], -int(np.round(np.log10(xstep)))))\n",
    "    ymin = np.min(np.around(tracks[yparam], -int(np.round(np.log10(ystep)))))\n",
    "    ymax = np.max(np.around(tracks[yparam], -int(np.round(np.log10(ystep)))))\n",
    "    x, y = np.meshgrid(np.arange(xmin, xmax, xstep), np.arange(ymin, ymax, ystep))\n",
    "            \n",
    "    return x, y, xmin, xmax, ymin, ymax\n",
    "\n",
    "def interp_mass_realization(age,mh,av,bp_rp,mg):\n",
    "    # For a single realization of cluster and source parameters, interpolate the mass\n",
    "\n",
    "    # get the isotrack for this realization of the cluster parameters\n",
    "    tracks = get_tracks(mh,age)\n",
    "    x = np.array(tracks[\"bp_rp\"])\n",
    "    y = np.array(tracks[\"mg\"])\n",
    "    z = np.array(tracks[\"mass\"])\n",
    "    # Add small noise to the isochrone (to avoid singularity problems)\n",
    "    x = x + np.random.normal(0, 0.0001, len(x))\n",
    "    y = y + np.random.normal(0, 0.0001, len(y))\n",
    "    z = z + np.random.normal(0, 0.0001, len(z))\n",
    "    # apply extinction to the isochrone\n",
    "    ag, e_bprp = extinction.get_AG_EBPRP(av,x)\n",
    "    y = y + ag\n",
    "    x = x + e_bprp\n",
    "    # interpolate this instance of color and magnitude along the isochrone\n",
    "    xstep, ystep = 0.05, 0.05\n",
    "    grid_x, grid_y, xmin, xmax, ymin, ymax = tracks2grid(tracks, xstep=xstep, ystep=ystep)    \n",
    "    fun_type = \"linear\"\n",
    "    interp = RBFInterpolator(np.array([x, y]).T, z, kernel=fun_type)\n",
    "    grid = np.array([grid_x, grid_y])\n",
    "    grid_flat = grid.reshape(2, -1).T\n",
    "    grid_z = interp(grid_flat).reshape(grid_x.shape)\n",
    "    mass = interp(np.array([[bp_rp, mg]]))[0]\n",
    "    return mass\n",
    "\n",
    "def photometric_mass(idx,save=False,plot=False,n_realizations=100):        \n",
    "    # Run monte carlo simulation to estimate primary pass and error\n",
    "    j = np.where(sources['idx'] == idx)[0][0]\n",
    "    age, e_age = sources[j]['age'], sources[j]['e_age']\n",
    "    mh, e_mh = sources[j]['[Fe/H]'], sources[j]['e_[Fe/H]']\n",
    "    av, e_av = sources[j]['Av'], sources[j]['e_Av']\n",
    "    mg = sources[j]['mg']\n",
    "    bp_rp = sources[j]['bp_rp']\n",
    "\n",
    "    # estimate photometric errors\n",
    "    e_g= 2.5*np.log(10)*sources[j]['phot_g_mean_flux_error']/sources[j]['phot_g_mean_flux']\n",
    "    e_mg = np.sqrt(e_g**2 + (2.17 / sources[j]['parallax_over_error'])**2)\n",
    "    e_bp = 2.5 * np.log(10) * sources[j]['phot_bp_mean_flux_error'] / sources[j]['phot_bp_mean_flux']\n",
    "    e_rp = 2.5 * np.log(10) * sources[j]['phot_rp_mean_flux_error'] / sources[j]['phot_rp_mean_flux']\n",
    "    e_bp_rp = np.sqrt(e_bp**2 + e_rp**2)\n",
    "\n",
    "    # run monte carlo simulation\n",
    "    age_vec = np.random.normal(age,e_age,n_realizations)\n",
    "    mh_vec = np.random.normal(mh,e_mh,n_realizations)\n",
    "    av_vec = np.random.normal(av,e_av,n_realizations)\n",
    "    bp_rp_vec = np.random.normal(bp_rp,e_bp_rp,n_realizations)\n",
    "    mg_vec = np.random.normal(mg,e_mg,n_realizations)\n",
    "    mass_vec = np.zeros(n_realizations)\n",
    "    for i in range(n_realizations):\n",
    "        try:\n",
    "            mass_vec[i] = interp_mass_realization(age_vec[i],mh_vec[i],av_vec[i],bp_rp_vec[i],mg_vec[i])\n",
    "        except:\n",
    "            mass_vec[i] = np.nan\n",
    "    m1 = np.nanmean(mass_vec)\n",
    "    m1_err = np.nanstd(mass_vec)\n",
    "    plot_mass_interp(age,mh,av,bp_rp,mg,m1,m1_err,idx,sources[j]['cluster'],save,plot)\n",
    "    return m1,m1_err\n",
    "\n",
    "def get_cluster_members(cluster):\n",
    "    # read the cluster member data from our premade files, apply quality cuts\n",
    "\n",
    "    filepath = path.join('..','OCFit','gaiaDR2','data',cluster+'.dat')\n",
    "    obs = np.genfromtxt(filepath,names=True,delimiter=',',dtype=None)\n",
    "    if path.exists(filepath.replace('.dat','_D.dat')):\n",
    "        obsD = np.genfromtxt(filepath.replace('.dat','_D.dat'),names=True,delimiter=',',dtype=None)\n",
    "        obs = np.concatenate((obs,obsD))\n",
    "\n",
    "    mg = obs['Gmag'] - 5 * np.log10(1000/obs['Plx']) + 5\n",
    "    #remove nans para fazer os plots\n",
    "    cond1 = np.isfinite(obs['Gmag'])\n",
    "    cond2 = np.isfinite(obs['BPmag'])\n",
    "    cond3 = np.isfinite(obs['RPmag'])\n",
    "    \n",
    "    cond4 = obs['RFG'] > 50.0\n",
    "    cond5 = obs['RFBP'] > 20.0\n",
    "    cond6 = obs['RFRP'] > 20.0\n",
    "    cond7 = obs['E_BR_RP_'] < 1.3+0.06*(obs['BPRP'])**2\n",
    "    cond8 = obs['E_BR_RP_'] > 1.0+0.015*(obs['BPRP'])**2\n",
    "    cond9 = obs['Nper'] > 8\n",
    "    cond10 = obs['fidelity_v2'] > 0.5\n",
    "    cond11 = (mg < 9) | (obs['BPRP'] > 0)       \n",
    "    ind  = np.where(cond1&cond2&cond3&cond4&cond5&cond6&cond7&cond8&cond9&cond10&cond11)\n",
    "    obs = obs[ind]\n",
    "    obs = Table(obs)\n",
    "    obs = table.unique(obs,keys='source_id')\n",
    "    return obs\n",
    "    \n",
    "def plot_cmd(idx,cluster,age,mh,ebv,save,plot):\n",
    "        memb = get_cluster_members(cluster)\n",
    "        memb['mg'] = memb['Gmag'] - 5 * np.log10(1000/memb['Plx']) + 5\n",
    "\n",
    "        mg = memb['mg']\n",
    "        bp_rp = memb['BPRP']\n",
    "        mg0 = sources[sources['idx']== idx]['mg']\n",
    "        bp_rp0= sources[sources['idx']== idx]['bp_rp']\n",
    "\n",
    "        track = get_tracks(mh,age)\n",
    "        bp_rp_model = np.array(track['bp_rp'])\n",
    "        mg_model = np.array(track['mg'])\n",
    "        ag, e_bprp = extinction.get_AG_EBPRP(3.1*ebv,bp_rp_model)\n",
    "        mg_model = mg_model + ag\n",
    "        bp_rp_model = bp_rp_model + e_bprp\n",
    "\n",
    "        fig,ax = plt.subplots(dpi=300)\n",
    "        ax.scatter(bp_rp,mg,s=5,c='r',label='Cluster members',zorder=5)\n",
    "        ax.scatter(bp_rp0,mg0,s=25,c='g',label='Candidate',zorder = 10)\n",
    "        ax.plot(bp_rp_model,mg_model, 'ko', markersize=1,label=f'PARSEC age={int(age)} Myr, [Fe/H]={mh:.2f}, E(B-V)={ebv:.3f}')\n",
    "        ax.set_xlabel('BP-RP')\n",
    "        ax.set_ylabel('G')\n",
    "        ax.invert_yaxis()\n",
    "        ax.legend(loc='lower left',frameon=False)\n",
    "        ax.set_title('Candidate '+ str(idx) + ' in cluster ' + cluster)\n",
    "        if save:\n",
    "            fig.savefig(f'../img/cmd/{idx}_'+cluster+'.png')\n",
    "        if not plot:\n",
    "            plt.close()\n",
    "\n",
    "def plot_mass_interp(age,mh,av,bp_rp,mg,m1,m1_err,idx,clstr,save,plot):\n",
    "    # For the final mass estimate, plot the mass interpolation\n",
    "    tracks = get_tracks(mh,age)\n",
    "    x = np.array(tracks[\"bp_rp\"])\n",
    "    y = np.array(tracks[\"mg\"])\n",
    "    z = np.array(tracks[\"mass\"])\n",
    "    # Add small noise to the isochrone (to avoid singularity problems)\n",
    "    x = x + np.random.normal(0, 0.0001, len(x))\n",
    "    y = y + np.random.normal(0, 0.0001, len(y))\n",
    "    z = z + np.random.normal(0, 0.0001, len(z))\n",
    "    # apply extinction to the isochrone\n",
    "    ag, e_bprp = extinction.get_AG_EBPRP(av,x)\n",
    "    y = y + ag\n",
    "    x = x + e_bprp\n",
    "    # interpolate this instance of color and magnitude along the isochrone\n",
    "    xstep, ystep = 0.05, 0.05\n",
    "    grid_x, grid_y, xmin, xmax, ymin, ymax = tracks2grid(tracks, xstep=xstep, ystep=ystep)    \n",
    "    fun_type = \"linear\"\n",
    "    interp = RBFInterpolator(np.array([x, y]).T, z, kernel=fun_type)\n",
    "    grid = np.array([grid_x, grid_y])\n",
    "    grid_flat = grid.reshape(2, -1).T\n",
    "    grid_z = interp(grid_flat).reshape(grid_x.shape)\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(dpi=300, tight_layout=True)\n",
    "    ax.plot(x, y, 'ko', markersize=1,label=f'PARSEC age={int(age)} Myr, [Fe/H]={mh:.2f}, E(B-V)={av/3.1:.3f}')\n",
    "    h = ax.imshow(grid_z, origin=\"lower\", extent=[xmin, xmax, ymin, ymax], cmap='Oranges', aspect='auto')\n",
    "    ax.scatter(bp_rp,mg,s=25,c='g',label=f'Candidate $M_1$={m1:.2f} $\\pm$ {m1_err:.2f} $M_\\odot$',zorder = 10)\n",
    "    plt.colorbar(h, label=r\"Mass (M$_\\odot$)\")\n",
    "    ax.set_xlabel(r\"$G_\\text{BP}-G_\\text{RP}$\")\n",
    "    ax.set_ylabel(r\"$G$\")\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_title(f'Candidate {idx} in cluster {clstr}')\n",
    "    ax.invert_yaxis()\n",
    "    ax.legend(loc='lower left',frameon=False,fontsize=8)\n",
    "    \n",
    "    if save:\n",
    "        fig.savefig(f'../img/mass_interp/{idx}_'+clstr+'.png')\n",
    "    if not plot:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = False\n",
    "save = True\n",
    "sources = Table.read('../table_B.fits')\n",
    "new_sources = sources.copy()\n",
    "m1_col = []\n",
    "m1_err_col = []\n",
    "\n",
    "# fitting all with parsec v1.2S\n",
    "# PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "PARSEC_path = '../OCFit/gaiaDR2/grids/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "for idx in new_sources['idx']:\n",
    "    age = new_sources[new_sources['idx'] == idx]['age'][0]\n",
    "    mh = new_sources[new_sources['idx'] == idx]['[Fe/H]'][0]\n",
    "    ebv = new_sources[new_sources['idx'] == idx]['Av'][0] / 3.1\n",
    "    cluster = new_sources[new_sources['idx'] == idx]['cluster'][0]\n",
    "    if np.isnan(age):\n",
    "        # if unable to fit age, skip the candidate\n",
    "        # new_sources.remove_row(np.where(new_sources['idx'] == idx)[0][0])\n",
    "        m1_col.append(np.nan)\n",
    "        m1_err_col.append(np.nan)\n",
    "    else:\n",
    "        try:\n",
    "            print(f'Photometric mass for candidate {idx}...')\n",
    "            m1, m1_err = photometric_mass(idx,save=True,plot=False,n_realizations=100)\n",
    "            m1_col.append(m1)\n",
    "            m1_err_col.append(m1_err)\n",
    "        except:\n",
    "            print(f'Error in photometric mass for candidate {idx}')\n",
    "            m1_col.append(np.nan)\n",
    "            m1_err_col.append(np.nan)\n",
    "        plot_cmd(idx,cluster,age,mh,ebv,save,plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "new_sources['m1'] = m1_col\n",
    "new_sources['m1_err'] = m1_err_col\n",
    "\n",
    "# new_sources.write('../table_B.fits',overwrite=True)\n",
    "sources = new_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions, gaia passbands\n",
    "\n",
    "# ------------ AMRF limits ----------------\n",
    "from astropy.io import ascii\n",
    "from synphot import SourceSpectrum, ReddeningLaw\n",
    "from synphot.models import BlackBodyNorm1D\n",
    "from synphot.units import convert_flux\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "import json \n",
    "from uncertainties import unumpy as unp, ufloat\n",
    "from uncertainties import correlated_values_norm, correlation_matrix\n",
    "import warnings\n",
    "\n",
    "def blackbody(temperature, wavelength, ebv=None, extinction_model='mwavg'):\n",
    "    bb = SourceSpectrum(BlackBodyNorm1D, temperature=temperature*u.K)  # [photons s^-1 cm^-2 A^-1]\n",
    "    # if ebv is not None:\n",
    "    #     # apply extinction\n",
    "    #     ext = ReddeningLaw.from_extinction_model(extinction_model).extinction_curve(ebv)\n",
    "    #     bb = bb * ext\n",
    "    bb = bb(wavelength)/(const.R_sun / const.kpc) ** 2  # undo synphot normalization (but leave the pi factor from integration over half a sphere)\n",
    "    bb = convert_flux(wavelength, bb, 'flam')  # [flam] = [erg s^-1 cm^-2 A^-1]\n",
    "    bb = bb.to(u.erg/u.s/u.cm**2/u.angstrom)  # express in normal astropy units\n",
    "    return bb\n",
    "\n",
    "\n",
    "def mlogg2radius(m, logg):\n",
    "    g = 10**logg*u.cm/u.s**2\n",
    "    r = np.sqrt(const.G*m/g)\n",
    "    return r.to(u.Rsun).value\n",
    "\n",
    "\n",
    "def calc_synth_phot(wavelength, flux, bandpass):\n",
    "    dlambda = np.diff(wavelength)\n",
    "    dlambda = np.concatenate([dlambda, np.array([dlambda[-1]])])\n",
    "\n",
    "    # assuming a photon-counting device\n",
    "    phot = np.sum(dlambda*bandpass*wavelength*flux)/np.sum(dlambda*bandpass*wavelength)\n",
    "    \n",
    "    return phot\n",
    "\n",
    "\n",
    "amrf = lambda q, S : q/(1+q)**(2/3)*(1 - S*(1+q)/(q*(1+S)))\n",
    "\n",
    "gaia_passband = ascii.read('../data/other/passband.dat', names=[\"wl\", \"gPb\", \"gPbError\", \"bpPb\", \"bpPbError\", \"rpPb\", \"rpPbError\"])\n",
    "\n",
    "# replace missing values with NaNs\n",
    "for col in gaia_passband.itercols():\n",
    "    col[col == 99.99] = 0\n",
    "    \n",
    "gaia_passband['wl'] *= 10  # [A]\n",
    "\n",
    "# ---------- AMRF -------------------\n",
    "\n",
    "limiting_curves = Table.read('../data/other/AMRF_limiting_curves.fits')\n",
    "# Retrieve the conservative limiting AMRF values for some primary mass\n",
    "# --------------\n",
    "def Atr(m1):\n",
    "    j = np.argmin(np.abs(m1 - limiting_curves['m1'].data))\n",
    "    return limiting_curves['Atr'][j]\n",
    "def Ams(m1):\n",
    "    j = np.argmin(np.abs(m1 - limiting_curves['m1'].data))\n",
    "    return limiting_curves['Ams'][j]\n",
    "\n",
    "# =============================================================================\n",
    "#                Auxil routines to obtain the covariance matrix\n",
    "# =============================================================================\n",
    "\n",
    "# 1) get the list of parameters from the solution type\n",
    "def get_par_list(solution_type=None):\n",
    "    if (solution_type is None) or (solution_type=='Orbital'):\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'eccentricity', 'period', 't_periastron')\n",
    "\n",
    "    elif (solution_type=='OrbitalAlternative') or (solution_type=='OrbitalAlternativeValidated') \\\n",
    "            or (solution_type=='OrbitalTargetedSearch') or (solution_type=='OrbitalTargetedSearchValidated'):\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'period', 'eccentricity', 't_periastron')\n",
    "\n",
    "    elif solution_type=='AstroSpectroSB1':\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'c_thiele_innes', 'h_thiele_innes', 'center_of_mass_velocity',\n",
    "                'eccentricity', 'period', 't_periastron')\n",
    "\n",
    "\n",
    "# 2) Get the order of parameters in the covariance matrix, for a given bit index.\n",
    "def bit_index_map(bit_index):\n",
    "    if bit_index==8191:\n",
    "        return ['ra','dec','parallax','pmra','pmdec','A','B','F','G', 'e','P', 'T']\n",
    "    elif bit_index==8179:\n",
    "        return ['ra','dec','parallax','pmra','pmdec','A','B','F','P', 'T']\n",
    "    elif bit_index==65535:\n",
    "        return ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'A', 'B', 'F', 'G', 'C', 'H', 'gamma','e', 'P', 'T']\n",
    "    elif bit_index==65435:\n",
    "        return ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'A', 'B', 'F', 'H', 'gamma', 'P', 'T']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# 3) Generate the correlation matrix\n",
    "def make_corr_matrix(input_table, pars=None):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    input_table nss_two_body_orbit table.\n",
    "    pars : list\n",
    "            list of parameters for the corresponding solution of the desired\n",
    "              target, in the same order as they appear in the Gaia table.\n",
    "      \"\"\"\n",
    "    if pars is None:\n",
    "        pars = get_par_list()\n",
    "\n",
    "    # read the correlation vector\n",
    "    s1 = input_table['corr_vec'].replace('\\n','')   \n",
    "    s1 = s1.replace(' ',',')\n",
    "    s1 = s1.replace('--','0')\n",
    "    corr_vec = list(json.loads(s1))\n",
    "    # set the number of parameters in the table\n",
    "    n_pars = len(pars)\n",
    "    # define the correlation matrix.\n",
    "    corr_mat = np.ones([n_pars, n_pars], dtype=float)\n",
    "\n",
    "    # Read the matrix (lower triangle)\n",
    "    ind = 0\n",
    "    for i in range(n_pars):\n",
    "        for j in range(i):\n",
    "            corr_mat[j][i] = corr_vec[ind]\n",
    "            corr_mat[i][j] = corr_vec[ind]\n",
    "            ind += 1\n",
    "\n",
    "    return corr_mat\n",
    "\n",
    "\n",
    "# 4) Get the NSS data \n",
    "def get_nss_data(input_table, source_id):\n",
    "\n",
    "    target_idx = np.argwhere(input_table['source_id'] == source_id)[0][0]\n",
    "    pars = get_par_list(input_table['nss_solution_type'][target_idx])\n",
    "    corr_mat = make_corr_matrix(input_table[target_idx], pars=pars)\n",
    "\n",
    "    mu, std = np.zeros(len(pars)), np.zeros(len(pars))\n",
    "    for i, par in enumerate(pars):\n",
    "        try:\n",
    "            mu[i] = input_table[par][target_idx]\n",
    "            std[i] = input_table[par + '_error'][target_idx]\n",
    "        except KeyError:\n",
    "            mu[i], std[i] = np.nan, np.nan\n",
    "\n",
    "    nan_idxs = np.argwhere(np.isnan(corr_mat))\n",
    "    corr_mat[nan_idxs[:, 0], nan_idxs[:, 1]] = 0.0\n",
    "\n",
    "    return mu, std, corr_mat\n",
    "\n",
    "def multivar_sample(mu, sigma, corr, n):\n",
    "    cov = corr*(sigma[:, None] * sigma[None, :])\n",
    "    # l = spla.cholesky(cov)\n",
    "    # z = np.random.normal(size=(n, mu.shape[0]))\n",
    "    # return z.dot(l) + mu\n",
    "    return np.random.multivariate_normal(mu, cov, size=n)\n",
    "\n",
    "# =============================================================================\n",
    "#                      calc parameters.\n",
    "# =============================================================================\n",
    "# Here we calculate the AMRF, qmin, etc, assuming that the mass of the luminous star \n",
    "# is exactly one solar mass. This is just for the red-clump stars...\n",
    "def calc_AMRF(par_in, par_in_errors, corr_matrix, m1, bit_index=8191):\n",
    "    \"\"\"\n",
    "    For the given set of orbital parameters by Gaia, this function calculates\n",
    "    the standard geometrical elements (a, omega, Omega, and i). If the error\n",
    "    estimates and covariance matrix are prodived, the error estimates on the\n",
    "    calculated parameters are returned as well.\n",
    "\n",
    "    Input: thiele_innes: Thiele Innes parameters [A,B,F,G] in milli-arcsec\n",
    "           thiele_innes_errors : Corresponding errors.\n",
    "           corr_matrix : Corresponding  4X4 correlation matrix.\n",
    "\n",
    "  Output: class-III probability via monte carlo\n",
    "    \"\"\"\n",
    "    # Read the coefficients and assign the correlation matrix.\n",
    "    # Create correlated quantities. If the error is nan we assume 1e-6...\n",
    "    par_in_errors[np.isnan(par_in_errors)] = 1e-6\n",
    "    par_list = correlated_values_norm([(par_in[i], par_in_errors[i]) for i in np.arange(len(par_in))], corr_matrix)\n",
    "    key_list = bit_index_map(bit_index)\n",
    "\n",
    "    par = {key_list[i]: par_list[i] for i in np.arange(len(key_list))}\n",
    "    par['mass'] = m1\n",
    "\n",
    "    # Add the G Thiele-Innes parameter if needed.\n",
    "    if (bit_index == 8179) | (bit_index == 65435):\n",
    "        G = -par['A']*par['F']/par['B']\n",
    "    else:\n",
    "        G = par['G']\n",
    "\n",
    "    # This in an intermediate step in the formulae...\n",
    "    p = (par['A'] ** 2 + par['B'] ** 2 + G ** 2 + par['F'] ** 2) / 2.\n",
    "    q = par['A'] * G - par['B'] * par['F']\n",
    "\n",
    "    # Calculate the angular semimajor axis (already in mas)\n",
    "    a_mas = unp.sqrt(p + unp.sqrt(p ** 2 - q ** 2))\n",
    "\n",
    "    # Calculate the inclination and convert from radians to degrees\n",
    "    i_deg = unp.arccos(q / (a_mas ** 2.)) * (180 / np.pi)\n",
    "    \n",
    "    try:\n",
    "        if par.get(\"d\") is not None:\n",
    "            K_kms = 4.74372*unp.sqrt(par['C'] ** 2 + par['H'] ** 2)*(2*np.pi)/(par['P']/ 365.25)/np.sqrt(1-par['e']**2)\n",
    "            acc   = 2*K_kms/par['P']\n",
    "        else:\n",
    "            K_kms = 4.74372*unp.sqrt(par['C'] ** 2 + par['H'] ** 2)*(2*np.pi)/(par['P']/ 365.25)\n",
    "            acc   = K_kms/par['P']/4\n",
    "    except:\n",
    "        K_kms = ufloat(999, 999) \n",
    "        acc   = ufloat(999,999)\n",
    "\n",
    "    # Calculate the AMRF\n",
    "    try:\n",
    "        AMRF = a_mas / par['parallax'] * par['mass'] ** (-1 / 3)  * (par['P']/ 365.25) ** (-2 / 3)\n",
    "\n",
    "        # Calculate AMRF q\n",
    "        y = AMRF ** 3\n",
    "        h = (y/2 + (y**2)/3 + (y**3)/27\n",
    "             + np.sqrt(3)/18*y*unp.sqrt(4*y+27))**(1/3)\n",
    "        q = h + (2*y/3 + (y**2)/9)/h + y/3\n",
    "    except:\n",
    "        AMRF = ufloat(np.nan, np.inf) \n",
    "        q    = ufloat(np.nan, np.inf) \n",
    "        \n",
    "    # Extract expectancy values and standard deviations\n",
    "    pars = np.array([unp.nominal_values(AMRF),\n",
    "                         unp.nominal_values(q),\n",
    "                         unp.nominal_values(a_mas),\n",
    "                         unp.nominal_values(i_deg),\n",
    "                         unp.nominal_values(K_kms),\n",
    "                         unp.nominal_values(acc)])\n",
    "\n",
    "    pars_error = np.array([unp.std_devs(AMRF),\n",
    "                               unp.std_devs(q),\n",
    "                               unp.std_devs(a_mas),\n",
    "                               unp.std_devs(i_deg),\n",
    "                               unp.std_devs(K_kms),\n",
    "                               unp.std_devs(acc)])\n",
    "\n",
    "    return pars, pars_error\n",
    "\n",
    "def class_probs(Atr,Ams,par_in, par_in_errors,\n",
    "                  m1, m1_error, corr_matrix, bit_index=8191, n=1e2, factor=1.0):\n",
    "    \"\"\"\n",
    "    For the given set of orbital parameters by Gaia, this function calculates\n",
    "    the standard geometrical elements (a, omega, Omega, and i). If the error\n",
    "    estimates and covariance matrix are prodived, the error estimates on the\n",
    "    calculated parameters are returned as well.\n",
    "\n",
    "    Input: thiele_innes: Thiele Innes parameters [A,B,F,G] in milli-arcsec\n",
    "           thiele_innes_errors : Corresponding errors.\n",
    "           corr_matrix : Corresponding  4X4 correlation matrix.\n",
    "\n",
    "  Output: physical and geometrical parameters\n",
    "    \"\"\"\n",
    "    r_3 = 0\n",
    "    r_2 = 0\n",
    "    par_in_errors[np.isnan(par_in_errors)] = 1e-6\n",
    "    vecs = multivar_sample(par_in, par_in_errors, corr_matrix, int(n))\n",
    "    key_list = bit_index_map(bit_index)\n",
    "\n",
    "    for vec in vecs:\n",
    "        par = {key_list[i]: vec[i] for i in np.arange(len(key_list))}\n",
    "        par['mass'] = m1_error*np.random.randn() + m1\n",
    "\n",
    "        # Add the G Thiele-Innes parameter if needed.\n",
    "        if (bit_index == 8179) | (bit_index == 65435):\n",
    "            par['G'] = -par['A'] * par['F'] / par['B']\n",
    "\n",
    "        # This in an intermediate step in the formulae...\n",
    "        p = (par['A'] ** 2 + par['B'] ** 2 + par['G'] ** 2 + par['F'] ** 2) / 2.\n",
    "        q = par['A'] * par['G'] - par['B'] * par['F']\n",
    "\n",
    "        # Calculate the semimajor axis (already in mas)\n",
    "        a_mas = np.sqrt(p + np.sqrt(p ** 2 - q ** 2))\n",
    "\n",
    "        # Calculate the AMRF\n",
    "        AMRF = a_mas / par['parallax'] * par['mass'] ** (-1 / 3) * (par['P']/ 365.25) ** (-2 / 3)\n",
    "\n",
    "        try:\n",
    "            if 0 < par['e'] < 1:\n",
    "                if AMRF > Atr * factor:\n",
    "                    r_3 += 1\n",
    "                elif Ams * factor < AMRF < Atr * factor:\n",
    "                    r_2 += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return (n-r_2-r_3)/n, r_2/n, r_3/n #(no_detections + detections)\n",
    "\n",
    "# =============================================================================\n",
    "#                       Read the data from the NSS table\n",
    "# =============================================================================\n",
    "def add_astrometric_parameters(data):\n",
    "    # Here we only calculate (but don't assign class 3 probabilities!\n",
    "    # We get the data table, arrange the arrays, calculate the astrometric\n",
    "    # coefficients and plug it all back into the table.\n",
    "\n",
    "    # Initialize the arrays\n",
    "    # ---------------------\n",
    "    # We need to calculate the AMRF, mass ratio, angular semi-major axis, orbtial inclination\n",
    "    # and order-of-magnitude acceleration. We also want their uncertainties.\n",
    "    count_good, count_bad = 0, 0\n",
    "    A, q, a_mas, i_deg, K_kms, acc, P1, P2, P3 = np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan), np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan), np.full(len(data), np.nan), np.full(len(data), np.nan) \n",
    "\n",
    "    Ae, qe, a_mase, i_dege, K_kmse, acce = np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                                   np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                                   np.full(len(data), np.nan),  np.full(len(data), np.nan)\n",
    "\n",
    "    # Now go one by one and calculate the AMRF\n",
    "    # ----------------------------------------\n",
    "    for idx in tqdm(range(len(data['source_id']))):\n",
    "        if data[idx]['nss_solution_type'] not in ['Orbital','AstroSpectroSB1']:\n",
    "            continue\n",
    "        # Read the NSS solutin values.\n",
    "        sid = data['source_id'][idx]\n",
    "        mu, std, corr_mat = get_nss_data(data, sid)\n",
    "        m1 = data['m1'][idx]\n",
    "        m1_error = data['m1_err'][idx]\n",
    "        if np.ma.is_masked(m1):\n",
    "            print(idx)\n",
    "            pass\n",
    "        Ams_idx = data['Ams'][idx]\n",
    "        Atr_idx = data['Atr'][idx]\n",
    "        if np.ma.is_masked(Ams_idx) | np.ma.is_masked(Atr_idx):\n",
    "            Ams_idx = Ams(m1)\n",
    "            Atr_idx = Atr(m1)\n",
    "            \n",
    "        vals, stds = calc_AMRF(mu, std, corr_mat, m1, bit_index=data['bit_index'][idx])\n",
    "        p1, p2, p3 = class_probs(data['Atr'][idx],data['Ams'][idx],mu, std, m1, m1_error, corr_mat, bit_index=data['bit_index'][idx], n = 1e4)\n",
    "        try:\n",
    "            A[idx], Ae[idx]  = vals[0], stds[0]\n",
    "            q[idx], qe[idx]  = vals[1], stds[1]\n",
    "            a_mas[idx], a_mase[idx]  = vals[2], stds[2]\n",
    "            i_deg[idx], i_dege[idx]  = vals[3], stds[3]\n",
    "            K_kms[idx], K_kmse[idx]  = vals[4], stds[4]\n",
    "            acc[idx],   acce[idx]    = vals[5], stds[5]\n",
    "            P1[idx], P2[idx], P3[idx] = p1, p2, p3\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Store it all back in the original data structure.\n",
    "    data['AMRF'], data['AMRF_error'] = A, Ae\n",
    "    data['AMRF_q'], data['AMRF_q_error'] = q, qe\n",
    "    data['a_mas'], data['a_mas_error'] = a_mas, a_mase\n",
    "    data['i_deg'], data['i_deg_error'] = i_deg, i_dege\n",
    "    data['K_kms'], data['K_kms_error'] = K_kms, K_kmse\n",
    "    data['acc_kmsd'], data['acc_kmsd_error'] = acc, acce\n",
    "    data['classI_prob'] = P1\n",
    "    data['classII_prob'] = P2\n",
    "    data['classIII_prob'] = P3\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [17:53<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calc AMRF limits\n",
    "\n",
    "sources['Ams'] = np.full(len(sources),np.nan)\n",
    "sources['Atr'] = np.full(len(sources),np.nan)\n",
    "\n",
    "## calculating for all sources\n",
    "\n",
    "stage_min = 0  # pre-main sequence\n",
    "stage_max = 5  # red giant branch\n",
    "mass_min = 0  # [Msun]\n",
    "mass_max = 8  # [Msun]\n",
    "\n",
    "m2_vec = np.arange(0.1, 10, 0.1)\n",
    "\n",
    "wavelength = gaia_passband['wl'].value  # [A]\n",
    "\n",
    "Gflux1 = np.zeros(len(sources))\n",
    "Gflux2 = np.zeros((len(sources), len(m2_vec)))\n",
    "Ag1 = np.zeros(len(sources))\n",
    "Ag2 = np.zeros((len(sources), len(m2_vec)))\n",
    "q = np.zeros((len(sources), len(m2_vec)))\n",
    "# PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "PARSEC_path = '../OCFit/gaiaDR2/grids/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "for i in tqdm(range(len(sources))):\n",
    "    idx = sources['idx'][i]\n",
    "    if sources[i]['nss_solution_type'] not in ['Orbital','AstroSpectroSB1']:\n",
    "        continue\n",
    "    mh = sources['[Fe/H]'][i]\n",
    "    age = sources['age'][i]\n",
    "    ebv = sources['Av'][i]/3.1\n",
    "    m1 = sources['m1'][i]\n",
    "    \n",
    "    try:\n",
    "        track_idx = get_track_idx(mh,age)[-1]\n",
    "        tracks = models[track_idx].copy()\n",
    "        tracks.sort('Mini')\n",
    "        idx = np.argmin(np.abs(tracks['Mass'] - m1))\n",
    "\n",
    "        teff1 = 10**tracks['logTe'][idx]  # [K]\n",
    "        logg1 = tracks['logg'][idx]\n",
    "        r1 = mlogg2radius(m1*u.Msun, logg1)  # [Rsun]\n",
    "        flux1 = blackbody(teff1, wavelength)*4*np.pi*r1**2\n",
    "        Gflux1[i] = calc_synth_phot(wavelength, flux1, gaia_passband['gPb'].value).value\n",
    "        Ag1[i],_ = extinction.get_AG_EBPRP(3.1*ebv,0,teff1)\n",
    "        q[i, :] = m2_vec/m1  # mass ratio\n",
    "\n",
    "        for j in range(len(m2_vec)):\n",
    "            m2 = m2_vec[j]\n",
    "            idx = np.argmin(np.abs(tracks['Mass'] - m2))\n",
    "            teff2 = 10**tracks['logTe'][idx]  # [K]\n",
    "            logg2 = tracks['logg'][idx]\n",
    "            r2 = mlogg2radius(m2*u.Msun, logg2)  # [Rsun]\n",
    "            flux2 = blackbody(teff2, wavelength, ebv=ebv)*4*np.pi*r2**2\n",
    "            Gflux2[i,j] = calc_synth_phot(wavelength, flux2, gaia_passband['gPb'].value).value\n",
    "            Ag2[i,j],_ = extinction.get_AG_EBPRP(3.1*ebv,0,teff2)\n",
    "\n",
    "        Sms = Gflux2[i,:]/Gflux1[i]*10**(-0.4*(Ag2[i,:]-Ag1[i]))\n",
    "        Ams = amrf(q[i, :], Sms)\n",
    "        valid_idx = Sms < 1\n",
    "        Ams = np.max(Ams[valid_idx]) \n",
    "        sources['Ams'][i] = Ams\n",
    "        Str = 2*Gflux2[i,:]/Gflux1[i]\n",
    "        Atr = amrf(2*q[i, :], Str)\n",
    "        valid_idx = Str < 1\n",
    "        Atr = np.max(Atr[valid_idx])\n",
    "        sources['Atr'][i] = Atr\n",
    "    except:\n",
    "        print(f'i = {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:24<00:00, 11.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calc AMRF and class probabilities\n",
    "new_sources = add_astrometric_parameters(sources)\n",
    "new_sources['m2'] = new_sources['m1'] * new_sources['AMRF_q']\n",
    "new_sources['m2_err'] = ((new_sources['m1_err'] * new_sources['AMRF_q'])**2 + (new_sources['m1'] * new_sources['AMRF_q_error'])**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "sources = new_sources\n",
    "cut1 = sources['significance'] > 158 * sources['period'].data**(-0.5)\n",
    "cut2 = (sources['parallax_over_error'] > 20,000 *sources['period']**(-1))[0]\n",
    "cut3 = sources['eccentricity_error'] < 0.079 * np.log(sources['period'].data) - 0.244\n",
    "\n",
    "cut = cut1 & cut2 & cut3\n",
    "\n",
    "sources = sources[cut]\n",
    "\n",
    "# sources.write('../table_B.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "cut1 = sources['m1'] / sources['m1_err'] > 50\n",
    "cut2 = sources['classI_prob'] < 0.1\n",
    "cut3 = sources['m2'] <= 1.4\n",
    "\n",
    "cut = cut1 & cut2 & cut3\n",
    "\n",
    "# sources[cut].write('../table_C.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "tbl = Table.read('../table_C.fits')\n",
    "\n",
    "for i in range(len(tbl)):\n",
    "    idx = tbl['idx'][i]\n",
    "    cluster = tbl['cluster'][i]\n",
    "    # cmd_fig_name = f'../img/cmd/{idx}_{cluster}.png'\n",
    "    # cmd_new_name = f'../img/cmd_tableC/{idx}_{cluster}.png'\n",
    "    # shutil.move(cmd_fig_name, cmd_new_name)\n",
    "    interp_fig_name = f'../img/mass_interp/{idx}_{cluster}.png'\n",
    "    interp_new_name = f'../img/mass_interpC/{idx}_{cluster}.png'\n",
    "    shutil.move(interp_fig_name, interp_new_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooling time and progenitor mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_life vs m from evolutionary tracks/M_i from t_cluster, t_cool\n",
    "from os import walk,path\n",
    "\n",
    "def get_zarr(): # metallicities of parsec evol tracks\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = []\n",
    "    for n in filenames:\n",
    "        z = n.split('Y')[0]\n",
    "        z_arr.append(float(z[1:]))\n",
    "    return np.unique(z_arr)\n",
    "\n",
    "def get_mdict(mh): # masses of evol tracks for a given metallicity\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = get_zarr()\n",
    "    z = 0.01524 * 10**mh\n",
    "    z_nearest = z_arr[np.argmin(np.abs(z_arr - z))]\n",
    "    z_str = 'Z'+f'{z_nearest}'\n",
    "\n",
    "    m_arr = []\n",
    "    s_arr = []\n",
    "    for n in filenames:\n",
    "        if z_str in n:\n",
    "            m = n.split('M')[1].removesuffix('.DAT')\n",
    "            if m.endswith('.HB'):\n",
    "                m = m.removesuffix('.HB')\n",
    "            m_arr.append(float(m))\n",
    "            s_arr.append(m)\n",
    "    tbl = Table({'mass':m_arr,'str':s_arr})\n",
    "    # tbl = tbl[tbl['mass'] <= 10]\n",
    "    return tbl\n",
    "\n",
    "def get_marr(mh): # masses of evol tracks for a given metallicity\n",
    "    return np.unique(get_mdict(mh)['mass'])\n",
    "\n",
    "def get_lifetime(mass,mh): # MS lifetime for given mass (>0.8) and metallicity\n",
    "    ## lifetime for m>0.8\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = get_zarr()\n",
    "\n",
    "    z = 0.01524 * 10**mh\n",
    "    z_nearest = z_arr[np.argmin(np.abs(z_arr - z))]\n",
    "    m_dict = get_mdict(mh)\n",
    "    mass_str = m_dict[m_dict['mass'] == mass]['str']\n",
    "    z_str = 'Z'+f'{z_nearest}'\n",
    "\n",
    "    trackpath = ''\n",
    "    for n in filenames:\n",
    "        m1 = n.split('M')[1].removesuffix('.DAT')\n",
    "        if m1.endswith('HB'):\n",
    "            continue\n",
    "        for m2 in mass_str:\n",
    "            if m1 == m2 and z_str in n:\n",
    "                trackpath = path.join(basedir,n)\n",
    "                break\n",
    "\n",
    "    if trackpath == '':\n",
    "        print(f'No track found for '+m2+' '+z_str)\n",
    "\n",
    "    trck = Table(np.genfromtxt(trackpath,names=True,dtype=None))\n",
    "    return trck[trck['PHASE'] == 6]['AGE'][0]\n",
    "\n",
    "def lifetime_vs_mass(mh): # MS lifetime for different masses (>0.8), fixed metallicity\n",
    "    m_arr = get_marr(mh)\n",
    "    m_arr = m_arr[m_arr > 0.8]\n",
    "    t_arr = []\n",
    "    for m in m_arr:\n",
    "        t_arr.append(get_lifetime(m,mh))\n",
    "    return m_arr,t_arr\n",
    "\n",
    "def create_lifetime_vs_mass_tables(): # create csv files for MS lifetime vs mass for different metallicities\n",
    "    z_arr = get_zarr()\n",
    "    mh_arr = np.log10(z_arr/0.01524)\n",
    "\n",
    "    for mh in mh_arr:\n",
    "        m_arr,t_arr = lifetime_vs_mass(mh)\n",
    "        tbl = Table({'mass':m_arr,'lifetime':t_arr})\n",
    "        tbl.write(path.join('..','data','MS_lifetime','parsec_V1.2S',f'lifetime_vs_mass{mh:.2f}.csv'),overwrite=True)\n",
    "\n",
    "    return ''\n",
    "\n",
    "def get_initial_mass(age,mh): # from MS lifetime and metallicity, get progenitor mass (invert get_lifetime)\n",
    "    ## age in Myr\n",
    "    ## returns mass in solar mass\n",
    "    basedir = path.join('..','data','MS_lifetime','parsec_V1.2S')\n",
    "    z_arr = get_zarr()\n",
    "    mh_arr = np.log10(z_arr/0.01524)\n",
    "    mh = mh_arr[np.argmin(np.abs(mh_arr - mh))]\n",
    "    filename = f'lifetime_vs_mass{mh:.2f}.csv'   \n",
    "    df = pd.read_csv(path.join(basedir,filename))\n",
    "    df.sort_values('lifetime',inplace=True)\n",
    "    return np.interp(age*1e6,df['lifetime'],df['mass'])\n",
    "    \n",
    "def get_cooling_age(teff,m,core='CO',atm='H'): # WD cooling age for given teff, mass, core, atm\n",
    "    if core =='He':\n",
    "        model = np.genfromtxt('../data/WD_models/He_wd.dat',names=True,dtype=None)\n",
    "    elif core == 'CO':\n",
    "        if atm == 'H':\n",
    "            model = np.genfromtxt('../data/WD_models/CO_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            model = np.genfromtxt('../data/WD_models/CO_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    elif core == 'ONe':\n",
    "        if atm == 'H':\n",
    "            model = np.genfromtxt('../data/WD_models/ONe_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            model = np.genfromtxt('../data/WD_models/ONe_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    # logg = logg_from_MR_relation(teff,m,core,atm)\n",
    "    interp = LinearNDInterpolator(np.array([model['Teff'],model['Mass']]).T,model['Age'])\n",
    "    age = interp([teff,m])[0]\n",
    "    if np.isnan(age):\n",
    "        return np.nan\n",
    "    return age\n",
    "\n",
    "def get_cooling_temp(age,m,core='CO',atm='H'): # WD cooling temp for given age, mass, core, atm\n",
    "    if core =='He':\n",
    "        model = np.genfromtxt('../data/WD_models/He_wd.dat',names=True,dtype=None)\n",
    "    elif core == 'CO':\n",
    "        if atm == 'H':\n",
    "            model = np.genfromtxt('../data/WD_models/CO_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            model = np.genfromtxt('../data/WD_models/CO_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    elif core == 'ONe':\n",
    "        if atm == 'H':\n",
    "            model = np.genfromtxt('../data/WD_models/ONe_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            model = np.genfromtxt('../data/WD_models/ONe_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    interp = LinearNDInterpolator(np.array([model['Age'],model['Mass']]).T,model['Teff'])\n",
    "    teff_init = interp([age,m])[0]\n",
    "    teff_vec = np.linspace(teff_init+10000,teff_init-10000,20)\n",
    "    age_vec = [get_cooling_age(teff,m,core,atm) for teff in teff_vec]\n",
    "    teff = np.interp(age,age_vec,teff_vec)\n",
    "    return teff\n",
    "\n",
    "def logg_from_MR_relation(teff,m,core='CO',atm='H'):\n",
    "    ## teff in K, m in solar masses\n",
    "    ## returns log_g in cm/s^2\n",
    "    if core == 'He':\n",
    "        wd = np.genfromtxt('../data/WD_models/He_wd.dat',names=True,dtype=None)\n",
    "    elif core == 'CO':\n",
    "        if atm == 'H':\n",
    "            wd = np.genfromtxt('../data/WD_models/CO_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            wd = np.genfromtxt('../data/WD_models/CO_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    elif core == 'ONe':\n",
    "        if atm == 'H':\n",
    "            wd = np.genfromtxt('../data/WD_models/ONe_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            wd = np.genfromtxt('../data/WD_models/ONe_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    interp = LinearNDInterpolator(np.array([wd['Teff'],wd['Mass']]).T,wd['log_g'])\n",
    "    logg = interp([teff,m])[0]\n",
    "    return logg\n",
    "\n",
    "def logg_from_agecool_m(age,m,core='CO',atm='H'):\n",
    "    ## teff in K, m in solar masses\n",
    "    ## returns log_g in cm/s^2\n",
    "    if core == 'He':\n",
    "        wd = np.genfromtxt('../data/WD_models/He_wd.dat',names=True,dtype=None)\n",
    "    elif core == 'CO':\n",
    "        if atm == 'H':\n",
    "            wd = np.genfromtxt('../data/WD_models/CO_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            wd = np.genfromtxt('../data/WD_models/CO_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    elif core == 'ONe':\n",
    "        if atm == 'H':\n",
    "            wd = np.genfromtxt('../data/WD_models/ONe_DA.dat',names=True,dtype=None)\n",
    "        elif atm == 'He':\n",
    "            wd = np.genfromtxt('../data/WD_models/ONe_DB.dat',names=True,dtype=None)\n",
    "        else:\n",
    "            print('atm either H or He')\n",
    "            return None\n",
    "    interp = LinearNDInterpolator(np.array([wd['Age'],wd['Mass']]).T,wd['log_g'])\n",
    "    logg = interp([age,m])[0]\n",
    "    return logg\n",
    "\n",
    "def get_temp_from_mag(m,mag,parallax,av,band='NUV',atm='H'): # for apparent UV mag/WD mass/parallax/av, get WD temp\n",
    "    if band not in ['NUV','FUV']:\n",
    "        print('band must be either NUV or FUV')\n",
    "        return None\n",
    "    if atm == 'H':\n",
    "        model = np.genfromtxt(f'../data/WD_models/CO_DA.dat',names=True,dtype=None)\n",
    "    elif atm == 'He':\n",
    "        model = np.genfromtxt(f'../data/WD_models/CO_DB.dat',names=True,dtype=None)\n",
    "    interp = LinearNDInterpolator(np.array([model['Mass'],model[band]]).T,model['Teff'])\n",
    "    abs_mag = mag - 5*np.log10(1000/parallax) + 5\n",
    "    teff_init = interp([m,abs_mag])[0] # rough temperature for dereddening the observed mag\n",
    "    if np.isnan(teff_init):\n",
    "        interp = NearestNDInterpolator(np.array([model['Mass'],model[band]]).T,model['Teff'])\n",
    "        teff_init = interp([m,abs_mag])[0] # rough temperature for dereddening the observed mag\n",
    "    ANUV,_ = extinction.get_Galex_extinction(av,0,teff_init)\n",
    "    abs_mag = abs_mag - ANUV # dereddened mag\n",
    "    teff = interp([m,abs_mag])[0] # final temperature\n",
    "    if np.isnan(teff):\n",
    "        interp = NearestNDInterpolator(np.array([model['Mass'],model[band]]).T,model['Teff'])\n",
    "        teff = interp([m,abs_mag])[0]\n",
    "    return int(teff)\n",
    "\n",
    "def add_temperature_limits_to_table(tbl): # Use cluster age and observed UV to constrain teff2\n",
    "\n",
    "    tbl['teff2_max'] = np.full(len(tbl),np.nan)\n",
    "    tbl['teff2_min'] = np.full(len(tbl),np.nan)\n",
    "\n",
    "    for idx in tbl['idx']:\n",
    "        j = np.argwhere(tbl['idx'] == idx)[0][0]\n",
    "        age = tbl['age'][j]\n",
    "        av = tbl['Av'][j]\n",
    "        mh = tbl['[Fe/H]'][j]\n",
    "        parallax = tbl['parallax'][j]\n",
    "        m2 = tbl['m2'][j]\n",
    "        nuv_mag = tbl['nuv_mag'][j]\n",
    "        fuv_mag = tbl['fuv_mag'][j]\n",
    "        \n",
    "        if m2<0.45: core = 'He'\n",
    "        elif m2<1.1: core = 'CO'\n",
    "        else: core = 'ONe'\n",
    "\n",
    "        # if UV photometry exists, UV excess can give strict limits on Teff2\n",
    "        # if no UV excess, we can still put upper bound on Teff2: the highest possible Teff2 must provide less than 10% of the observed UV flux, or else there'd be excess\n",
    "        if not np.ma.is_masked(fuv_mag): \n",
    "            tbl[j]['teff2_max'] = get_temp_from_mag(m2,fuv_mag+2.5,parallax,av,band='FUV',atm='H')\n",
    "        elif not np.ma.is_masked(nuv_mag): \n",
    "            tbl[j]['teff2_max'] = get_temp_from_mag(m2,nuv_mag+2.5,parallax,av,band='NUV',atm='H')\n",
    "        tbl[j]['teff2_min'] = get_cooling_temp(age,m2,core,'H')\n",
    "\n",
    "    tbl['teff2'] = np.full(len(tbl),np.nan)\n",
    "    excess = [53,174,175,236,249,281,283]\n",
    "    for idx in excess:\n",
    "        j = np.argwhere(tbl['idx'] == idx)[0][0]\n",
    "        t_best, t_min, t_max = get_fit_results(idx)\n",
    "        tbl[j]['teff2'] = t_best\n",
    "        tbl[j]['teff2_min'] = t_min\n",
    "        tbl[j]['teff2_max'] = t_max\n",
    "\n",
    "def get_fit_results(idx): # get median and 16th, 84th percentiles of teff2 chain\n",
    "    filepath = f'../data/chains/chains_{idx}.csv'\n",
    "    chain = Table.read(filepath)['teff2']\n",
    "    return np.median(chain),np.percentile(chain,16),np.percentile(chain,84)\n",
    "\n",
    "def sample_teff2_posterior(idx,n=1e4,tclstr=None): # sample teff2 from posterior using rejection sampling\n",
    "    filepath = f'../data/chains/chains_{idx}.csv'\n",
    "    chain = Table.read(filepath)['teff2']\n",
    "    counts,bins = np.histogram(chain,bins=100)\n",
    "    tmax = bins[-1]\n",
    "    tmin = bins[0]\n",
    "    teff2 = []\n",
    "    if tclstr is not None:\n",
    "        tmin = np.max([tmin,tclstr])\n",
    "    while len(teff2) < n:\n",
    "        t = np.random.uniform(tmin,tmax)\n",
    "        if np.random.uniform(0,1) < np.interp(t,bins[:-1],counts)/np.max(counts):\n",
    "            teff2.append(t)\n",
    "    return np.array(teff2)\n",
    "\n",
    "def sample_m_init_posterior(tbl,idx,n=1e4): # sample m_init from teff2 posterior, age, mh, m2 \n",
    "    j = np.argwhere(tbl['idx'] == idx)[0][0]\n",
    "    age, e_age = tbl[j]['age'],tbl[j]['e_age']\n",
    "    mh, e_mh = tbl[j]['[Fe/H]'],tbl[j]['e_[Fe/H]']\n",
    "    m2, m2_err = tbl[j]['m2'],tbl[j]['m2_err']\n",
    "\n",
    "    atm = 'H'\n",
    "    if m2<0.45: core = 'He'\n",
    "    elif m2<1.1: core = 'CO'\n",
    "    else: core = 'ONe'\n",
    "\n",
    "    # tclstr = get_cooling_temp(age,m2,core,atm)\n",
    "    teff2_vec = sample_teff2_posterior(idx,n=10*n)\n",
    "    age_vec = []\n",
    "    mh_vec = []\n",
    "    m2_vec = []\n",
    "    t2_vec = []\n",
    "    m_i_vec = []\n",
    "    k = 0\n",
    "    while (np.count_nonzero(~np.isnan(m_i_vec) & (np.array(m_i_vec) < 8)) < n):\n",
    "        age_vec.append(np.random.normal(age,e_age))\n",
    "        mh_vec.append(np.random.normal(mh,e_mh))\n",
    "        m2_vec.append(np.random.normal(m2,m2_err))\n",
    "\n",
    "        # t_ms_min = get_lifetime(8.0,mh_vec[-1])\n",
    "        # age_wd_max = age_vec[-1] - t_ms_min\n",
    "    \n",
    "        t2_vec.append(np.random.choice(teff2_vec))\n",
    "\n",
    "        age_wd = get_cooling_age(t2_vec[-1],m2_vec[-1],core,atm)\n",
    "        t_ms = age_vec[-1] - age_wd\n",
    "        if t_ms > 0:\n",
    "            m_i_vec.append(get_initial_mass(t_ms,mh_vec[-1]))\n",
    "        else:\n",
    "            m_i_vec.append(np.nan)\n",
    "    return Table({'m_i':m_i_vec,'age':age_vec,'[Fe/H]':mh_vec,'m2':m2_vec,'teff2':t2_vec})\n",
    "\n",
    "def weight_m_init_posterior(idx,n=1e4): # weight m_init chain using kroupa IMF\n",
    "    filepath = f'../data/chains/mchain_{idx}.csv'\n",
    "    chain_tbl = Table.read(filepath)\n",
    "    m_chain = chain_tbl['m_i']\n",
    "    age_chain = chain_tbl['age']\n",
    "    mh_chain = chain_tbl['[Fe/H]']\n",
    "    m2_chain = chain_tbl['m2']\n",
    "    teff2_chain = chain_tbl['teff2']\n",
    "\n",
    "    cut = ~np.isnan(m_chain) & (m_chain < 8)\n",
    "    m_chain = m_chain[cut]\n",
    "    age_chain = age_chain[cut]\n",
    "    mh_chain = mh_chain[cut]\n",
    "\n",
    "    n = len(m_chain)\n",
    "    m_chain_w, age_chain_w, mh_chain_w, m2_chain_w, teff2_chain_w = [],[],[],[],[]\n",
    "\n",
    "\n",
    "    kroupa = lambda m,m0: (m/m0)**(-2.7) # peak normalized to 1\n",
    "    while len(m_chain_w) < n:\n",
    "        i = np.random.randint(0,n)\n",
    "        m = m_chain[i]\n",
    "        age = age_chain[i]\n",
    "        mh = mh_chain[i]\n",
    "        m2 = m2_chain[i]\n",
    "        teff2 = teff2_chain[i]\n",
    "\n",
    "        m_min = get_initial_mass(age,mh) # to define kroupa lower cut-off.\n",
    "        p = np.random.random()\n",
    "        if p < kroupa(m,m_min) and m > m_min and m < 8: # rejection sampling on truncated kroupa IMF\n",
    "            m_chain_w.append(m)\n",
    "            age_chain_w.append(age)\n",
    "            mh_chain_w.append(mh)\n",
    "            m2_chain_w.append(m2)\n",
    "            teff2_chain_w.append(teff2)\n",
    "\n",
    "    return Table({'m_i':m_chain_w,'age':age_chain_w,'[Fe/H]':mh_chain_w,'m2':m2_chain_w,'teff2':teff2_chain_w})\n",
    "\n",
    "def sample_kroupa_uniform(m_min,m_max,n=1e4): # sample m from kroupa IMF with no prior\n",
    "    kroupa = lambda m,m0: (m/m0)**(-2.7) # peak normalized to 1\n",
    "    m_arr = []\n",
    "    while len(m_arr) < n:\n",
    "        m = np.random.uniform(m_min,m_max)\n",
    "        p = np.random.random()\n",
    "        if p < kroupa(m,m_min) and m > m_min and m < m_max: # rejection sampling on truncated kroupa IMF\n",
    "            m_arr.append(m)\n",
    "    return np.array(m_arr)\n",
    "\n",
    "def create_ifmr_tbl(tbl): # create m_i vs. m_f table, with all levels of bounds\n",
    "    ifmr = Table({'idx':tbl['idx'],'source_id':tbl['source_id'],'m2':tbl['m2'],'m_i_min1':np.full(len(tbl),np.nan),'m_i_max1':np.full(len(tbl),np.nan)})\n",
    "    for j in range(len(ifmr)): # Loose bounds\n",
    "        age = tbl[j]['age']\n",
    "        mh = tbl[j]['[Fe/H]']\n",
    "        \n",
    "        m_min = get_initial_mass(age,mh) # Heaviest MS star remaining in the cluster ~ Lightest possible progenitor\n",
    "    \n",
    "    ifmr['m_i_min2'] = np.full(len(ifmr),np.nan)\n",
    "    ifmr['m_i_max2'] = ifmr['m_i_max1']\n",
    "    add_temperature_limits_to_table(tbl)\n",
    "    uv = ~np.isnan(tbl['teff2_max'])\n",
    "    uv_excess = np.isin(tbl['idx'],[53,174,175,236,249,281,283])\n",
    "    no_excess = uv & ~uv_excess\n",
    "\n",
    "    for idx in tbl[no_excess]['idx']: # If no UV excess, use maximal teff2 to get minimal m_init\n",
    "        j = np.argwhere(tbl['idx'] == idx)[0][0]\n",
    "        k = np.argwhere(ifmr['idx']==idx)[0][0]\n",
    "        age = tbl[j]['age']\n",
    "        mh = tbl[j]['[Fe/H]']\n",
    "        m2 = tbl[j]['m2']\n",
    "        teff2_max = tbl[j]['teff2_max']\n",
    "        atm = 'H'\n",
    "\n",
    "        if m2<0.45: core = 'He'\n",
    "        elif m2<1.1: core = 'CO'\n",
    "        else: core = 'ONe'\n",
    "\n",
    "        age_wd_min = get_cooling_age(teff2_max,m2,core,atm)\n",
    "        t_ms_max = np.nanmin([age,age-age_wd_min]) # if didn't find agecool, use cluster age such that the bound remains unchanged\n",
    "        m_min = get_initial_mass(t_ms_max,mh)\n",
    "        if not np.isnan(m_min) and m_min >= ifmr[k]['m_i_min1']:\n",
    "            ifmr[k]['m_i_min2'] = m_min\n",
    "\n",
    "    \n",
    "    ifmr['m_i_min3'] = np.full(len(ifmr),np.nan)\n",
    "    ifmr['m_i_max3'] = np.full(len(ifmr),np.nan)\n",
    "    ifmr['m_i'] = np.full(len(ifmr),np.nan)\n",
    "    for idx in tbl[uv_excess]['idx']: # Use MCMC bounds on teff2 to get tighter bound on m_init including a best value\n",
    "        filepath = f'../data/chains/wmchain_{idx}.csv'\n",
    "        k = np.argwhere(ifmr['idx']==idx)[0][0]\n",
    "        if path.exists(filepath): # otherwise, leave it as nan\n",
    "            wmchain = Table.read(filepath)['m_i']\n",
    "            ifmr[k]['m_i_min3'] = np.percentile(wmchain,16)\n",
    "            ifmr[k]['m_i'] = np.percentile(wmchain,50)\n",
    "            ifmr[k]['m_i_max3'] = np.percentile(wmchain,84)\n",
    "    return ifmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "sources = Table.read('../table_C.fits')\n",
    "for idx in sources['idx']:\n",
    "    j = np.argwhere(sources['idx'] == idx)[0][0]\n",
    "    age_vec = np.random.normal(sources[j]['age'],sources[j]['e_age'],1000)\n",
    "    mh_vec = np.random.normal(sources[j]['[Fe/H]'],sources[j]['e_[Fe/H]'],1000)\n",
    "\n",
    "    kroupa_vec = []\n",
    "    for age,mh in zip(age_vec,mh_vec):\n",
    "        m_min = get_initial_mass(age,mh)\n",
    "        m_max = 8\n",
    "        if m_min > m_max:\n",
    "            continue\n",
    "        kroupa_vec.extend(sample_kroupa_uniform(m_min,m_max,n=100))\n",
    "    if len(kroupa_vec) > 0:\n",
    "        np.save(f'../data/chains/kroupa_{idx}.npy',np.array(kroupa_vec))\n",
    "        fig,ax = plt.subplots(dpi=300)\n",
    "\n",
    "        ax.hist(kroupa_vec,bins=50,density=True,histtype='step',color='k')\n",
    "        ax.axvline(np.percentile(kroupa_vec,16),color='r',label=f'16% = {np.percentile(kroupa_vec,16):.1f}$M_\\odot$',linestyle='--')\n",
    "        ax.axvline(np.percentile(kroupa_vec,50),color='b',label=f'50% = {np.percentile(kroupa_vec,50):.1f}$M_\\odot$',linestyle='--')\n",
    "        ax.axvline(np.percentile(kroupa_vec,84),color='g',label=f'84% = {np.percentile(kroupa_vec,84):.1f}$M_\\odot$',linestyle='--')\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('$M_{initial}$ ($M_\\odot$)')\n",
    "        ax.set_ylabel('Probability Density')\n",
    "        ax.set_title(f'Candidate {idx}- rough progenitor mass posterior')\n",
    "        fig.savefig(f'../img/kroupa_posterior/{idx}_kroupa_posterior.png')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "sources = Table.read('../table_C.fits')\n",
    "\n",
    "ifmr = create_ifmr_tbl(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=37</i>\n",
       "<table id=\"table125510272269568-788424\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>idx</th><th>source_id</th><th>m2</th><th>m_i_min1</th><th>m_i_max1</th><th>m_i_min2</th><th>m_i_max2</th><th>m_i_min3</th><th>m_i_max3</th><th>m_i</th></tr></thead>\n",
       "<tr><td>6</td><td>183325907326150528</td><td>0.9383295551949724</td><td>3.0591465771600563</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>16</td><td>422751230068950016</td><td>1.015032479765023</td><td>4.2878905598409665</td><td>8.0</td><td>4.2878905598409665</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>22</td><td>457836680469874560</td><td>0.3926128166039292</td><td>5.548076636555905</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>48</td><td>534740028404333184</td><td>0.6186223308354638</td><td>6.406694270939131</td><td>8.0</td><td>350.0</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>53</td><td>661148268907314432</td><td>0.7965174858311868</td><td>2.334695276372379</td><td>8.0</td><td>nan</td><td>8.0</td><td>4.602254139951923</td><td>6.983156184749249</td><td>5.731697003864424</td></tr>\n",
       "<tr><td>68</td><td>1872574993400437888</td><td>0.7328268776281763</td><td>3.7659238417360745</td><td>8.0</td><td>3.7865535626751807</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>71</td><td>1942497610724886912</td><td>0.6679663228825435</td><td>4.02596030215321</td><td>8.0</td><td>6.258451097982551</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>80</td><td>1989228126220910208</td><td>0.8356900800208915</td><td>2.033345134383304</td><td>8.0</td><td>2.050685505040841</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>96</td><td>2059201419867861248</td><td>0.6343704584315644</td><td>4.034584077842209</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>101</td><td>2068005003311062144</td><td>0.8957323702395803</td><td>3.8796573284166125</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>105</td><td>2073689276577590912</td><td>0.7864027820182545</td><td>6.992782202617762</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>110</td><td>2166849556774987520</td><td>1.0117511039342182</td><td>2.591700751381357</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>114</td><td>2174275039828118912</td><td>0.746740189679614</td><td>9.174550368834538</td><td>8.0</td><td>9.258378762197797</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>118</td><td>2194332434010280960</td><td>0.8051795000669998</td><td>8.141725536090242</td><td>8.0</td><td>350.0</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>121</td><td>2205542917130608512</td><td>0.9764458331314424</td><td>11.667518374092543</td><td>8.0</td><td>11.667518374092543</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>154</td><td>3451094801741563264</td><td>1.0694188374234426</td><td>2.5046375902250477</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>160</td><td>4040550102266227328</td><td>0.4835127803678865</td><td>2.9732202132330556</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>174</td><td>4782447359703077248</td><td>0.4539656976717653</td><td>3.210205559836165</td><td>8.0</td><td>nan</td><td>8.0</td><td>5.773816318845636</td><td>6.948823868523224</td><td>6.36132009368443</td></tr>\n",
       "<tr><td>175</td><td>4816334892186732160</td><td>0.6038236805906355</td><td>2.092763237383283</td><td>8.0</td><td>nan</td><td>8.0</td><td>2.4571990592356343</td><td>2.9020003065706623</td><td>2.6506284604264376</td></tr>\n",
       "<tr><td>178</td><td>5222629723121939328</td><td>0.6131804049344656</td><td>4.294557198800004</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>180</td><td>5237947539322507136</td><td>1.1675073205065059</td><td>3.4423556603277863</td><td>8.0</td><td>3.4442704312472316</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>183</td><td>5242761476090953728</td><td>0.9685955273502815</td><td>2.283564639754356</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>191</td><td>5263315540296196992</td><td>0.31900038473647346</td><td>2.7778829046158746</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>192</td><td>5269539115409912832</td><td>0.452343530095151</td><td>2.7778829046158746</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>194</td><td>5303867040970691456</td><td>0.528982841470677</td><td>4.178643356588042</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>233</td><td>5541167076447007872</td><td>0.43857338166552784</td><td>4.47844879404966</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>236</td><td>5581250082066100736</td><td>0.5994471887657568</td><td>4.637976622647418</td><td>8.0</td><td>nan</td><td>8.0</td><td>4.936978401892873</td><td>6.538040630562376</td><td>5.480849690164118</td></tr>\n",
       "<tr><td>246</td><td>5635800835352566144</td><td>0.3367782792928342</td><td>2.7954943354793054</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>248</td><td>5752835434289715584</td><td>0.391110578912094</td><td>2.3582361383440125</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>249</td><td>5753128007461925760</td><td>0.7214495839607389</td><td>2.3582361383440125</td><td>8.0</td><td>nan</td><td>8.0</td><td>2.4761022872329987</td><td>2.819844722324797</td><td>2.6307191737669093</td></tr>\n",
       "<tr><td>260</td><td>5870278497578560128</td><td>1.1850948778171495</td><td>3.45241212888405</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>262</td><td>5930051213822024704</td><td>1.1673782197847093</td><td>1.7103617621086347</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>270</td><td>5990577714009072896</td><td>0.8529160737701427</td><td>2.7371347278421054</td><td>8.0</td><td>2.7371347278421054</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>277</td><td>6071002793352423424</td><td>0.9593527643095765</td><td>3.0870359909534986</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>281</td><td>6460313579841489920</td><td>0.3639484758174585</td><td>3.566881524596993</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>282</td><td>6830692970829432832</td><td>0.3510466138550325</td><td>4.020206897548197</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>283</td><td>6909825338076583424</td><td>0.4131844813224569</td><td>4.0795191097677295</td><td>8.0</td><td>nan</td><td>8.0</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "</table><style>table.dataTable {clear: both; width: auto !important; margin: 0 !important;}\n",
       ".dataTables_info, .dataTables_length, .dataTables_filter, .dataTables_paginate{\n",
       "display: inline-block; margin-right: 1em; }\n",
       ".paginate_button { margin-right: 5px; }\n",
       "</style>\n",
       "<script>\n",
       "\n",
       "var astropy_sort_num = function(a, b) {\n",
       "    var a_num = parseFloat(a);\n",
       "    var b_num = parseFloat(b);\n",
       "\n",
       "    if (isNaN(a_num) && isNaN(b_num))\n",
       "        return ((a < b) ? -1 : ((a > b) ? 1 : 0));\n",
       "    else if (!isNaN(a_num) && !isNaN(b_num))\n",
       "        return ((a_num < b_num) ? -1 : ((a_num > b_num) ? 1 : 0));\n",
       "    else\n",
       "        return isNaN(a_num) ? -1 : 1;\n",
       "}\n",
       "\n",
       "require.config({paths: {\n",
       "    datatables: 'https://cdn.datatables.net/1.10.12/js/jquery.dataTables.min'\n",
       "}});\n",
       "require([\"datatables\"], function(){\n",
       "    console.log(\"$('#table125510272269568-788424').dataTable()\");\n",
       "    \n",
       "jQuery.extend( jQuery.fn.dataTableExt.oSort, {\n",
       "    \"optionalnum-asc\": astropy_sort_num,\n",
       "    \"optionalnum-desc\": function (a,b) { return -astropy_sort_num(a, b); }\n",
       "});\n",
       "\n",
       "    $('#table125510272269568-788424').dataTable({\n",
       "        order: [],\n",
       "        pageLength: 50,\n",
       "        lengthMenu: [[10, 25, 50, 100, 500, 1000, -1], [10, 25, 50, 100, 500, 1000, 'All']],\n",
       "        pagingType: \"full_numbers\",\n",
       "        columnDefs: [{targets: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], type: \"optionalnum\"}]\n",
       "    });\n",
       "});\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ifmr.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'WD temperature [K]')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut = ~np.isnan(m_i_vec)\n",
    "m_i_plot = np.array(m_i_vec)[cut]\n",
    "teff2_plot = np.array(teff2_vec)[cut]\n",
    "\n",
    "plt.hist2d(m_i_plot,teff2_plot,bins=50,cmap='Greys',range=[[0,15],[8000,15000]])\n",
    "plt.xlabel('Initial mass [Msun]')\n",
    "plt.ylabel('WD temperature [K]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
