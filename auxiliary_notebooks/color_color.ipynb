{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from astropy import table\n",
    "from astroquery.gaia import Gaia\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import scoreatpercentile\n",
    "import stam\n",
    "from tqdm import tqdm\n",
    "import WD_models\n",
    "from os import path\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters = Table.read('../data/hunt_clusters/clusters.csv')\n",
    "# members = Table.read('../data/hunt_clusters/members.csv')\n",
    "sources = Table.read('../table_C_Dias.fits', format='fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.vizier import Vizier\n",
    "clstrs = Vizier(catalog='J/MNRAS/504/356',columns=['Cluster','N','logage','e_logage','[Fe/H]','e_[Fe/H]','Av','e_Av','FileName'],row_limit=-1).query_constraints()[0]\n",
    "\n",
    "clstrs.rename_columns(clstrs.colnames,['Cluster','N','logage','e_logage','Fe/H','e_Fe/H','Av','e_Av','FileName'])\n",
    "# sources = Table.read('../table_extra.fits')\n",
    "sources['idx'] = np.full(len(sources),'---',dtype=object)\n",
    "\n",
    "cut = (sources['nss_solution_type'] == 'Orbital') | (sources['nss_solution_type'] == 'AstroSpectroSB1')\n",
    "sources = sources[cut]\n",
    "\n",
    "nms = np.unique(sources['cluster'])\n",
    "for n in nms:\n",
    "    for i, s in enumerate(sources[sources['cluster'] == n]):\n",
    "        j = np.where(sources['source_id'] == s['source_id'])[0][0]\n",
    "        sources[j]['idx'] = n+'_'+str(i)\n",
    "\n",
    "sources['idx'] = sources['idx'].astype(str)\n",
    "# sources['age'] = np.full(len(sources),np.nan)\n",
    "# sources['mh_for_mass_interp'] = np.full(len(sources),np.nan)\n",
    "# sources['av_for_mass_interp'] = np.full(len(sources),np.nan)\n",
    "\n",
    "# for j in range(len(sources)):\n",
    "#     if sources[j]['cluster'] == 'Hyades':\n",
    "#         sources[j]['age'] = 680\n",
    "#         sources[j]['mh_for_mass_interp'] = 0.14\n",
    "#         sources[j]['av_for_mass_interp'] = 0.01 * 3.1\n",
    "#     if sources[j]['cluster'] == 'IC_2602':\n",
    "#         sources[j]['age'] = 60\n",
    "#         sources[j]['mh_for_mass_interp'] = -0.02\n",
    "#         sources[j]['av_for_mass_interp'] = 0.05 * 3.1\n",
    "#     if sources[j]['cluster'] == 'NGC_2287':\n",
    "#         sources[j]['age'] = 200\n",
    "#         sources[j]['mh_for_mass_interp'] = -0.11\n",
    "#         sources[j]['av_for_mass_interp'] = 0.03 * 3.1\n",
    "#     if sources[j]['cluster'] == 'NGC_2547':\n",
    "#         sources[j]['mh'] = 60\n",
    "#         sources[j]['mh_for_mass_interp'] = 0.01\n",
    "#         sources[j]['av_for_mass_interp'] = 0.06 * 3.1\n",
    "\n",
    "# for j in range(len(sources)):\n",
    "#     clstr = sources[j]['cluster']\n",
    "#     if clstr in clstrs['cluster']:\n",
    "#         i = np.where(clstrs['cluster'] == clstr)[0][0]\n",
    "#         sources[j]['age'] = clstrs[i]['age']\n",
    "#         sources[j]['mh_for_mass_interp'] = clstrs[i]['Fe_H']\n",
    "#         sources[j]['av_for_mass_interp'] = clstrs[i]['ebv'] * 3.1\n",
    "    \n",
    "sources.sort('idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARSEC functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "\n",
    "def choose_model(mh):\n",
    "    if (-0.6 <= mh) and (mh <= 0.05):\n",
    "        PARSEC_path = '../data/PARSECv2.0/w_i=0.6/'\n",
    "        models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "    else:\n",
    "        PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "        models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "    return PARSEC_path,models\n",
    "\n",
    "def get_tracks(mh,age):\n",
    "    if PARSEC_path == '../data/PARSEC v1.2S/Gaia_lin/':\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation\n",
    "        if age <= 100:\n",
    "            age_res = 2.5e-3 # [Gyr]\n",
    "        else:\n",
    "            age_res = 1.5e-2\n",
    "    else:\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP_i45\", \"G_RP_i45\", \"G_i45\" ## rotation with 45 deg inclination\n",
    "        if age <= 45:\n",
    "            age_res = 5e-4\n",
    "        elif age <= 100:\n",
    "            age_res = 1e-3\n",
    "        else:\n",
    "            age_res = 2.5e-2\n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 10  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 20  # [Msun]\n",
    "    tracks = stam.gentracks.get_isotrack(models, [age * 1e-3, mh], params=(\"age\", \"mh\"), return_table=True,\n",
    "                                    age_res=age_res, mass_min=mass_min, mass_max=mass_max, mh_res = 0.03,\n",
    "                                    stage=None, stage_min=stage_min, stage_max=stage_max, sort_by=\"age\", color_filter1=color_fil_1, color_filter2=color_fil_2,\n",
    "                mag_filter=mag_fil)\n",
    "    return tracks\n",
    "\n",
    "def get_track_idx(mh,age):\n",
    "    if PARSEC_path == '../data/PARSEC v1.2S/Gaia_lin/':\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation\n",
    "        if age <= 100:\n",
    "            age_res = 2.5e-3 # [Gyr]\n",
    "        else:\n",
    "            age_res = 1.5e-2\n",
    "    else:\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP_i45\", \"G_RP_i45\", \"G_i45\" ## rotation with 45 deg inclination\n",
    "        if age <= 45:\n",
    "            age_res = 5e-4\n",
    "        elif age <= 100:\n",
    "            age_res = 1e-3\n",
    "        else:\n",
    "            age_res = 2.5e-2\n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 10  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 20  # [Msun]\n",
    "    track_idx = stam.gentracks.get_isotrack(models, [age * 1e-3, mh], params=(\"age\", \"mh\"), return_idx=True,\n",
    "                                    age_res=age_res, mass_min=mass_min, mass_max=mass_max, mh_res = 0.03,\n",
    "                                    stage=None, stage_min=stage_min, stage_max=stage_max, sort_by=\"age\", color_filter1=color_fil_1, color_filter2=color_fil_2,\n",
    "                mag_filter=mag_fil)   \n",
    "    return track_idx\n",
    "\n",
    "\n",
    "def get_age_mh_grid():\n",
    "    if PARSEC_path == '../data/PARSEC v1.2S/Gaia_lin/':\n",
    "            age = np.concatenate([np.arange(1,100,5),np.arange(100,950,25)])\n",
    "            mh = np.arange(-2.0,0.3,0.05)\n",
    "    else:\n",
    "        age = np.concatenate([np.arange(10,45,1),np.arange(45,100,5),np.arange(100,1001,50)])\n",
    "        mh = np.arange(-0.6,0.07,0.05)\n",
    "    \n",
    "    age,mh = np.meshgrid(age,mh)\n",
    "    return age,mh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster parameters and primary mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the (empirical) model color-color relation to be compared with the data\n",
    "## The fit will determine the best value of E(B-V) (at B-V=0) to minimize the chi^2\n",
    "\n",
    "data = pd.read_csv('../data/other/color_relations.csv')\n",
    "\n",
    "eta = lambda bv0: 0.97 - 0.09 * bv0\n",
    "\n",
    "e_bv = lambda bv0,e_bv0: eta(bv0)/eta(0) * e_bv0 \n",
    "\n",
    "e_ub = lambda e_bv,alpha,beta,gamma: alpha * e_bv + beta * e_bv**2 + gamma * e_bv**3\n",
    "\n",
    "def redden_f70(e_bv0):\n",
    "    bv0_arr = data['(B-V)0'].values\n",
    "    ub0_arr = data['(U-B)0'].values\n",
    "    alpha_arr = data['alpha'].values\n",
    "    beta_arr = data['beta'].values\n",
    "    gamma_arr = data['gamma'].values\n",
    "    \n",
    "    e_bv_arr = e_bv(bv0_arr,e_bv0)\n",
    "    e_ub_arr = e_ub(e_bv_arr,alpha_arr,beta_arr,gamma_arr)\n",
    "\n",
    "    bv0_arr_reddened = bv0_arr + e_bv_arr\n",
    "    ub0_arr_reddened = ub0_arr + e_ub_arr\n",
    "    \n",
    "    return bv0_arr_reddened,ub0_arr_reddened\n",
    "\n",
    "def chi_2_ccd(e_bv0,bv_arr,ub_arr):\n",
    "    bv0_arr_reddened,ub0_arr_reddened = redden_f70(e_bv0)\n",
    "    \n",
    "    cut = (bv_arr > bv0_arr_reddened[0]) & (bv_arr < bv0_arr_reddened[-1])\n",
    "    bv_arr = bv_arr[cut]\n",
    "    ub_arr = ub_arr[cut]\n",
    "\n",
    "    ub0_f70 = np.interp(bv_arr,bv0_arr_reddened,ub0_arr_reddened)\n",
    "    chi_2 = np.sum((ub_arr - ub0_f70)**2)\n",
    "    return chi_2\n",
    "\n",
    "def f70_lims(e_bv0):\n",
    "    bv_f70,ub_f70 = redden_f70(e_bv0)\n",
    "    up_lim = ub_f70 + 0.017\n",
    "    low_lim = np.interp(bv_f70-0.020,bv_f70,ub_f70)\n",
    "    return up_lim,low_lim\n",
    "\n",
    "def in_f70_lims(tbl,bv_f70,up_lim,low_lim):\n",
    "    up_lim = np.interp(tbl['bv'],bv_f70,up_lim)\n",
    "    low_lim = np.interp(tbl['bv'],bv_f70,low_lim)\n",
    "    cut = (tbl['ub'] < up_lim) & (tbl['ub'] > low_lim) & (tbl['bv'] < bv_f70[-1]) & (tbl['bv'] > bv_f70[0])\n",
    "    return tbl[cut]\n",
    "\n",
    "def fit_and_plot(idx, plot = False, save = False):\n",
    "    # clstr_id = sources[sources['idx']== idx]['id'][0]\n",
    "    # clstr = clusters[clusters['id']==clstr_id]\n",
    "    # memb = members[members['id']==clstr_id]\n",
    "    # cut = (memb['probability'] > 0.99) & (memb['parallax']/memb['parallax_error'] > 10)\n",
    "    # memb = memb[cut]\n",
    "    clstr = sources[sources['idx'] == idx]['cluster'][0]\n",
    "    memb = Table.read(path.join('..','data','clusters',clstr+'.fits'),format='fits')\n",
    "\n",
    "\n",
    "    query = f'''SELECT source_id, u_jkc_mag, v_jkc_mag, b_jkc_mag FROM gaiadr3.synthetic_photometry_gspc WHERE source_id IN {tuple(memb['source_id'])}'''\n",
    "    job = Gaia.launch_job(query)\n",
    "    r = job.get_results()\n",
    "\n",
    "    cut = (~r['u_jkc_mag'].mask) & (~r['v_jkc_mag'].mask) & (~r['b_jkc_mag'].mask)\n",
    "    r = r[cut]\n",
    "    if len(r) == 0:\n",
    "        print(f'No photometry for candidate {idx}')\n",
    "        return np.nan,Table({})\n",
    "    if 'SOURCE_ID' in r.colnames:\n",
    "        r.rename_column('SOURCE_ID','source_id')\n",
    "    tbl = table.join(memb,r,keys='source_id')\n",
    "    tbl['mg'] = tbl['phot_g_mean_mag'] - 5 * np.log10(1000/tbl['parallax']) + 5\n",
    "    tbl['bv'] = tbl['b_jkc_mag'] - tbl['v_jkc_mag']\n",
    "    tbl['ub'] = tbl['u_jkc_mag'] - tbl['b_jkc_mag']\n",
    "    tbl = tbl['source_id','mg','bp_rp','bv','ub']\n",
    "\n",
    "    # ebv_guess = clstr['a_v_50'][0] / 3.1\n",
    "    ebv_guess = sources[sources['idx'] == idx]['av_for_mass_interp'][0] / 3.1\n",
    "    tbl.sort('bv')\n",
    "\n",
    "    res = minimize(chi_2_ccd,ebv_guess,args=(tbl['bv'],tbl['ub']),bounds=[(0,0.3)])\n",
    "    ebv = res.x[0]\n",
    "\n",
    "    fig,(ax1,ax2) = plt.subplots(nrows=2,dpi=200,gridspec_kw={'height_ratios':[3,1]})\n",
    "    bv_f70,ub_f70 = redden_f70(ebv)\n",
    "    cut = tbl['bv'] < bv_f70[-1]\n",
    "    bv_plot = tbl['bv'][cut]\n",
    "    ub_plot = tbl['ub'][cut]\n",
    "\n",
    "    up_lim,low_lim = f70_lims(ebv)\n",
    "    tbl_mtso = in_f70_lims(tbl,bv_f70,up_lim,low_lim)\n",
    "    tbl_mtso = tbl_mtso[tbl_mtso['mg'] < 7]\n",
    "\n",
    "    ax1.plot(bv_f70,ub_f70,'k-',label=f'F70 ebv={ebv:.3f}')\n",
    "    ax1.fill_between(bv_f70,up_lim,low_lim,alpha=0.5,color='Gold')\n",
    "    ax1.scatter(bv_plot,ub_plot,s=10,c='r',label='Data')\n",
    "    ax1.scatter(tbl_mtso['bv'],tbl_mtso['ub'],s=30,c='g',label='Good MSTO',marker='x')\n",
    "    ax1.set_xlabel('B-V',fontsize=14)\n",
    "    ax1.set_ylabel('U-B',fontsize=14)\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.legend(fontsize=15)\n",
    "    ax1.set_title(f'cluster '+ clstr,fontsize=12)\n",
    "    # textstr = f'{len(memb)} reliable cluster members\\n {len(tbl_mtso)} good MSTO stars'\n",
    "    # props = dict(boxstyle='round', facecolor='k', alpha=0.5)\n",
    "    # ax1.text(0.05, 0.23, textstr, transform=ax1.transAxes, fontsize=15,\n",
    "    #         verticalalignment='top', bbox=props)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax2.set_xlabel('U-B',fontsize=14)\n",
    "    ax2.set_ylabel(r'$\\Delta$ (U-B)',fontsize=14)\n",
    "    ax2.scatter(ub_plot,ub_plot-np.interp(bv_plot,bv_f70,ub_f70),s=10,c='r')\n",
    "    ax2.scatter(tbl_mtso['ub'],tbl_mtso['ub']-np.interp(tbl_mtso['bv'],bv_f70,ub_f70),s=30,c='g',marker='x')\n",
    "    ax2.fill_between(ub_f70,up_lim-ub_f70,low_lim-ub_f70,alpha=0.5,color='Gold')\n",
    "    ax2.invert_yaxis()\n",
    "    fig.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(f'../img/ccd/ccd'+clstr+'.png')\n",
    "    if not plot:\n",
    "        plt.close()\n",
    "    return ebv,tbl_mtso\n",
    "\n",
    "def chi_2_cmd(age,mh,bp_rp,mg,ebv):\n",
    "    tracks = get_tracks(mh,age)\n",
    "    x = np.array(tracks[\"bp_rp\"])\n",
    "    y = np.array(tracks[\"mg\"])\n",
    "    xx,yy = [a for _,a in sorted(zip(y,x))], np.sort(y)\n",
    "    \n",
    "    e_bprp, A_G = stam.gaia.get_extinction_in_band(ebv,mag_filter=\"G\",color_filter1='G_BP',color_filter2='G_RP')\n",
    "    bp_rp_corrected = bp_rp - e_bprp\n",
    "    mg_corrected = mg - A_G\n",
    "    bp_rp_model = np.interp(mg_corrected,yy,xx)\n",
    "    chi_2 = np.sum((bp_rp_corrected - bp_rp_model)**2)\n",
    "    return chi_2/len(bp_rp_corrected)\n",
    "\n",
    "def fit_cluster_cmd(idx, plot = False, save = False):\n",
    "    ebv,tbl_mtso = fit_and_plot(idx, plot = plot, save = save)\n",
    "    ebv = sources[sources['idx'] == idx]['av_for_mass_interp'][0] / 3.1 ## FIX E(B-V) BASED ON CLUSTER CATALOG for testing\n",
    "    if len(tbl_mtso) >= 4:\n",
    "        age,mh = get_age_mh_grid()\n",
    "        mh0 = sources[sources['idx']== idx]['mh_for_mass_interp'][0]\n",
    "        if mh0 > mh.max():\n",
    "            mh0 = mh.max()\n",
    "        if mh0 < mh.min():\n",
    "            mh0 = mh.min()\n",
    "        mh = np.full_like(mh,mh0) #### FIX METALLICITY BASED ON CLUSTER CATALOG\n",
    "        chi2_mat = np.zeros((mh.shape[0],age.shape[1]))\n",
    "        for i in range(age.shape[1]):\n",
    "            for j in range(mh.shape[0]):\n",
    "                chi2_mat[j,i] = chi_2_cmd(age[j,i],mh[j,i],tbl_mtso['bp_rp'],tbl_mtso['mg'],ebv)\n",
    "\n",
    "        j,i = np.unravel_index(np.argmin(chi2_mat), chi2_mat.shape)\n",
    "        age_best = age[j,i]\n",
    "        mh_best = mh[j,i]\n",
    "        tracks = get_tracks(mh_best,age_best)\n",
    "        \n",
    "        x = np.array(tracks[\"bp_rp\"])\n",
    "        y = np.array(tracks[\"mg\"])\n",
    "        xx,yy = [a for _,a in sorted(zip(y,x))], np.sort(y)\n",
    "\n",
    "        e_bprp, A_G = stam.gaia.get_extinction_in_band(ebv,mag_filter=\"G\",color_filter1='G_BP',color_filter2='G_RP')\n",
    "        bp_rp_corrected = tbl_mtso['bp_rp'] - e_bprp\n",
    "        mg_corrected = tbl_mtso['mg'] - A_G\n",
    "        mg_corrected = mg_corrected.data\n",
    "        bp_rp_model = np.interp(np.union1d(mg_corrected,yy),yy,xx)\n",
    "\n",
    "        # clstr_id = sources[sources['idx']== idx]['id'][0]\n",
    "        # memb = members[members['id']==clstr_id]\n",
    "        # cut = (memb['probability'] > 0.99) & (memb['parallax']/memb['parallax_error'] > 10)\n",
    "        # memb = memb[cut]\n",
    "        \n",
    "        clstr = sources[sources['idx'] == idx]['cluster'][0]\n",
    "        memb = Table.read(path.join('..','data','clusters',clstr + '.fits'),format='fits')\n",
    "        memb['mg'] = memb['phot_g_mean_mag'] - 5 * np.log10(1000/memb['parallax']) + 5\n",
    "\n",
    "        fig,ax = plt.subplots(dpi=300)\n",
    "        ax.scatter(bp_rp_corrected,mg_corrected,s=10,c='r',label='MSTO used for fit')\n",
    "        ax.scatter(memb['bp_rp'] - e_bprp,memb['mg'] - A_G,s=5,c='b',label='All members')\n",
    "        ax.scatter(sources[sources['idx']== idx]['bp_rp'] - e_bprp,sources[sources['idx']== idx]['mg'] - A_G,s=25,c='g',label='Candidate',zorder = 10)\n",
    "        ax.plot(bp_rp_model,np.union1d(mg_corrected,yy), 'ko', markersize=1,label=f'PARSEC age={int(age_best)} Myr, [Fe/H]={mh_best:.2f}')\n",
    "        ax.set_xlabel('BP-RP')\n",
    "        ax.set_ylabel('G')\n",
    "        ax.invert_yaxis()\n",
    "        ax.legend(loc='lower left',frameon=False)\n",
    "        ax.set_title('cluster ' + clstr)\n",
    "        if save:\n",
    "            fig.savefig(f'../img/cmd/cmd'+clstr+'.png')\n",
    "        if not plot:\n",
    "            plt.close()\n",
    "        return age_best, mh_best, ebv\n",
    "    else:\n",
    "        print(f'Candidate {idx} has only {len(tbl_mtso)} good MSTO stars, not enough to fit the isochrone.')\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "def photometric_mass(age,mh,ebv,src):    \n",
    "    src['e_bv'] = ebv\n",
    "    color_excess_key = 'e_bv'\n",
    "    n_realizations = 10000\n",
    "    correct_extinction = True\n",
    "    if PARSEC_path == '../data/PARSEC v1.2S/Gaia_lin/':\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation\n",
    "        if age <= 100:\n",
    "            age_res = 2.5e-3 # [Gyr]\n",
    "        else:\n",
    "            age_res = 1.5e-2\n",
    "    else:\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP_i45\", \"G_RP_i45\", \"G_i45\" ## rotation with 45 deg inclination\n",
    "        if age <= 45:\n",
    "            age_res = 5e-4\n",
    "        elif age <= 100:\n",
    "            age_res = 1e-3\n",
    "        else:\n",
    "            age_res = 2.5e-2\n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 10  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 10  # [Msun]\n",
    "        \n",
    "    m1, m1_err = stam.run.multirun(src, vals=[age * 1e-3, mh], params=(\"age\", \"mh\"), suffix=\"\", is_save=False,\n",
    "                                                track_type=\"isotrack\", assign_param=\"mass\", is_extrapolate=False, rbf_func=\"linear\",\n",
    "                                                    output_type=\"csv\", output_path=\"./stam_output/\", n_realizations=n_realizations, interp_fun=\"griddata\",\n",
    "                                                    models=models, correct_extinction=correct_extinction, color_excess_key=color_excess_key , mh_res = 0.03,\n",
    "                                                    use_reddening_key=False, mass_min=mass_min, mass_max=mass_max,stage=None, stage_min=stage_min, stage_max=stage_max, age_res=age_res,\n",
    "                                                    color_filter1=color_fil_1, color_filter2=color_fil_2, mag_filter=mag_fil)\n",
    "    return m1[0], m1_err[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = False\n",
    "plot = False\n",
    "save = False\n",
    "\n",
    "new_sources = sources.copy()\n",
    "m1_col = []\n",
    "m1_err_col = []\n",
    "age_col = []\n",
    "mh_col = []\n",
    "av_col = []\n",
    "# fitting all with parsec v1.2S\n",
    "PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "for idx in new_sources['idx']:\n",
    "    if idx.split('_')[-1] == '0':\n",
    "        # The first candidate of each cluster determines the PARSEC model to be used\n",
    "        # PARSEC_path,models = choose_model(sources[sources['idx'] == idx]['mh_for_mass_interp'][0])\n",
    "        if fit:\n",
    "            # only the first candidate of each cluster is used to fit the isochrone\n",
    "            print('Fitting cluster ' + sources[sources['idx'] == idx]['cluster'][0] + '...')\n",
    "            age,mh,ebv = fit_cluster_cmd(idx, plot = plot, save = save)\n",
    "        else:\n",
    "            # if the cluster parameters are known, use them\n",
    "            age = new_sources[new_sources['idx'] == idx]['age'][0]\n",
    "            mh = new_sources[new_sources['idx'] == idx]['mh_for_mass_interp'][0]\n",
    "            ebv = new_sources[new_sources['idx'] == idx]['av_for_mass_interp'][0] / 3.1\n",
    "    else:\n",
    "        # use the same cluster parameters for subsequent candidates\n",
    "        frst = new_sources[new_sources['idx'] == idx]['cluster'][0] + '_0'\n",
    "        j = np.where(new_sources['idx'] == frst)[0][0]\n",
    "        age = age_col[j]\n",
    "        mh = mh_col[j]\n",
    "        ebv = av_col[j] / 3.1\n",
    "    age_col.append(age)\n",
    "    mh_col.append(mh)\n",
    "    av_col.append(ebv * 3.1)\n",
    "    if np.isnan(age):\n",
    "        # if unable to fit age, skip the candidate\n",
    "        # new_sources.remove_row(np.where(new_sources['idx'] == idx)[0][0])\n",
    "        m1_col.append(np.nan)\n",
    "        m1_err_col.append(np.nan)\n",
    "    else:\n",
    "        try:\n",
    "            print(f'Photometric mass for candidate {idx}...')\n",
    "            m1,m1_err = photometric_mass(age,mh,ebv,new_sources[new_sources['idx'] == idx])\n",
    "            m1_col.append(m1)\n",
    "            m1_err_col.append(m1_err)\n",
    "        except:\n",
    "            print(f'Error in photometric mass for candidate {idx}')\n",
    "            m1_col.append(np.nan)\n",
    "            m1_err_col.append(np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sources['m1'] = m1_col\n",
    "new_sources['m1_err'] = m1_err_col\n",
    "# new_sources['age1'] = age_col\n",
    "# new_sources['mh1'] = mh_col\n",
    "# new_sources['av1'] = av_col\n",
    "new_sources.write('../table_B_Dias.fits',overwrite=True)\n",
    "sources = new_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions, gaia passbands\n",
    "\n",
    "# ------------ AMRF limits ----------------\n",
    "from astropy.io import ascii\n",
    "from synphot import SourceSpectrum, ReddeningLaw\n",
    "from synphot.models import BlackBodyNorm1D\n",
    "from synphot.units import convert_flux\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "import json \n",
    "from uncertainties import unumpy as unp, ufloat\n",
    "from uncertainties import correlated_values_norm, correlation_matrix\n",
    "import warnings\n",
    "\n",
    "def blackbody(temperature, wavelength, ebv=None, extinction_model='mwavg'):\n",
    "    bb = SourceSpectrum(BlackBodyNorm1D, temperature=temperature*u.K)  # [photons s^-1 cm^-2 A^-1]\n",
    "    if ebv is not None:\n",
    "        # apply extinction\n",
    "        ext = ReddeningLaw.from_extinction_model(extinction_model).extinction_curve(ebv)\n",
    "        bb = bb * ext\n",
    "    bb = bb(wavelength)/(const.R_sun / const.kpc) ** 2  # undo synphot normalization (but leave the pi factor from integration over half a sphere)\n",
    "    bb = convert_flux(wavelength, bb, 'flam')  # [flam] = [erg s^-1 cm^-2 A^-1]\n",
    "    bb = bb.to(u.erg/u.s/u.cm**2/u.angstrom)  # express in normal astropy units\n",
    "    return bb\n",
    "\n",
    "\n",
    "def mlogg2radius(m, logg):\n",
    "    g = 10**logg*u.cm/u.s**2\n",
    "    r = np.sqrt(const.G*m/g)\n",
    "    return r.to(u.Rsun).value\n",
    "\n",
    "\n",
    "def calc_synth_phot(wavelength, flux, bandpass):\n",
    "    dlambda = np.diff(wavelength)\n",
    "    dlambda = np.concatenate([dlambda, np.array([dlambda[-1]])])\n",
    "\n",
    "    # assuming a photon-counting device\n",
    "    phot = np.sum(dlambda*bandpass*wavelength*flux)/np.sum(dlambda*bandpass*wavelength)\n",
    "    \n",
    "    return phot\n",
    "\n",
    "\n",
    "amrf = lambda q, S : q/(1+q)**(2/3)*(1 - S*(1+q)/(q*(1+S)))\n",
    "\n",
    "gaia_passband = ascii.read('../data/other/passband.dat', names=[\"wl\", \"gPb\", \"gPbError\", \"bpPb\", \"bpPbError\", \"rpPb\", \"rpPbError\"])\n",
    "\n",
    "# replace missing values with NaNs\n",
    "for col in gaia_passband.itercols():\n",
    "    col[col == 99.99] = 0\n",
    "    \n",
    "gaia_passband['wl'] *= 10  # [A]\n",
    "\n",
    "# ---------- AMRF -------------------\n",
    "\n",
    "limiting_curves = Table.read('../data/other/AMRF_limiting_curves.fits')\n",
    "# Retrieve the conservative limiting AMRF values for some primary mass\n",
    "# --------------\n",
    "def Atr(m1):\n",
    "    j = np.argmin(np.abs(m1 - limiting_curves['m1'].data))\n",
    "    return limiting_curves['Atr'][j]\n",
    "def Ams(m1):\n",
    "    j = np.argmin(np.abs(m1 - limiting_curves['m1'].data))\n",
    "    return limiting_curves['Ams'][j]\n",
    "\n",
    "# =============================================================================\n",
    "#                Auxil routines to obtain the covariance matrix\n",
    "# =============================================================================\n",
    "\n",
    "# 1) get the list of parameters from the solution type\n",
    "def get_par_list(solution_type=None):\n",
    "    if (solution_type is None) or (solution_type=='Orbital'):\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'eccentricity', 'period', 't_periastron')\n",
    "\n",
    "    elif (solution_type=='OrbitalAlternative') or (solution_type=='OrbitalAlternativeValidated') \\\n",
    "            or (solution_type=='OrbitalTargetedSearch') or (solution_type=='OrbitalTargetedSearchValidated'):\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'period', 'eccentricity', 't_periastron')\n",
    "\n",
    "    elif solution_type=='AstroSpectroSB1':\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'c_thiele_innes', 'h_thiele_innes', 'center_of_mass_velocity',\n",
    "                'eccentricity', 'period', 't_periastron')\n",
    "\n",
    "\n",
    "# 2) Get the order of parameters in the covariance matrix, for a given bit index.\n",
    "def bit_index_map(bit_index):\n",
    "    if bit_index==8191:\n",
    "        return ['ra','dec','parallax','pmra','pmdec','A','B','F','G', 'e','P', 'T']\n",
    "    elif bit_index==8179:\n",
    "        return ['ra','dec','parallax','pmra','pmdec','A','B','F','P', 'T']\n",
    "    elif bit_index==65535:\n",
    "        return ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'A', 'B', 'F', 'G', 'C', 'H', 'gamma','e', 'P', 'T']\n",
    "    elif bit_index==65435:\n",
    "        return ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'A', 'B', 'F', 'H', 'gamma', 'P', 'T']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# 3) Generate the correlation matrix\n",
    "def make_corr_matrix(input_table, pars=None):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    input_table nss_two_body_orbit table.\n",
    "    pars : list\n",
    "            list of parameters for the corresponding solution of the desired\n",
    "              target, in the same order as they appear in the Gaia table.\n",
    "      \"\"\"\n",
    "    if pars is None:\n",
    "        pars = get_par_list()\n",
    "\n",
    "    # read the correlation vector\n",
    "    s1 = input_table['corr_vec'].replace('\\n','')   \n",
    "    s1 = s1.replace(' ',',')\n",
    "    s1 = s1.replace('--','0')\n",
    "    corr_vec = list(json.loads(s1))\n",
    "    # set the number of parameters in the table\n",
    "    n_pars = len(pars)\n",
    "    # define the correlation matrix.\n",
    "    corr_mat = np.ones([n_pars, n_pars], dtype=float)\n",
    "\n",
    "    # Read the matrix (lower triangle)\n",
    "    ind = 0\n",
    "    for i in range(n_pars):\n",
    "        for j in range(i):\n",
    "            corr_mat[j][i] = corr_vec[ind]\n",
    "            corr_mat[i][j] = corr_vec[ind]\n",
    "            ind += 1\n",
    "\n",
    "    return corr_mat\n",
    "\n",
    "\n",
    "# 4) Get the NSS data \n",
    "def get_nss_data(input_table, source_id):\n",
    "\n",
    "    target_idx = np.argwhere(input_table['source_id'] == source_id)[0][0]\n",
    "    pars = get_par_list(input_table['nss_solution_type'][target_idx])\n",
    "    corr_mat = make_corr_matrix(input_table[target_idx], pars=pars)\n",
    "\n",
    "    mu, std = np.zeros(len(pars)), np.zeros(len(pars))\n",
    "    for i, par in enumerate(pars):\n",
    "        try:\n",
    "            mu[i] = input_table[par][target_idx]\n",
    "            std[i] = input_table[par + '_error'][target_idx]\n",
    "        except KeyError:\n",
    "            mu[i], std[i] = np.nan, np.nan\n",
    "\n",
    "    nan_idxs = np.argwhere(np.isnan(corr_mat))\n",
    "    corr_mat[nan_idxs[:, 0], nan_idxs[:, 1]] = 0.0\n",
    "\n",
    "    return mu, std, corr_mat\n",
    "\n",
    "def multivar_sample(mu, sigma, corr, n):\n",
    "    cov = corr*(sigma[:, None] * sigma[None, :])\n",
    "    # l = spla.cholesky(cov)\n",
    "    # z = np.random.normal(size=(n, mu.shape[0]))\n",
    "    # return z.dot(l) + mu\n",
    "    return np.random.multivariate_normal(mu, cov, size=n)\n",
    "\n",
    "# =============================================================================\n",
    "#                      calc parameters.\n",
    "# =============================================================================\n",
    "# Here we calculate the AMRF, qmin, etc, assuming that the mass of the luminous star \n",
    "# is exactly one solar mass. This is just for the red-clump stars...\n",
    "def calc_AMRF(par_in, par_in_errors, corr_matrix, m1, bit_index=8191):\n",
    "    \"\"\"\n",
    "    For the given set of orbital parameters by Gaia, this function calculates\n",
    "    the standard geometrical elements (a, omega, Omega, and i). If the error\n",
    "    estimates and covariance matrix are prodived, the error estimates on the\n",
    "    calculated parameters are returned as well.\n",
    "\n",
    "    Input: thiele_innes: Thiele Innes parameters [A,B,F,G] in milli-arcsec\n",
    "           thiele_innes_errors : Corresponding errors.\n",
    "           corr_matrix : Corresponding  4X4 correlation matrix.\n",
    "\n",
    "  Output: class-III probability via monte carlo\n",
    "    \"\"\"\n",
    "    # Read the coefficients and assign the correlation matrix.\n",
    "    # Create correlated quantities. If the error is nan we assume 1e-6...\n",
    "    par_in_errors[np.isnan(par_in_errors)] = 1e-6\n",
    "    par_list = correlated_values_norm([(par_in[i], par_in_errors[i]) for i in np.arange(len(par_in))], corr_matrix)\n",
    "    key_list = bit_index_map(bit_index)\n",
    "\n",
    "    par = {key_list[i]: par_list[i] for i in np.arange(len(key_list))}\n",
    "    par['mass'] = m1\n",
    "\n",
    "    # Add the G Thiele-Innes parameter if needed.\n",
    "    if (bit_index == 8179) | (bit_index == 65435):\n",
    "        G = -par['A']*par['F']/par['B']\n",
    "    else:\n",
    "        G = par['G']\n",
    "\n",
    "    # This in an intermediate step in the formulae...\n",
    "    p = (par['A'] ** 2 + par['B'] ** 2 + G ** 2 + par['F'] ** 2) / 2.\n",
    "    q = par['A'] * G - par['B'] * par['F']\n",
    "\n",
    "    # Calculate the angular semimajor axis (already in mas)\n",
    "    a_mas = unp.sqrt(p + unp.sqrt(p ** 2 - q ** 2))\n",
    "\n",
    "    # Calculate the inclination and convert from radians to degrees\n",
    "    i_deg = unp.arccos(q / (a_mas ** 2.)) * (180 / np.pi)\n",
    "    \n",
    "    try:\n",
    "        if par.get(\"d\") is not None:\n",
    "            K_kms = 4.74372*unp.sqrt(par['C'] ** 2 + par['H'] ** 2)*(2*np.pi)/(par['P']/ 365.25)/np.sqrt(1-par['e']**2)\n",
    "            acc   = 2*K_kms/par['P']\n",
    "        else:\n",
    "            K_kms = 4.74372*unp.sqrt(par['C'] ** 2 + par['H'] ** 2)*(2*np.pi)/(par['P']/ 365.25)\n",
    "            acc   = K_kms/par['P']/4\n",
    "    except:\n",
    "        K_kms = ufloat(999, 999) \n",
    "        acc   = ufloat(999,999)\n",
    "\n",
    "    # Calculate the AMRF\n",
    "    try:\n",
    "        AMRF = a_mas / par['parallax'] * par['mass'] ** (-1 / 3)  * (par['P']/ 365.25) ** (-2 / 3)\n",
    "\n",
    "        # Calculate AMRF q\n",
    "        y = AMRF ** 3\n",
    "        h = (y/2 + (y**2)/3 + (y**3)/27\n",
    "             + np.sqrt(3)/18*y*unp.sqrt(4*y+27))**(1/3)\n",
    "        q = h + (2*y/3 + (y**2)/9)/h + y/3\n",
    "    except:\n",
    "        AMRF = ufloat(np.nan, np.inf) \n",
    "        q    = ufloat(np.nan, np.inf) \n",
    "        \n",
    "    # Extract expectancy values and standard deviations\n",
    "    pars = np.array([unp.nominal_values(AMRF),\n",
    "                         unp.nominal_values(q),\n",
    "                         unp.nominal_values(a_mas),\n",
    "                         unp.nominal_values(i_deg),\n",
    "                         unp.nominal_values(K_kms),\n",
    "                         unp.nominal_values(acc)])\n",
    "\n",
    "    pars_error = np.array([unp.std_devs(AMRF),\n",
    "                               unp.std_devs(q),\n",
    "                               unp.std_devs(a_mas),\n",
    "                               unp.std_devs(i_deg),\n",
    "                               unp.std_devs(K_kms),\n",
    "                               unp.std_devs(acc)])\n",
    "\n",
    "    return pars, pars_error\n",
    "\n",
    "def class_probs(Atr,Ams,par_in, par_in_errors,\n",
    "                  m1, m1_error, corr_matrix, bit_index=8191, n=1e2, factor=1.0):\n",
    "    \"\"\"\n",
    "    For the given set of orbital parameters by Gaia, this function calculates\n",
    "    the standard geometrical elements (a, omega, Omega, and i). If the error\n",
    "    estimates and covariance matrix are prodived, the error estimates on the\n",
    "    calculated parameters are returned as well.\n",
    "\n",
    "    Input: thiele_innes: Thiele Innes parameters [A,B,F,G] in milli-arcsec\n",
    "           thiele_innes_errors : Corresponding errors.\n",
    "           corr_matrix : Corresponding  4X4 correlation matrix.\n",
    "\n",
    "  Output: physical and geometrical parameters\n",
    "    \"\"\"\n",
    "    r_3 = 0\n",
    "    r_2 = 0\n",
    "    par_in_errors[np.isnan(par_in_errors)] = 1e-6\n",
    "    vecs = multivar_sample(par_in, par_in_errors, corr_matrix, int(n))\n",
    "    key_list = bit_index_map(bit_index)\n",
    "\n",
    "    for vec in vecs:\n",
    "        par = {key_list[i]: vec[i] for i in np.arange(len(key_list))}\n",
    "        par['mass'] = m1_error*np.random.randn() + m1\n",
    "\n",
    "        # Add the G Thiele-Innes parameter if needed.\n",
    "        if (bit_index == 8179) | (bit_index == 65435):\n",
    "            par['G'] = -par['A'] * par['F'] / par['B']\n",
    "\n",
    "        # This in an intermediate step in the formulae...\n",
    "        p = (par['A'] ** 2 + par['B'] ** 2 + par['G'] ** 2 + par['F'] ** 2) / 2.\n",
    "        q = par['A'] * par['G'] - par['B'] * par['F']\n",
    "\n",
    "        # Calculate the semimajor axis (already in mas)\n",
    "        a_mas = np.sqrt(p + np.sqrt(p ** 2 - q ** 2))\n",
    "\n",
    "        # Calculate the AMRF\n",
    "        AMRF = a_mas / par['parallax'] * par['mass'] ** (-1 / 3) * (par['P']/ 365.25) ** (-2 / 3)\n",
    "\n",
    "        try:\n",
    "            if 0 < par['e'] < 1:\n",
    "                if AMRF > Atr * factor:\n",
    "                    r_3 += 1\n",
    "                elif Ams * factor < AMRF < Atr * factor:\n",
    "                    r_2 += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return (n-r_2-r_3)/n, r_2/n, r_3/n #(no_detections + detections)\n",
    "\n",
    "# =============================================================================\n",
    "#                       Read the data from the NSS table\n",
    "# =============================================================================\n",
    "def add_astrometric_parameters(data):\n",
    "    # Here we only calculate (but don't assign class 3 probabilities!\n",
    "    # We get the data table, arrange the arrays, calculate the astrometric\n",
    "    # coefficients and plug it all back into the table.\n",
    "\n",
    "    # Initialize the arrays\n",
    "    # ---------------------\n",
    "    # We need to calculate the AMRF, mass ratio, angular semi-major axis, orbtial inclination\n",
    "    # and order-of-magnitude acceleration. We also want their uncertainties.\n",
    "    count_good, count_bad = 0, 0\n",
    "    A, q, a_mas, i_deg, K_kms, acc, P1, P2, P3 = np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan), np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan), np.full(len(data), np.nan), np.full(len(data), np.nan) \n",
    "\n",
    "    Ae, qe, a_mase, i_dege, K_kmse, acce = np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                                   np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                                   np.full(len(data), np.nan),  np.full(len(data), np.nan)\n",
    "\n",
    "    # Now go one by one and calculate the AMRF\n",
    "    # ----------------------------------------\n",
    "    for idx in tqdm(range(len(data['source_id']))):\n",
    "        if data[idx]['nss_solution_type'] not in ['Orbital','AstroSpectroSB1']:\n",
    "            continue\n",
    "        # Read the NSS solutin values.\n",
    "        sid = data['source_id'][idx]\n",
    "        mu, std, corr_mat = get_nss_data(data, sid)\n",
    "        m1 = data['m1'][idx]\n",
    "        m1_error = data['m1_err'][idx]\n",
    "        if np.ma.is_masked(m1):\n",
    "            print(idx)\n",
    "            pass\n",
    "        Ams_idx = data['Ams'][idx]\n",
    "        Atr_idx = data['Atr'][idx]\n",
    "        if np.ma.is_masked(Ams_idx) | np.ma.is_masked(Atr_idx):\n",
    "            Ams_idx = Ams(m1)\n",
    "            Atr_idx = Atr(m1)\n",
    "            \n",
    "        vals, stds = calc_AMRF(mu, std, corr_mat, m1, bit_index=data['bit_index'][idx])\n",
    "        p1, p2, p3 = class_probs(data['Atr'][idx],data['Ams'][idx],mu, std, m1, m1_error, corr_mat, bit_index=data['bit_index'][idx], n = 1e4)\n",
    "        try:\n",
    "            A[idx], Ae[idx]  = vals[0], stds[0]\n",
    "            q[idx], qe[idx]  = vals[1], stds[1]\n",
    "            a_mas[idx], a_mase[idx]  = vals[2], stds[2]\n",
    "            i_deg[idx], i_dege[idx]  = vals[3], stds[3]\n",
    "            K_kms[idx], K_kmse[idx]  = vals[4], stds[4]\n",
    "            acc[idx],   acce[idx]    = vals[5], stds[5]\n",
    "            P1[idx], P2[idx], P3[idx] = p1, p2, p3\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Store it all back in the original data structure.\n",
    "    data['AMRF'], data['AMRF_error'] = A, Ae\n",
    "    data['AMRF_q'], data['AMRF_q_error'] = q, qe\n",
    "    data['a_mas'], data['a_mas_error'] = a_mas, a_mase\n",
    "    data['i_deg'], data['i_deg_error'] = i_deg, i_dege\n",
    "    data['K_kms'], data['K_kms_error'] = K_kms, K_kmse\n",
    "    data['acc_kmsd'], data['acc_kmsd_error'] = acc, acce\n",
    "    data['classI_prob'] = P1\n",
    "    data['classII_prob'] = P2\n",
    "    data['classIII_prob'] = P3\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc AMRF limits\n",
    "\n",
    "sources['Ams'] = np.full(len(sources),np.nan)\n",
    "sources['Atr'] = np.full(len(sources),np.nan)\n",
    "\n",
    "## calculating for all sources\n",
    "\n",
    "stage_min = 0  # pre-main sequence\n",
    "stage_max = 3  # red giant branch\n",
    "mass_min = 0  # [Msun]\n",
    "mass_max = 8  # [Msun]\n",
    "\n",
    "m2_vec = np.arange(0.1, 10, 0.1)\n",
    "\n",
    "wavelength = gaia_passband['wl'].value  # [A]\n",
    "\n",
    "Gflux1 = np.zeros(len(sources))\n",
    "Gflux2 = np.zeros((len(sources), len(m2_vec)))\n",
    "q = np.zeros((len(sources), len(m2_vec)))\n",
    "PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "for i in tqdm(range(len(sources))):\n",
    "    idx = sources['idx'][i]\n",
    "    if idx.split('_')[-1] == '0':\n",
    "        # The first candidate of each cluster determines the PARSEC model to be used\n",
    "        # PARSEC_path,models = choose_model(sources[sources['idx'] == idx]['mh_for_mass_interp'][0])\n",
    "        ''\n",
    "    if sources[i]['nss_solution_type'] not in ['Orbital','AstroSpectroSB1']:\n",
    "        continue\n",
    "    mh = sources['mh_for_mass_interp'][i]\n",
    "    age = sources['age'][i]\n",
    "    ebv = sources['av_for_mass_interp'][i]/3.1\n",
    "    m1 = sources['m1'][i]\n",
    "    \n",
    "    try:\n",
    "        track_idx = get_track_idx(mh,age)[-1]\n",
    "        tracks = models[track_idx].copy()\n",
    "        tracks.sort('Mini')\n",
    "        idx = np.argmin(np.abs(tracks['Mass'] - m1))\n",
    "\n",
    "        teff1 = 10**tracks['logTe'][idx]  # [K]\n",
    "        logg1 = tracks['logg'][idx]\n",
    "        r1 = mlogg2radius(m1*u.Msun, logg1)  # [Rsun]\n",
    "        flux1 = blackbody(teff1, wavelength, ebv=ebv)*4*np.pi*r1**2\n",
    "        Gflux1[i] = calc_synth_phot(wavelength, flux1, gaia_passband['gPb'].value).value\n",
    "\n",
    "        q[i, :] = m2_vec/m1  # mass ratio\n",
    "\n",
    "        for j in range(len(m2_vec)):\n",
    "            m2 = m2_vec[j]\n",
    "            idx = np.argmin(np.abs(tracks['Mass'] - m2))\n",
    "            teff2 = 10**tracks['logTe'][idx]  # [K]\n",
    "            logg2 = tracks['logg'][idx]\n",
    "            r2 = mlogg2radius(m2*u.Msun, logg2)  # [Rsun]\n",
    "            flux2 = blackbody(teff2, wavelength, ebv=ebv)*4*np.pi*r2**2\n",
    "            Gflux2[i,j] = calc_synth_phot(wavelength, flux2, gaia_passband['gPb'].value).value\n",
    "\n",
    "        Sms = Gflux2[i,:]/Gflux1[i]\n",
    "        Ams = amrf(q[i, :], Sms)\n",
    "        valid_idx = Sms < 1\n",
    "        Ams = np.max(Ams[valid_idx]) \n",
    "        sources['Ams'][i] = Ams\n",
    "        Str = 2*Gflux2[i,:]/Gflux1[i]\n",
    "        Atr = amrf(2*q[i, :], Str)\n",
    "        valid_idx = Str < 1\n",
    "        Atr = np.max(Atr[valid_idx])\n",
    "        sources['Atr'][i] = Atr\n",
    "    except:\n",
    "        print(f'i = {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:08<00:00, 12.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calc AMRF and class probabilities\n",
    "new_sources = add_astrometric_parameters(sources)\n",
    "new_sources['m2'] = new_sources['m1'] * new_sources['AMRF_q']\n",
    "new_sources['m2_err'] = ((new_sources['m1_err'] * new_sources['AMRF_q'])**2 + (new_sources['m1'] * new_sources['AMRF_q_error'])**2)**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooling time and progenitor mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WD cooling age ~568 (510 to 634)\n",
      "Initial mass ~3.80 (3.40 to 4.60)\n"
     ]
    }
   ],
   "source": [
    "## t_life vs m from evolutionary tracks/M_i from t_cluster, t_cool\n",
    "from os import walk,path\n",
    "\n",
    "def get_zarr(omega):\n",
    "    basedir = path.join('..','data','PARSECv2.0','evol_track',f'w_i={omega:.1f}')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = []\n",
    "    for n in filenames:\n",
    "        z = n.split('Y')[0]\n",
    "        z_arr.append(float(z[1:]))\n",
    "    return np.unique(z_arr)\n",
    "\n",
    "def get_marr(mh,omega):\n",
    "    basedir = path.join('..','data','PARSECv2.0','evol_track',f'w_i={omega:.1f}')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = get_zarr(omega)\n",
    "    z = 0.01524 * 10**mh\n",
    "    z_nearest = z_arr[np.argmin(np.abs(z_arr - z))]\n",
    "    z_str = 'Z'+f'{z_nearest}'\n",
    "\n",
    "    m_arr = []\n",
    "    for n in filenames:\n",
    "        if z_str in n:\n",
    "            m = n.split('M')[1].removesuffix('.TAB')\n",
    "            m_arr.append(float(m))\n",
    "    return np.unique(m_arr)\n",
    "\n",
    "def get_lifetime(mass,mh,omega):\n",
    "    ## lifetime for m>0.8\n",
    "    basedir = path.join('..','data','PARSECv2.0','evol_track',f'w_i={omega:.1f}')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = get_zarr(omega)\n",
    "    \n",
    "    z = 0.01524 * 10**mh\n",
    "    z_nearest = z_arr[np.argmin(np.abs(z_arr - z))]\n",
    "\n",
    "    mass_str = ('M' + f'{mass:.2f}'.removeprefix('0'))[:5]\n",
    "    z_str = 'Z'+f'{z_nearest}'\n",
    "\n",
    "    trackpath = ''\n",
    "    for n in filenames:\n",
    "        if mass_str in n and z_str in n:\n",
    "            trackpath = path.join(basedir,n)\n",
    "            break\n",
    "    if trackpath == '':\n",
    "        print(f'No track found for '+mass_str+' '+z_str)\n",
    "\n",
    "    trck = pd.read_fwf(trackpath, header=None, skiprows=5)\n",
    "    names = Table.read(trackpath, format='ascii.fixed_width', data_start=4, data_end=5,header_start=None)\n",
    "    colnames = names[0][0].split()\n",
    "\n",
    "    trck.columns = colnames\n",
    "    trck = trck.iloc[:-1]\n",
    "    trck = Table.from_pandas(trck)\n",
    "    trck['PHS'] = trck['PHS'].astype(float)\n",
    "    trck['AGE'] = trck['AGE'].astype(float)\n",
    "\n",
    "    return trck[trck['PHS'] > 1]['AGE'].min()\n",
    "\n",
    "def lifetime_vs_mass(mh,omega):\n",
    "    m_arr = get_marr(mh,omega)\n",
    "    m_arr = m_arr[m_arr > 0.8]\n",
    "    t_arr = []\n",
    "    for m in m_arr:\n",
    "        t_arr.append(get_lifetime(m,mh,omega))\n",
    "    return m_arr,t_arr\n",
    "\n",
    "def get_initial_mass(age,mh,omega):\n",
    "    ## age in Myr\n",
    "    ## returns mass in solar mass\n",
    "    basedir = path.join('..','data','MS_lifetime',f'w_i={omega:.1f}')\n",
    "    z_arr = get_zarr(omega)\n",
    "    mh_arr = np.log10(z_arr/0.01524)\n",
    "    mh = mh_arr[np.argmin(np.abs(mh_arr - mh))]\n",
    "    filename = f'lifetime_vs_mass{mh:.2f}.csv'   \n",
    "    df = pd.read_csv(path.join(basedir,filename))\n",
    "    idx = np.argmin(np.abs(df['lifetime'] - age*1e6))\n",
    "    return df['mass'][idx]\n",
    "\n",
    "def get_wd_cooling_age(m2,t2):\n",
    "    # in Myr\n",
    "    model = WD_models.load_model(low_mass_model='Bedard2020',\n",
    "                             middle_mass_model='Bedard2020',\n",
    "                             high_mass_model='ONe',\n",
    "                             atm_type='H',\n",
    "                             HR_bands=('FUV-NUV', 'NUV'))\n",
    "\n",
    "    m_logteff_to_agecool = WD_models.interp_xy_z_func(x=model['mass_array'],\n",
    "                                                  y=model['logteff'],\n",
    "                                                  z=model['age_cool'],\n",
    "                                                  interp_type='linear')\n",
    "    return m_logteff_to_agecool(m2, np.log10(t2)) * 1e3\n",
    "\n",
    "clstr_age = 762\n",
    "m2 = 0.81\n",
    "mh = 0.195\n",
    "omega = 0.0\n",
    "\n",
    "teff_lo = 12000\n",
    "teff_bst = 12500\n",
    "teff_hi = 13000\n",
    "\n",
    "wd_age_hi = get_wd_cooling_age(m2,teff_lo)\n",
    "wd_age_bst = get_wd_cooling_age(m2,teff_bst)\n",
    "wd_age_lo = get_wd_cooling_age(m2,teff_hi)\n",
    "ms_age_hi = clstr_age - wd_age_lo\n",
    "ms_age_bst = clstr_age - wd_age_bst\n",
    "ms_age_lo = clstr_age - wd_age_hi\n",
    "m1_hi = get_initial_mass(ms_age_lo,mh,omega)\n",
    "m1_bst = get_initial_mass(ms_age_bst,mh,omega)\n",
    "m1_lo = get_initial_mass(ms_age_hi,mh,omega)\n",
    "\n",
    "print(f'WD cooling age ~{int(wd_age_bst)} ({int(wd_age_lo)} to {int(wd_age_hi)})')\n",
    "print(f'Initial mass ~{m1_bst:.2f} ({m1_lo:.2f} to {m1_hi:.2f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = Table.read('../table_tristan.fits')\n",
    "\n",
    "agevec,mhvec,ebvvec = [],[],[]\n",
    "disvec = []\n",
    "age1vec,mh1vec,ebv1vec,m1vec,m1errvec = [],[],[],[],[]\n",
    "age2vec,mh2vec,ebv2vec,m2vec,m2errvec = [],[],[],[],[]\n",
    "age3vec,mh3vec,ebv3vec,m3vec,m3errvec = [],[],[],[],[]\n",
    "age4vec,mh4vec,ebv4vec,m4vec,m4errvec = [],[],[],[],[]\n",
    "\n",
    "\n",
    "for clstr in np.unique(sources['cluster']):\n",
    "    j = np.where(sources['idx'] == clstr + '_0')[0][0]\n",
    "    agevec.append(sources[j]['age'])\n",
    "    mhvec.append(sources[j]['mh_for_mass_interp'])\n",
    "    ebvvec.append(sources[j]['av_for_mass_interp']/3.1)\n",
    "    age1vec.append(sources[j]['age1'])\n",
    "    mh1vec.append(sources[j]['mh1'])\n",
    "    ebv1vec.append(sources[j]['av1']/3.1)\n",
    "    m1vec.append(sources[j]['m1'])\n",
    "    m1errvec.append(sources[j]['m1_err'])\n",
    "    age2vec.append(sources[j]['age2'])\n",
    "    mh2vec.append(sources[j]['mh2'])\n",
    "    ebv2vec.append(sources[j]['av2']/3.1)\n",
    "    m2vec.append(sources[j]['m1a'])\n",
    "    m2errvec.append(sources[j]['m1a_err'])\n",
    "    age3vec.append(sources[j]['age3'])\n",
    "    mh3vec.append(sources[j]['mh3'])\n",
    "    ebv3vec.append(sources[j]['av3']/3.1)\n",
    "    m3vec.append(sources[j]['m1b'])\n",
    "    m3errvec.append(sources[j]['m1b_err'])\n",
    "    age4vec.append(sources[j]['age4'])\n",
    "    mh4vec.append(sources[j]['mh4'])\n",
    "    ebv4vec.append(sources[j]['av4']/3.1)\n",
    "    m4vec.append(sources[j]['m1c'])\n",
    "    m4errvec.append(sources[j]['m1c_err'])\n",
    "    disvec.append(1000/sources[j]['parallax'])\n",
    "\n",
    "fig,ax = plt.subplots(dpi = 200)\n",
    "minvec = np.array([age1vec,age2vec,age3vec,age4vec]) - np.array([agevec,agevec,agevec,agevec])\n",
    "minvec = np.abs(minvec)\n",
    "modelvec = np.argmin(minvec,axis=0)\n",
    "minvec = np.min(minvec,axis=0)\n",
    "\n",
    "\n",
    "agevec = np.array(agevec)\n",
    "age1vec = np.array(age1vec)\n",
    "age2vec = np.array(age2vec)\n",
    "age3vec = np.array(age3vec)\n",
    "age4vec = np.array(age4vec)\n",
    "m1vec = np.array(m1vec)\n",
    "m2vec = np.array(m2vec)\n",
    "m3vec = np.array(m3vec)\n",
    "m4vec = np.array(m4vec)\n",
    "mh1vec = np.array(mh1vec)\n",
    "mh2vec = np.array(mh2vec)\n",
    "mh3vec = np.array(mh3vec)\n",
    "mh4vec = np.array(mh4vec)\n",
    "\n",
    "\n",
    "dmvec = np.array([m1vec-m2vec,m1vec-m3vec,m1vec-m4vec,m2vec-m3vec,m2vec-m4vec,m3vec-m4vec])\n",
    "dmvec = np.abs(dmvec)\n",
    "dmvec = np.max(dmvec,axis=0)\n",
    "dagevec = np.array([age1vec-age2vec,age1vec-age3vec,age1vec-age4vec,age2vec-age3vec,age2vec-age4vec,age3vec-age4vec])\n",
    "dagevec = np.abs(dagevec)\n",
    "dagevec = np.max(dagevec,axis=0)\n",
    "dmhvec = np.array([mh1vec-mh2vec,mh1vec-mh3vec,mh1vec-mh4vec,mh2vec-mh3vec,mh2vec-mh4vec,mh3vec-mh4vec])\n",
    "dmhvec = np.abs(dmhvec)\n",
    "dmhvec = np.max(dmhvec,axis=0)\n",
    "\n",
    "\n",
    "# ax.plot(np.sort(agevec),np.sort(agevec),ls='--',color='k',zorder=0)\n",
    "# ax.scatter(agevec,age1vec,label='PARSEC v1.2s',c='r',s=40,zorder=1)\n",
    "# ax.scatter(agevec,age2vec,label='PARSEC v2.0 $\\omega_i=0.0$',c='g',s=30,zorder=2)\n",
    "# ax.scatter(agevec,age3vec,label='PARSEC v2.0 $\\omega_i=0.3$',c='b',s=20,zorder=3)\n",
    "# ax.scatter(agevec,age4vec,label='PARSEC v2.0 $\\omega_i=0.6$',c='m',s=10,zorder=4)\n",
    "# ax.set_xlim(0,800)\n",
    "# ax.set_ylim(0,800)\n",
    "# ax.set_xlabel('Literature Age (Myr)')\n",
    "# ax.set_ylabel('Age (Myr)')\n",
    "\n",
    "# ax.plot(np.sort(mhvec),np.sort(mhvec),ls='--',color='k',zorder=0)\n",
    "# ax.scatter(mhvec,mh1vec,label='PARSEC v1.2s',c='r',s=40,zorder=1)\n",
    "# ax.scatter(mhvec,mh2vec,label='PARSEC v2.0 $\\omega_i=0.0$',c='g',s=30,zorder=2)\n",
    "# ax.scatter(mhvec,mh3vec,label='PARSEC v2.0 $\\omega_i=0.3$',c='b',s=20,zorder=3)\n",
    "# ax.scatter(mhvec,mh4vec,label='PARSEC v2.0 $\\omega_i=0.6$',c='m',s=10,zorder=4)\n",
    "# ax.set_xlabel('Literature [M/H] (dex)')\n",
    "# ax.set_ylabel('[M/H] (dex)')\n",
    "\n",
    "# for m in [0,1,2,3]:\n",
    "#     cut = (modelvec == m)\n",
    "#     if m == 0:\n",
    "#         label = 'PARSEC v1.2s'\n",
    "#     elif m == 1:\n",
    "#         label = 'PARSEC v2.0 $\\omega_i = 0.0$'\n",
    "#     elif m == 2:\n",
    "#         label = 'PARSEC v2.0 $\\omega_i = 0.3$'\n",
    "#     elif m == 3:\n",
    "#         label = 'PARSEC v2.0 $\\omega_i = 0.6$'\n",
    "#     ax.scatter(np.array(mhvec)[cut],np.array(minvec)[cut],label=label)\n",
    "# ax.set_xlabel('Literature [M/H] (dex)')\n",
    "# ax.set_ylabel('Max Age Error (Myr)')\n",
    "\n",
    "for m in [0,1,2,3]:\n",
    "    cut = (modelvec == m)\n",
    "    if m == 0:\n",
    "        label = 'PARSEC v1.2s'\n",
    "    elif m == 1:\n",
    "        label = 'PARSEC v2.0 $\\omega_i = 0.0$'\n",
    "    elif m == 2:\n",
    "        label = 'PARSEC v2.0 $\\omega_i = 0.3$'\n",
    "    elif m == 3:\n",
    "        label = 'PARSEC v2.0 $\\omega_i = 0.6$'\n",
    "    ax.scatter(np.array(agevec)[cut],np.array(minvec)[cut],label=label)\n",
    "ax.set_xlabel('Literature Age (Myr)')\n",
    "ax.set_ylabel('Max Age Error (Myr)')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=6</i>\n",
       "<table id=\"table131897489129424\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>idx</th><th>phot_g_mean_mag</th><th>age</th><th>m1</th><th>teff1</th><th>m2</th><th>period</th><th>eccentricity</th><th>nuv_mag</th><th>fuv_mag</th><th>mh_for_mass_interp</th><th>av_for_mass_interp</th><th>l</th><th>b</th></tr></thead>\n",
       "<thead><tr><th></th><th>mag</th><th></th><th></th><th></th><th></th><th>d</th><th></th><th></th><th></th><th></th><th></th><th>deg</th><th>deg</th></tr></thead>\n",
       "<thead><tr><th>bytes15</th><th>float32</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>FSR_0398_0</td><td>12.800576</td><td>21.577449798583984</td><td>2.5277128225155834</td><td>10678.326257315708</td><td>1.1106687586593218</td><td>270.0103338094788</td><td>0.16093534535037357</td><td>17.425127</td><td>--</td><td>0.2879999876022339</td><td>1.9589999914169312</td><td>108.82722083240834</td><td>5.031208513724868</td></tr>\n",
       "<tr><td>NGC_2099_0</td><td>13.293033</td><td>608.1355590820312</td><td>1.6056298925273493</td><td>7407.176867792029</td><td>1.1116349123934164</td><td>983.3979926461742</td><td>0.4087145124097095</td><td>--</td><td>--</td><td>0.014000000432133675</td><td>0.921999990940094</td><td>178.03403351313932</td><td>3.693854228958652</td></tr>\n",
       "<tr><td>NGC_2632_0</td><td>10.339978</td><td>762.0789794921875</td><td>1.2347891403781002</td><td>6066.230462159834</td><td>0.8106310410157176</td><td>142.76272558382473</td><td>0.19136618988207196</td><td>--</td><td>21.0648956</td><td>0.19599999487400055</td><td>0.03200000151991844</td><td>206.2784719173449</td><td>33.43102140001032</td></tr>\n",
       "<tr><td>NGC_6475_0</td><td>13.397923</td><td>272.897705078125</td><td>0.8674997032064846</td><td>4686.135992863516</td><td>0.5005076222920907</td><td>178.47568712985222</td><td>0.22805369397764308</td><td>--</td><td>--</td><td>0.01899999938905239</td><td>0.37700000405311584</td><td>355.8898991926016</td><td>-5.566333818026338</td></tr>\n",
       "<tr><td>Roslund_6_2</td><td>12.64903</td><td>258.82135009765625</td><td>1.0332558913569267</td><td>5281.848765277762</td><td>0.9145440755987587</td><td>265.43232336307216</td><td>0.6111320219689335</td><td>--</td><td>--</td><td>0.07800000160932541</td><td>0.12300000339746475</td><td>79.7824886942358</td><td>1.4457829445488999</td></tr>\n",
       "<tr><td>SAI_118_0</td><td>12.360745</td><td>24.660404205322266</td><td>3.803284408251827</td><td>15836.741819578647</td><td>1.7650663366442796</td><td>755.8324759562555</td><td>0.699874882530523</td><td>--</td><td>--</td><td>0.052000001072883606</td><td>1.1119999885559082</td><td>308.7339557748028</td><td>-0.8725977668272873</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=6>\n",
       "    idx     phot_g_mean_mag ...         l                   b         \n",
       "                  mag       ...        deg                 deg        \n",
       "  bytes15       float32     ...      float64             float64      \n",
       "----------- --------------- ... ------------------ -------------------\n",
       " FSR_0398_0       12.800576 ... 108.82722083240834   5.031208513724868\n",
       " NGC_2099_0       13.293033 ... 178.03403351313932   3.693854228958652\n",
       " NGC_2632_0       10.339978 ...  206.2784719173449   33.43102140001032\n",
       " NGC_6475_0       13.397923 ...  355.8898991926016  -5.566333818026338\n",
       "Roslund_6_2        12.64903 ...   79.7824886942358  1.4457829445488999\n",
       "  SAI_118_0       12.360745 ...  308.7339557748028 -0.8725977668272873"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources['idx','phot_g_mean_mag','age','m1','teff1','m2','period','eccentricity','nuv_mag','fuv_mag','mh_for_mass_interp','av_for_mass_interp','l','b']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
