{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from astropy import table\n",
    "from astroquery.gaia import Gaia\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import scoreatpercentile\n",
    "from scipy.interpolate import RBFInterpolator, LinearNDInterpolator\n",
    "import stam\n",
    "from tqdm import tqdm\n",
    "import WD_models\n",
    "from os import path\n",
    "import extinction\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "# clusters = Table.read('../data/hunt_clusters/clusters.csv')\n",
    "# members = Table.read('../data/hunt_clusters/members.csv')\n",
    "sources = Table.read('../table_C.fits', format='fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from astroquery.vizier import Vizier\n",
    "# clstrs = Vizier(catalog='J/MNRAS/504/356',columns=['Cluster','N','logage','e_logage','[Fe/H]','e_[Fe/H]','Av','e_Av','FileName'],row_limit=-1).query_constraints()[0]\n",
    "\n",
    "# clstrs.rename_columns(clstrs.colnames,['Cluster','N','logage','e_logage','Fe/H','e_Fe/H','Av','e_Av','FileName'])\n",
    "# # sources = Table.read('../table_extra.fits')\n",
    "# sources['idx'] = np.full(len(sources),'---',dtype=object)\n",
    "\n",
    "# cut = (sources['nss_solution_type'] == 'Orbital') | (sources['nss_solution_type'] == 'AstroSpectroSB1')\n",
    "# sources = sources[cut]\n",
    "\n",
    "# nms = np.unique(sources['cluster'])\n",
    "# for n in nms:\n",
    "#     for i, s in enumerate(sources[sources['cluster'] == n]):\n",
    "#         j = np.where(sources['source_id'] == s['source_id'])[0][0]\n",
    "#         sources[j]['idx'] = n+'_'+str(i)\n",
    "\n",
    "# sources['idx'] = sources['idx'].astype(str)\n",
    "# sources['age'] = np.full(len(sources),np.nan)\n",
    "# sources['[Fe/H]'] = np.full(len(sources),np.nan)\n",
    "# sources['Av'] = np.full(len(sources),np.nan)\n",
    "\n",
    "# for j in range(len(sources)):\n",
    "#     if sources[j]['cluster'] == 'Hyades':\n",
    "#         sources[j]['age'] = 680\n",
    "#         sources[j]['[Fe/H]'] = 0.14\n",
    "#         sources[j]['Av'] = 0.01 * 3.1\n",
    "#     if sources[j]['cluster'] == 'IC_2602':\n",
    "#         sources[j]['age'] = 60\n",
    "#         sources[j]['[Fe/H]'] = -0.02\n",
    "#         sources[j]['Av'] = 0.05 * 3.1\n",
    "#     if sources[j]['cluster'] == 'NGC_2287':\n",
    "#         sources[j]['age'] = 200\n",
    "#         sources[j]['[Fe/H]'] = -0.11\n",
    "#         sources[j]['Av'] = 0.03 * 3.1\n",
    "#     if sources[j]['cluster'] == 'NGC_2547':\n",
    "#         sources[j]['mh'] = 60\n",
    "#         sources[j]['[Fe/H]'] = 0.01\n",
    "#         sources[j]['Av'] = 0.06 * 3.1\n",
    "\n",
    "# for j in range(len(sources)):\n",
    "#     clstr = sources[j]['cluster']\n",
    "#     if clstr in clstrs['cluster']:\n",
    "#         i = np.where(clstrs['cluster'] == clstr)[0][0]\n",
    "#         sources[j]['age'] = clstrs[i]['age']\n",
    "#         sources[j]['[Fe/H]'] = clstrs[i]['Fe_H']\n",
    "#         sources[j]['Av'] = clstrs[i]['ebv'] * 3.1\n",
    "    \n",
    "# sources.sort('idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARSEC functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "PARSEC_path = '../OCFit/gaiaDR2/grids/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "\n",
    "\n",
    "def choose_model(mh):\n",
    "    if (-0.6 <= mh) and (mh <= 0.05):\n",
    "        PARSEC_path = '../data/PARSECv2.0/w_i=0.6/'\n",
    "        models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "    else:\n",
    "        PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "        models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "    return PARSEC_path,models\n",
    "\n",
    "def get_tracks(mh,age):\n",
    "    \n",
    "    color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation    \n",
    "    age_res = np.min(abs(10**np.unique(models['logAge'].data) * 1e-9 - age * 1e-3)) * 1.05 + 1e-3\n",
    "    mh_res = np.min(abs(np.unique(models['MH'].data) - mh)) + 0.005\n",
    "   \n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 5  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 8  # [Msun]\n",
    "    tracks = stam.gentracks.get_isotrack(models, [age * 1e-3, mh], params=(\"age\", \"mh\"), return_table=True,\n",
    "                                    age_res=age_res, mass_min=mass_min, mass_max=mass_max, mh_res = mh_res,\n",
    "                                    stage=None, stage_min=stage_min, stage_max=stage_max, sort_by=\"age\", color_filter1=color_fil_1, color_filter2=color_fil_2,\n",
    "                mag_filter=mag_fil)\n",
    "    return tracks\n",
    "\n",
    "def get_track_idx(mh,age):\n",
    "    color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation    \n",
    "    age_res = np.min(abs(10**np.unique(models['logAge'].data) * 1e-9 - age * 1e-3)) * 1.05\n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 5  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 8  # [Msun]\n",
    "    track_idx = stam.gentracks.get_isotrack(models, [age * 1e-3, mh], params=(\"age\", \"mh\"), return_idx=True,\n",
    "                                    age_res=age_res, mass_min=mass_min, mass_max=mass_max, mh_res = 0.025,\n",
    "                                    stage=None, stage_min=stage_min, stage_max=stage_max, sort_by=\"age\", color_filter1=color_fil_1, color_filter2=color_fil_2,\n",
    "                mag_filter=mag_fil)   \n",
    "    return track_idx\n",
    "\n",
    "def get_age_mh_grid():\n",
    "    age = 10**np.unique(models['logAge'].data) * 1e-6\n",
    "    mh = np.unique(models['MH'].data)\n",
    "    age,mh = np.meshgrid(age,mh)\n",
    "    return age,mh\n",
    "\n",
    "\n",
    "# c = (models['label'] <= 5) & (models['Mini']<=8)\n",
    "# p1 = models[c]['Mass']\n",
    "# p2 = models[c]['logAge']\n",
    "# p3 = models[c]['MH']\n",
    "# pdep1 = models[c]['G_BPmag'] - models[c]['G_RPmag']\n",
    "# pdep2 = models[c]['Gmag']\n",
    "\n",
    "# mass_to_mag = LinearNDInterpolator(np.vstack(list(zip(p1,p2,p3))), pdep2)\n",
    "# mass_to_color = LinearNDInterpolator(np.vstack(list(zip(p1,p2,p3))), pdep1)\n",
    "\n",
    "# def get_isochrone(mh,age):\n",
    "#     mass_arr = get_tracks(mh,age)['mass']\n",
    "#     gmag = mass_to_mag(mass_arr,np.log10(age*1e6),mh)\n",
    "#     bprp = mass_to_color(mass_arr,np.log10(age*1e6),mh)\n",
    "#     return Table([mass_arr,bprp,gmag],names=['mass','bp_rp','mg'])\n",
    "\n",
    "# _ = get_isochrone(0,101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster parameters and primary mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mass interpolations, cluster cmd plots\n",
    "\n",
    "def tracks2grid(tracks, xparam = \"bp_rp\", yparam = \"mg\", xstep=0.05, ystep=0.05):\n",
    "    # auxiliary to interp_mass_realization\n",
    "    xmin = np.min(np.around(tracks[xparam], -int(np.round(np.log10(xstep)))))\n",
    "    xmax = np.max(np.around(tracks[xparam], -int(np.round(np.log10(xstep)))))\n",
    "    ymin = np.min(np.around(tracks[yparam], -int(np.round(np.log10(ystep)))))\n",
    "    ymax = np.max(np.around(tracks[yparam], -int(np.round(np.log10(ystep)))))\n",
    "    x, y = np.meshgrid(np.arange(xmin, xmax, xstep), np.arange(ymin, ymax, ystep))\n",
    "            \n",
    "    return x, y, xmin, xmax, ymin, ymax\n",
    "\n",
    "def interp_mass_realization(age,mh,av,bp_rp,mg):\n",
    "    # For a single realization of cluster and source parameters, interpolate the mass\n",
    "\n",
    "    # get the isotrack for this realization of the cluster parameters\n",
    "    tracks = get_tracks(mh,age)\n",
    "    x = np.array(tracks[\"bp_rp\"])\n",
    "    y = np.array(tracks[\"mg\"])\n",
    "    z = np.array(tracks[\"mass\"])\n",
    "    # Add small noise to the isochrone (to avoid singularity problems)\n",
    "    x = x + np.random.normal(0, 0.0001, len(x))\n",
    "    y = y + np.random.normal(0, 0.0001, len(y))\n",
    "    z = z + np.random.normal(0, 0.0001, len(z))\n",
    "    # apply extinction to the isochrone\n",
    "    ag, e_bprp = extinction.get_AG_EBPRP(av,x)\n",
    "    y = y + ag\n",
    "    x = x + e_bprp\n",
    "    # interpolate this instance of color and magnitude along the isochrone\n",
    "    xstep, ystep = 0.05, 0.05\n",
    "    grid_x, grid_y, xmin, xmax, ymin, ymax = tracks2grid(tracks, xstep=xstep, ystep=ystep)    \n",
    "    fun_type = \"linear\"\n",
    "    interp = RBFInterpolator(np.array([x, y]).T, z, kernel=fun_type)\n",
    "    grid = np.array([grid_x, grid_y])\n",
    "    grid_flat = grid.reshape(2, -1).T\n",
    "    grid_z = interp(grid_flat).reshape(grid_x.shape)\n",
    "    mass = interp(np.array([[bp_rp, mg]]))[0]\n",
    "    return mass\n",
    "\n",
    "def photometric_mass(idx,save=False,plot=False,n_realizations=100):        \n",
    "    # Run monte carlo simulation to estimate primary pass and error\n",
    "    j = np.where(sources['idx'] == idx)[0][0]\n",
    "    age, e_age = sources[j]['age'], sources[j]['e_age']\n",
    "    mh, e_mh = sources[j]['[Fe/H]'], sources[j]['e_[Fe/H]']\n",
    "    av, e_av = sources[j]['Av'], sources[j]['e_Av']\n",
    "    mg = sources[j]['mg']\n",
    "    bp_rp = sources[j]['bp_rp']\n",
    "\n",
    "    # estimate photometric errors\n",
    "    e_g= 2.5*np.log(10)*sources[j]['phot_g_mean_flux_error']/sources[j]['phot_g_mean_flux']\n",
    "    e_mg = np.sqrt(e_g**2 + (2.17 / sources[j]['parallax_over_error'])**2)\n",
    "    e_bp = 2.5 * np.log(10) * sources[j]['phot_bp_mean_flux_error'] / sources[j]['phot_bp_mean_flux']\n",
    "    e_rp = 2.5 * np.log(10) * sources[j]['phot_rp_mean_flux_error'] / sources[j]['phot_rp_mean_flux']\n",
    "    e_bp_rp = np.sqrt(e_bp**2 + e_rp**2)\n",
    "\n",
    "    # run monte carlo simulation\n",
    "    age_vec = np.random.normal(age,e_age,n_realizations)\n",
    "    mh_vec = np.random.normal(mh,e_mh,n_realizations)\n",
    "    av_vec = np.random.normal(av,e_av,n_realizations)\n",
    "    bp_rp_vec = np.random.normal(bp_rp,e_bp_rp,n_realizations)\n",
    "    mg_vec = np.random.normal(mg,e_mg,n_realizations)\n",
    "    mass_vec = np.zeros(n_realizations)\n",
    "    for i in range(n_realizations):\n",
    "        try:\n",
    "            mass_vec[i] = interp_mass_realization(age_vec[i],mh_vec[i],av_vec[i],bp_rp_vec[i],mg_vec[i])\n",
    "        except:\n",
    "            mass_vec[i] = np.nan\n",
    "    m1 = np.nanmean(mass_vec)\n",
    "    m1_err = np.nanstd(mass_vec)\n",
    "    plot_mass_interp(age,mh,av,bp_rp,mg,m1,m1_err,idx,sources[j]['cluster'],save,plot)\n",
    "    return m1,m1_err\n",
    "\n",
    "def get_cluster_members(cluster):\n",
    "    # read the cluster member data from our premade files, apply quality cuts\n",
    "\n",
    "    filepath = path.join('..','OCFit','gaiaDR2','data',cluster+'.dat')\n",
    "    obs = np.genfromtxt(filepath,names=True,delimiter=',',dtype=None)\n",
    "    if path.exists(filepath.replace('.dat','_D.dat')):\n",
    "        obsD = np.genfromtxt(filepath.replace('.dat','_D.dat'),names=True,delimiter=',',dtype=None)\n",
    "        obs = np.concatenate((obs,obsD))\n",
    "\n",
    "    mg = obs['Gmag'] - 5 * np.log10(1000/obs['Plx']) + 5\n",
    "    #remove nans para fazer os plots\n",
    "    cond1 = np.isfinite(obs['Gmag'])\n",
    "    cond2 = np.isfinite(obs['BPmag'])\n",
    "    cond3 = np.isfinite(obs['RPmag'])\n",
    "    \n",
    "    cond4 = obs['RFG'] > 50.0\n",
    "    cond5 = obs['RFBP'] > 20.0\n",
    "    cond6 = obs['RFRP'] > 20.0\n",
    "    cond7 = obs['E_BR_RP_'] < 1.3+0.06*(obs['BPRP'])**2\n",
    "    cond8 = obs['E_BR_RP_'] > 1.0+0.015*(obs['BPRP'])**2\n",
    "    cond9 = obs['Nper'] > 8\n",
    "    cond10 = obs['fidelity_v2'] > 0.5\n",
    "    cond11 = (mg < 9) | (obs['BPRP'] > 0)       \n",
    "    ind  = np.where(cond1&cond2&cond3&cond4&cond5&cond6&cond7&cond8&cond9&cond10&cond11)\n",
    "    obs = obs[ind]\n",
    "    obs = Table(obs)\n",
    "    obs = table.unique(obs,keys='source_id')\n",
    "    return obs\n",
    "    \n",
    "def plot_cmd(idx,cluster,age,mh,ebv,save,plot):\n",
    "        memb = get_cluster_members(cluster)\n",
    "        memb['mg'] = memb['Gmag'] - 5 * np.log10(1000/memb['Plx']) + 5\n",
    "\n",
    "        mg = memb['mg']\n",
    "        bp_rp = memb['BPRP']\n",
    "        mg0 = sources[sources['idx']== idx]['mg']\n",
    "        bp_rp0= sources[sources['idx']== idx]['bp_rp']\n",
    "\n",
    "        track = get_tracks(mh,age)\n",
    "        bp_rp_model = np.array(track['bp_rp'])\n",
    "        mg_model = np.array(track['mg'])\n",
    "        ag, e_bprp = extinction.get_AG_EBPRP(3.1*ebv,bp_rp_model)\n",
    "        mg_model = mg_model + ag\n",
    "        bp_rp_model = bp_rp_model + e_bprp\n",
    "\n",
    "        fig,ax = plt.subplots(dpi=300)\n",
    "        ax.scatter(bp_rp,mg,s=5,c='r',label='Cluster members',zorder=5)\n",
    "        ax.scatter(bp_rp0,mg0,s=25,c='g',label='Candidate',zorder = 10)\n",
    "        ax.plot(bp_rp_model,mg_model, 'ko', markersize=1,label=f'PARSEC age={int(age)} Myr, [Fe/H]={mh:.2f}, E(B-V)={ebv:.3f}')\n",
    "        ax.set_xlabel('BP-RP')\n",
    "        ax.set_ylabel('G')\n",
    "        ax.invert_yaxis()\n",
    "        ax.legend(loc='lower left',frameon=False)\n",
    "        ax.set_title('Candidate '+ str(idx) + ' in cluster ' + cluster)\n",
    "        if save:\n",
    "            fig.savefig(f'../img/cmd/{idx}_'+cluster+'.png')\n",
    "        if not plot:\n",
    "            plt.close()\n",
    "\n",
    "def plot_mass_interp(age,mh,av,bp_rp,mg,m1,m1_err,idx,clstr,save,plot):\n",
    "    # For the final mass estimate, plot the mass interpolation\n",
    "    tracks = get_tracks(mh,age)\n",
    "    x = np.array(tracks[\"bp_rp\"])\n",
    "    y = np.array(tracks[\"mg\"])\n",
    "    z = np.array(tracks[\"mass\"])\n",
    "    # Add small noise to the isochrone (to avoid singularity problems)\n",
    "    x = x + np.random.normal(0, 0.0001, len(x))\n",
    "    y = y + np.random.normal(0, 0.0001, len(y))\n",
    "    z = z + np.random.normal(0, 0.0001, len(z))\n",
    "    # apply extinction to the isochrone\n",
    "    ag, e_bprp = extinction.get_AG_EBPRP(av,x)\n",
    "    y = y + ag\n",
    "    x = x + e_bprp\n",
    "    # interpolate this instance of color and magnitude along the isochrone\n",
    "    xstep, ystep = 0.05, 0.05\n",
    "    grid_x, grid_y, xmin, xmax, ymin, ymax = tracks2grid(tracks, xstep=xstep, ystep=ystep)    \n",
    "    fun_type = \"linear\"\n",
    "    interp = RBFInterpolator(np.array([x, y]).T, z, kernel=fun_type)\n",
    "    grid = np.array([grid_x, grid_y])\n",
    "    grid_flat = grid.reshape(2, -1).T\n",
    "    grid_z = interp(grid_flat).reshape(grid_x.shape)\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(dpi=300, tight_layout=True)\n",
    "    ax.plot(x, y, 'ko', markersize=1,label=f'PARSEC age={int(age)} Myr, [Fe/H]={mh:.2f}, E(B-V)={av/3.1:.3f}')\n",
    "    h = ax.imshow(grid_z, origin=\"lower\", extent=[xmin, xmax, ymin, ymax], cmap='Oranges', aspect='auto')\n",
    "    ax.scatter(bp_rp,mg,s=25,c='g',label=f'Candidate $M_1$={m1:.2f} $\\pm$ {m1_err:.2f} $M_\\odot$',zorder = 10)\n",
    "    plt.colorbar(h, label=r\"Mass (M$_\\odot$)\")\n",
    "    ax.set_xlabel(r\"$G_\\text{BP}-G_\\text{RP}$\")\n",
    "    ax.set_ylabel(r\"$G$\")\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_title(f'Candidate {idx} in cluster {clstr}')\n",
    "    ax.invert_yaxis()\n",
    "    ax.legend(loc='lower left',frameon=False,fontsize=8)\n",
    "    \n",
    "    if save:\n",
    "        fig.savefig(f'../img/mass_interp/{idx}_'+clstr+'.png')\n",
    "    if not plot:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = False\n",
    "save = True\n",
    "sources = Table.read('../table_B.fits')\n",
    "new_sources = sources.copy()\n",
    "m1_col = []\n",
    "m1_err_col = []\n",
    "\n",
    "# fitting all with parsec v1.2S\n",
    "# PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "PARSEC_path = '../OCFit/gaiaDR2/grids/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "for idx in new_sources['idx']:\n",
    "    age = new_sources[new_sources['idx'] == idx]['age'][0]\n",
    "    mh = new_sources[new_sources['idx'] == idx]['[Fe/H]'][0]\n",
    "    ebv = new_sources[new_sources['idx'] == idx]['Av'][0] / 3.1\n",
    "    cluster = new_sources[new_sources['idx'] == idx]['cluster'][0]\n",
    "    if np.isnan(age):\n",
    "        # if unable to fit age, skip the candidate\n",
    "        # new_sources.remove_row(np.where(new_sources['idx'] == idx)[0][0])\n",
    "        m1_col.append(np.nan)\n",
    "        m1_err_col.append(np.nan)\n",
    "    else:\n",
    "        try:\n",
    "            print(f'Photometric mass for candidate {idx}...')\n",
    "            m1, m1_err = photometric_mass(idx,save=True,plot=False,n_realizations=100)\n",
    "            m1_col.append(m1)\n",
    "            m1_err_col.append(m1_err)\n",
    "        except:\n",
    "            print(f'Error in photometric mass for candidate {idx}')\n",
    "            m1_col.append(np.nan)\n",
    "            m1_err_col.append(np.nan)\n",
    "        plot_cmd(idx,cluster,age,mh,ebv,save,plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "new_sources['m1'] = m1_col\n",
    "new_sources['m1_err'] = m1_err_col\n",
    "\n",
    "# new_sources.write('../table_B.fits',overwrite=True)\n",
    "sources = new_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions, gaia passbands\n",
    "\n",
    "# ------------ AMRF limits ----------------\n",
    "from astropy.io import ascii\n",
    "from synphot import SourceSpectrum, ReddeningLaw\n",
    "from synphot.models import BlackBodyNorm1D\n",
    "from synphot.units import convert_flux\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "import json \n",
    "from uncertainties import unumpy as unp, ufloat\n",
    "from uncertainties import correlated_values_norm, correlation_matrix\n",
    "import warnings\n",
    "\n",
    "def blackbody(temperature, wavelength, ebv=None, extinction_model='mwavg'):\n",
    "    bb = SourceSpectrum(BlackBodyNorm1D, temperature=temperature*u.K)  # [photons s^-1 cm^-2 A^-1]\n",
    "    # if ebv is not None:\n",
    "    #     # apply extinction\n",
    "    #     ext = ReddeningLaw.from_extinction_model(extinction_model).extinction_curve(ebv)\n",
    "    #     bb = bb * ext\n",
    "    bb = bb(wavelength)/(const.R_sun / const.kpc) ** 2  # undo synphot normalization (but leave the pi factor from integration over half a sphere)\n",
    "    bb = convert_flux(wavelength, bb, 'flam')  # [flam] = [erg s^-1 cm^-2 A^-1]\n",
    "    bb = bb.to(u.erg/u.s/u.cm**2/u.angstrom)  # express in normal astropy units\n",
    "    return bb\n",
    "\n",
    "\n",
    "def mlogg2radius(m, logg):\n",
    "    g = 10**logg*u.cm/u.s**2\n",
    "    r = np.sqrt(const.G*m/g)\n",
    "    return r.to(u.Rsun).value\n",
    "\n",
    "\n",
    "def calc_synth_phot(wavelength, flux, bandpass):\n",
    "    dlambda = np.diff(wavelength)\n",
    "    dlambda = np.concatenate([dlambda, np.array([dlambda[-1]])])\n",
    "\n",
    "    # assuming a photon-counting device\n",
    "    phot = np.sum(dlambda*bandpass*wavelength*flux)/np.sum(dlambda*bandpass*wavelength)\n",
    "    \n",
    "    return phot\n",
    "\n",
    "\n",
    "amrf = lambda q, S : q/(1+q)**(2/3)*(1 - S*(1+q)/(q*(1+S)))\n",
    "\n",
    "gaia_passband = ascii.read('../data/other/passband.dat', names=[\"wl\", \"gPb\", \"gPbError\", \"bpPb\", \"bpPbError\", \"rpPb\", \"rpPbError\"])\n",
    "\n",
    "# replace missing values with NaNs\n",
    "for col in gaia_passband.itercols():\n",
    "    col[col == 99.99] = 0\n",
    "    \n",
    "gaia_passband['wl'] *= 10  # [A]\n",
    "\n",
    "# ---------- AMRF -------------------\n",
    "\n",
    "limiting_curves = Table.read('../data/other/AMRF_limiting_curves.fits')\n",
    "# Retrieve the conservative limiting AMRF values for some primary mass\n",
    "# --------------\n",
    "def Atr(m1):\n",
    "    j = np.argmin(np.abs(m1 - limiting_curves['m1'].data))\n",
    "    return limiting_curves['Atr'][j]\n",
    "def Ams(m1):\n",
    "    j = np.argmin(np.abs(m1 - limiting_curves['m1'].data))\n",
    "    return limiting_curves['Ams'][j]\n",
    "\n",
    "# =============================================================================\n",
    "#                Auxil routines to obtain the covariance matrix\n",
    "# =============================================================================\n",
    "\n",
    "# 1) get the list of parameters from the solution type\n",
    "def get_par_list(solution_type=None):\n",
    "    if (solution_type is None) or (solution_type=='Orbital'):\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'eccentricity', 'period', 't_periastron')\n",
    "\n",
    "    elif (solution_type=='OrbitalAlternative') or (solution_type=='OrbitalAlternativeValidated') \\\n",
    "            or (solution_type=='OrbitalTargetedSearch') or (solution_type=='OrbitalTargetedSearchValidated'):\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'period', 'eccentricity', 't_periastron')\n",
    "\n",
    "    elif solution_type=='AstroSpectroSB1':\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'c_thiele_innes', 'h_thiele_innes', 'center_of_mass_velocity',\n",
    "                'eccentricity', 'period', 't_periastron')\n",
    "\n",
    "\n",
    "# 2) Get the order of parameters in the covariance matrix, for a given bit index.\n",
    "def bit_index_map(bit_index):\n",
    "    if bit_index==8191:\n",
    "        return ['ra','dec','parallax','pmra','pmdec','A','B','F','G', 'e','P', 'T']\n",
    "    elif bit_index==8179:\n",
    "        return ['ra','dec','parallax','pmra','pmdec','A','B','F','P', 'T']\n",
    "    elif bit_index==65535:\n",
    "        return ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'A', 'B', 'F', 'G', 'C', 'H', 'gamma','e', 'P', 'T']\n",
    "    elif bit_index==65435:\n",
    "        return ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'A', 'B', 'F', 'H', 'gamma', 'P', 'T']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# 3) Generate the correlation matrix\n",
    "def make_corr_matrix(input_table, pars=None):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    input_table nss_two_body_orbit table.\n",
    "    pars : list\n",
    "            list of parameters for the corresponding solution of the desired\n",
    "              target, in the same order as they appear in the Gaia table.\n",
    "      \"\"\"\n",
    "    if pars is None:\n",
    "        pars = get_par_list()\n",
    "\n",
    "    # read the correlation vector\n",
    "    s1 = input_table['corr_vec'].replace('\\n','')   \n",
    "    s1 = s1.replace(' ',',')\n",
    "    s1 = s1.replace('--','0')\n",
    "    corr_vec = list(json.loads(s1))\n",
    "    # set the number of parameters in the table\n",
    "    n_pars = len(pars)\n",
    "    # define the correlation matrix.\n",
    "    corr_mat = np.ones([n_pars, n_pars], dtype=float)\n",
    "\n",
    "    # Read the matrix (lower triangle)\n",
    "    ind = 0\n",
    "    for i in range(n_pars):\n",
    "        for j in range(i):\n",
    "            corr_mat[j][i] = corr_vec[ind]\n",
    "            corr_mat[i][j] = corr_vec[ind]\n",
    "            ind += 1\n",
    "\n",
    "    return corr_mat\n",
    "\n",
    "\n",
    "# 4) Get the NSS data \n",
    "def get_nss_data(input_table, source_id):\n",
    "\n",
    "    target_idx = np.argwhere(input_table['source_id'] == source_id)[0][0]\n",
    "    pars = get_par_list(input_table['nss_solution_type'][target_idx])\n",
    "    corr_mat = make_corr_matrix(input_table[target_idx], pars=pars)\n",
    "\n",
    "    mu, std = np.zeros(len(pars)), np.zeros(len(pars))\n",
    "    for i, par in enumerate(pars):\n",
    "        try:\n",
    "            mu[i] = input_table[par][target_idx]\n",
    "            std[i] = input_table[par + '_error'][target_idx]\n",
    "        except KeyError:\n",
    "            mu[i], std[i] = np.nan, np.nan\n",
    "\n",
    "    nan_idxs = np.argwhere(np.isnan(corr_mat))\n",
    "    corr_mat[nan_idxs[:, 0], nan_idxs[:, 1]] = 0.0\n",
    "\n",
    "    return mu, std, corr_mat\n",
    "\n",
    "def multivar_sample(mu, sigma, corr, n):\n",
    "    cov = corr*(sigma[:, None] * sigma[None, :])\n",
    "    # l = spla.cholesky(cov)\n",
    "    # z = np.random.normal(size=(n, mu.shape[0]))\n",
    "    # return z.dot(l) + mu\n",
    "    return np.random.multivariate_normal(mu, cov, size=n)\n",
    "\n",
    "# =============================================================================\n",
    "#                      calc parameters.\n",
    "# =============================================================================\n",
    "# Here we calculate the AMRF, qmin, etc, assuming that the mass of the luminous star \n",
    "# is exactly one solar mass. This is just for the red-clump stars...\n",
    "def calc_AMRF(par_in, par_in_errors, corr_matrix, m1, bit_index=8191):\n",
    "    \"\"\"\n",
    "    For the given set of orbital parameters by Gaia, this function calculates\n",
    "    the standard geometrical elements (a, omega, Omega, and i). If the error\n",
    "    estimates and covariance matrix are prodived, the error estimates on the\n",
    "    calculated parameters are returned as well.\n",
    "\n",
    "    Input: thiele_innes: Thiele Innes parameters [A,B,F,G] in milli-arcsec\n",
    "           thiele_innes_errors : Corresponding errors.\n",
    "           corr_matrix : Corresponding  4X4 correlation matrix.\n",
    "\n",
    "  Output: class-III probability via monte carlo\n",
    "    \"\"\"\n",
    "    # Read the coefficients and assign the correlation matrix.\n",
    "    # Create correlated quantities. If the error is nan we assume 1e-6...\n",
    "    par_in_errors[np.isnan(par_in_errors)] = 1e-6\n",
    "    par_list = correlated_values_norm([(par_in[i], par_in_errors[i]) for i in np.arange(len(par_in))], corr_matrix)\n",
    "    key_list = bit_index_map(bit_index)\n",
    "\n",
    "    par = {key_list[i]: par_list[i] for i in np.arange(len(key_list))}\n",
    "    par['mass'] = m1\n",
    "\n",
    "    # Add the G Thiele-Innes parameter if needed.\n",
    "    if (bit_index == 8179) | (bit_index == 65435):\n",
    "        G = -par['A']*par['F']/par['B']\n",
    "    else:\n",
    "        G = par['G']\n",
    "\n",
    "    # This in an intermediate step in the formulae...\n",
    "    p = (par['A'] ** 2 + par['B'] ** 2 + G ** 2 + par['F'] ** 2) / 2.\n",
    "    q = par['A'] * G - par['B'] * par['F']\n",
    "\n",
    "    # Calculate the angular semimajor axis (already in mas)\n",
    "    a_mas = unp.sqrt(p + unp.sqrt(p ** 2 - q ** 2))\n",
    "\n",
    "    # Calculate the inclination and convert from radians to degrees\n",
    "    i_deg = unp.arccos(q / (a_mas ** 2.)) * (180 / np.pi)\n",
    "    \n",
    "    try:\n",
    "        if par.get(\"d\") is not None:\n",
    "            K_kms = 4.74372*unp.sqrt(par['C'] ** 2 + par['H'] ** 2)*(2*np.pi)/(par['P']/ 365.25)/np.sqrt(1-par['e']**2)\n",
    "            acc   = 2*K_kms/par['P']\n",
    "        else:\n",
    "            K_kms = 4.74372*unp.sqrt(par['C'] ** 2 + par['H'] ** 2)*(2*np.pi)/(par['P']/ 365.25)\n",
    "            acc   = K_kms/par['P']/4\n",
    "    except:\n",
    "        K_kms = ufloat(999, 999) \n",
    "        acc   = ufloat(999,999)\n",
    "\n",
    "    # Calculate the AMRF\n",
    "    try:\n",
    "        AMRF = a_mas / par['parallax'] * par['mass'] ** (-1 / 3)  * (par['P']/ 365.25) ** (-2 / 3)\n",
    "\n",
    "        # Calculate AMRF q\n",
    "        y = AMRF ** 3\n",
    "        h = (y/2 + (y**2)/3 + (y**3)/27\n",
    "             + np.sqrt(3)/18*y*unp.sqrt(4*y+27))**(1/3)\n",
    "        q = h + (2*y/3 + (y**2)/9)/h + y/3\n",
    "    except:\n",
    "        AMRF = ufloat(np.nan, np.inf) \n",
    "        q    = ufloat(np.nan, np.inf) \n",
    "        \n",
    "    # Extract expectancy values and standard deviations\n",
    "    pars = np.array([unp.nominal_values(AMRF),\n",
    "                         unp.nominal_values(q),\n",
    "                         unp.nominal_values(a_mas),\n",
    "                         unp.nominal_values(i_deg),\n",
    "                         unp.nominal_values(K_kms),\n",
    "                         unp.nominal_values(acc)])\n",
    "\n",
    "    pars_error = np.array([unp.std_devs(AMRF),\n",
    "                               unp.std_devs(q),\n",
    "                               unp.std_devs(a_mas),\n",
    "                               unp.std_devs(i_deg),\n",
    "                               unp.std_devs(K_kms),\n",
    "                               unp.std_devs(acc)])\n",
    "\n",
    "    return pars, pars_error\n",
    "\n",
    "def class_probs(Atr,Ams,par_in, par_in_errors,\n",
    "                  m1, m1_error, corr_matrix, bit_index=8191, n=1e2, factor=1.0):\n",
    "    \"\"\"\n",
    "    For the given set of orbital parameters by Gaia, this function calculates\n",
    "    the standard geometrical elements (a, omega, Omega, and i). If the error\n",
    "    estimates and covariance matrix are prodived, the error estimates on the\n",
    "    calculated parameters are returned as well.\n",
    "\n",
    "    Input: thiele_innes: Thiele Innes parameters [A,B,F,G] in milli-arcsec\n",
    "           thiele_innes_errors : Corresponding errors.\n",
    "           corr_matrix : Corresponding  4X4 correlation matrix.\n",
    "\n",
    "  Output: physical and geometrical parameters\n",
    "    \"\"\"\n",
    "    r_3 = 0\n",
    "    r_2 = 0\n",
    "    par_in_errors[np.isnan(par_in_errors)] = 1e-6\n",
    "    vecs = multivar_sample(par_in, par_in_errors, corr_matrix, int(n))\n",
    "    key_list = bit_index_map(bit_index)\n",
    "\n",
    "    for vec in vecs:\n",
    "        par = {key_list[i]: vec[i] for i in np.arange(len(key_list))}\n",
    "        par['mass'] = m1_error*np.random.randn() + m1\n",
    "\n",
    "        # Add the G Thiele-Innes parameter if needed.\n",
    "        if (bit_index == 8179) | (bit_index == 65435):\n",
    "            par['G'] = -par['A'] * par['F'] / par['B']\n",
    "\n",
    "        # This in an intermediate step in the formulae...\n",
    "        p = (par['A'] ** 2 + par['B'] ** 2 + par['G'] ** 2 + par['F'] ** 2) / 2.\n",
    "        q = par['A'] * par['G'] - par['B'] * par['F']\n",
    "\n",
    "        # Calculate the semimajor axis (already in mas)\n",
    "        a_mas = np.sqrt(p + np.sqrt(p ** 2 - q ** 2))\n",
    "\n",
    "        # Calculate the AMRF\n",
    "        AMRF = a_mas / par['parallax'] * par['mass'] ** (-1 / 3) * (par['P']/ 365.25) ** (-2 / 3)\n",
    "\n",
    "        try:\n",
    "            if 0 < par['e'] < 1:\n",
    "                if AMRF > Atr * factor:\n",
    "                    r_3 += 1\n",
    "                elif Ams * factor < AMRF < Atr * factor:\n",
    "                    r_2 += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return (n-r_2-r_3)/n, r_2/n, r_3/n #(no_detections + detections)\n",
    "\n",
    "# =============================================================================\n",
    "#                       Read the data from the NSS table\n",
    "# =============================================================================\n",
    "def add_astrometric_parameters(data):\n",
    "    # Here we only calculate (but don't assign class 3 probabilities!\n",
    "    # We get the data table, arrange the arrays, calculate the astrometric\n",
    "    # coefficients and plug it all back into the table.\n",
    "\n",
    "    # Initialize the arrays\n",
    "    # ---------------------\n",
    "    # We need to calculate the AMRF, mass ratio, angular semi-major axis, orbtial inclination\n",
    "    # and order-of-magnitude acceleration. We also want their uncertainties.\n",
    "    count_good, count_bad = 0, 0\n",
    "    A, q, a_mas, i_deg, K_kms, acc, P1, P2, P3 = np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan), np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan), np.full(len(data), np.nan), np.full(len(data), np.nan) \n",
    "\n",
    "    Ae, qe, a_mase, i_dege, K_kmse, acce = np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                                   np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                                   np.full(len(data), np.nan),  np.full(len(data), np.nan)\n",
    "\n",
    "    # Now go one by one and calculate the AMRF\n",
    "    # ----------------------------------------\n",
    "    for idx in tqdm(range(len(data['source_id']))):\n",
    "        if data[idx]['nss_solution_type'] not in ['Orbital','AstroSpectroSB1']:\n",
    "            continue\n",
    "        # Read the NSS solutin values.\n",
    "        sid = data['source_id'][idx]\n",
    "        mu, std, corr_mat = get_nss_data(data, sid)\n",
    "        m1 = data['m1'][idx]\n",
    "        m1_error = data['m1_err'][idx]\n",
    "        if np.ma.is_masked(m1):\n",
    "            print(idx)\n",
    "            pass\n",
    "        Ams_idx = data['Ams'][idx]\n",
    "        Atr_idx = data['Atr'][idx]\n",
    "        if np.ma.is_masked(Ams_idx) | np.ma.is_masked(Atr_idx):\n",
    "            Ams_idx = Ams(m1)\n",
    "            Atr_idx = Atr(m1)\n",
    "            \n",
    "        vals, stds = calc_AMRF(mu, std, corr_mat, m1, bit_index=data['bit_index'][idx])\n",
    "        p1, p2, p3 = class_probs(data['Atr'][idx],data['Ams'][idx],mu, std, m1, m1_error, corr_mat, bit_index=data['bit_index'][idx], n = 1e4)\n",
    "        try:\n",
    "            A[idx], Ae[idx]  = vals[0], stds[0]\n",
    "            q[idx], qe[idx]  = vals[1], stds[1]\n",
    "            a_mas[idx], a_mase[idx]  = vals[2], stds[2]\n",
    "            i_deg[idx], i_dege[idx]  = vals[3], stds[3]\n",
    "            K_kms[idx], K_kmse[idx]  = vals[4], stds[4]\n",
    "            acc[idx],   acce[idx]    = vals[5], stds[5]\n",
    "            P1[idx], P2[idx], P3[idx] = p1, p2, p3\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Store it all back in the original data structure.\n",
    "    data['AMRF'], data['AMRF_error'] = A, Ae\n",
    "    data['AMRF_q'], data['AMRF_q_error'] = q, qe\n",
    "    data['a_mas'], data['a_mas_error'] = a_mas, a_mase\n",
    "    data['i_deg'], data['i_deg_error'] = i_deg, i_dege\n",
    "    data['K_kms'], data['K_kms_error'] = K_kms, K_kmse\n",
    "    data['acc_kmsd'], data['acc_kmsd_error'] = acc, acce\n",
    "    data['classI_prob'] = P1\n",
    "    data['classII_prob'] = P2\n",
    "    data['classIII_prob'] = P3\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [17:53<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calc AMRF limits\n",
    "\n",
    "sources['Ams'] = np.full(len(sources),np.nan)\n",
    "sources['Atr'] = np.full(len(sources),np.nan)\n",
    "\n",
    "## calculating for all sources\n",
    "\n",
    "stage_min = 0  # pre-main sequence\n",
    "stage_max = 5  # red giant branch\n",
    "mass_min = 0  # [Msun]\n",
    "mass_max = 8  # [Msun]\n",
    "\n",
    "m2_vec = np.arange(0.1, 10, 0.1)\n",
    "\n",
    "wavelength = gaia_passband['wl'].value  # [A]\n",
    "\n",
    "Gflux1 = np.zeros(len(sources))\n",
    "Gflux2 = np.zeros((len(sources), len(m2_vec)))\n",
    "Ag1 = np.zeros(len(sources))\n",
    "Ag2 = np.zeros((len(sources), len(m2_vec)))\n",
    "q = np.zeros((len(sources), len(m2_vec)))\n",
    "# PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "PARSEC_path = '../OCFit/gaiaDR2/grids/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "for i in tqdm(range(len(sources))):\n",
    "    idx = sources['idx'][i]\n",
    "    if sources[i]['nss_solution_type'] not in ['Orbital','AstroSpectroSB1']:\n",
    "        continue\n",
    "    mh = sources['[Fe/H]'][i]\n",
    "    age = sources['age'][i]\n",
    "    ebv = sources['Av'][i]/3.1\n",
    "    m1 = sources['m1'][i]\n",
    "    \n",
    "    try:\n",
    "        track_idx = get_track_idx(mh,age)[-1]\n",
    "        tracks = models[track_idx].copy()\n",
    "        tracks.sort('Mini')\n",
    "        idx = np.argmin(np.abs(tracks['Mass'] - m1))\n",
    "\n",
    "        teff1 = 10**tracks['logTe'][idx]  # [K]\n",
    "        logg1 = tracks['logg'][idx]\n",
    "        r1 = mlogg2radius(m1*u.Msun, logg1)  # [Rsun]\n",
    "        flux1 = blackbody(teff1, wavelength)*4*np.pi*r1**2\n",
    "        Gflux1[i] = calc_synth_phot(wavelength, flux1, gaia_passband['gPb'].value).value\n",
    "        Ag1[i],_ = extinction.get_AG_EBPRP(3.1*ebv,0,teff1)\n",
    "        q[i, :] = m2_vec/m1  # mass ratio\n",
    "\n",
    "        for j in range(len(m2_vec)):\n",
    "            m2 = m2_vec[j]\n",
    "            idx = np.argmin(np.abs(tracks['Mass'] - m2))\n",
    "            teff2 = 10**tracks['logTe'][idx]  # [K]\n",
    "            logg2 = tracks['logg'][idx]\n",
    "            r2 = mlogg2radius(m2*u.Msun, logg2)  # [Rsun]\n",
    "            flux2 = blackbody(teff2, wavelength, ebv=ebv)*4*np.pi*r2**2\n",
    "            Gflux2[i,j] = calc_synth_phot(wavelength, flux2, gaia_passband['gPb'].value).value\n",
    "            Ag2[i,j],_ = extinction.get_AG_EBPRP(3.1*ebv,0,teff2)\n",
    "\n",
    "        Sms = Gflux2[i,:]/Gflux1[i]*10**(-0.4*(Ag2[i,:]-Ag1[i]))\n",
    "        Ams = amrf(q[i, :], Sms)\n",
    "        valid_idx = Sms < 1\n",
    "        Ams = np.max(Ams[valid_idx]) \n",
    "        sources['Ams'][i] = Ams\n",
    "        Str = 2*Gflux2[i,:]/Gflux1[i]\n",
    "        Atr = amrf(2*q[i, :], Str)\n",
    "        valid_idx = Str < 1\n",
    "        Atr = np.max(Atr[valid_idx])\n",
    "        sources['Atr'][i] = Atr\n",
    "    except:\n",
    "        print(f'i = {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:24<00:00, 11.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calc AMRF and class probabilities\n",
    "new_sources = add_astrometric_parameters(sources)\n",
    "new_sources['m2'] = new_sources['m1'] * new_sources['AMRF_q']\n",
    "new_sources['m2_err'] = ((new_sources['m1_err'] * new_sources['AMRF_q'])**2 + (new_sources['m1'] * new_sources['AMRF_q_error'])**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "sources = new_sources\n",
    "cut1 = sources['significance'] > 158 * sources['period'].data**(-0.5)\n",
    "cut2 = (sources['parallax_over_error'] > 20,000 *sources['period']**(-1))[0]\n",
    "cut3 = sources['eccentricity_error'] < 0.079 * np.log(sources['period'].data) - 0.244\n",
    "\n",
    "cut = cut1 & cut2 & cut3\n",
    "\n",
    "sources = sources[cut]\n",
    "\n",
    "# sources.write('../table_B.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "cut1 = sources['m1'] / sources['m1_err'] > 50\n",
    "cut2 = sources['classI_prob'] < 0.1\n",
    "cut3 = sources['m2'] <= 1.4\n",
    "\n",
    "cut = cut1 & cut2 & cut3\n",
    "\n",
    "# sources[cut].write('../table_C.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "tbl = Table.read('../table_C.fits')\n",
    "\n",
    "for i in range(len(tbl)):\n",
    "    idx = tbl['idx'][i]\n",
    "    cluster = tbl['cluster'][i]\n",
    "    # cmd_fig_name = f'../img/cmd/{idx}_{cluster}.png'\n",
    "    # cmd_new_name = f'../img/cmd_tableC/{idx}_{cluster}.png'\n",
    "    # shutil.move(cmd_fig_name, cmd_new_name)\n",
    "    interp_fig_name = f'../img/mass_interp/{idx}_{cluster}.png'\n",
    "    interp_new_name = f'../img/mass_interpC/{idx}_{cluster}.png'\n",
    "    shutil.move(interp_fig_name, interp_new_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooling time and progenitor mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_life vs m from evolutionary tracks/M_i from t_cluster, t_cool\n",
    "from os import walk,path\n",
    "\n",
    "def get_zarr():\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = []\n",
    "    for n in filenames:\n",
    "        z = n.split('Y')[0]\n",
    "        z_arr.append(float(z[1:]))\n",
    "    return np.unique(z_arr)\n",
    "\n",
    "def get_mdict(mh):\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = get_zarr()\n",
    "    z = 0.01524 * 10**mh\n",
    "    z_nearest = z_arr[np.argmin(np.abs(z_arr - z))]\n",
    "    z_str = 'Z'+f'{z_nearest}'\n",
    "\n",
    "    m_arr = []\n",
    "    s_arr = []\n",
    "    for n in filenames:\n",
    "        if z_str in n:\n",
    "            m = n.split('M')[1].removesuffix('.DAT')\n",
    "            if m.endswith('.HB'):\n",
    "                m = m.removesuffix('.HB')\n",
    "            m_arr.append(float(m))\n",
    "            s_arr.append(m)\n",
    "    tbl = Table({'mass':m_arr,'str':s_arr})\n",
    "    tbl = tbl[tbl['mass'] <= 8]\n",
    "    return tbl\n",
    "\n",
    "def get_marr(mh):\n",
    "    return np.unique(get_mdict(mh)['mass'])\n",
    "\n",
    "def get_lifetime(mass,mh):\n",
    "    ## lifetime for m>0.8\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = get_zarr()\n",
    "\n",
    "    z = 0.01524 * 10**mh\n",
    "    z_nearest = z_arr[np.argmin(np.abs(z_arr - z))]\n",
    "    m_dict = get_mdict(mh)\n",
    "    mass_str = m_dict[m_dict['mass'] == mass]['str']\n",
    "    z_str = 'Z'+f'{z_nearest}'\n",
    "\n",
    "    trackpath = ''\n",
    "    for n in filenames:\n",
    "        m1 = n.split('M')[1].removesuffix('.DAT')\n",
    "        if m1.endswith('HB'):\n",
    "            continue\n",
    "        for m2 in mass_str:\n",
    "            if m1 == m2 and z_str in n:\n",
    "                trackpath = path.join(basedir,n)\n",
    "                break\n",
    "\n",
    "    if trackpath == '':\n",
    "        print(f'No track found for '+m2+' '+z_str)\n",
    "\n",
    "    trck = Table(np.genfromtxt(trackpath,names=True,dtype=None))\n",
    "    return trck[trck['MODELL'] == 600 ]['AGE'][0]\n",
    "\n",
    "def lifetime_vs_mass(mh):\n",
    "    m_arr = get_marr(mh)\n",
    "    m_arr = m_arr[m_arr > 0.8]\n",
    "    t_arr = []\n",
    "    for m in m_arr:\n",
    "        t_arr.append(get_lifetime(m,mh))\n",
    "    return m_arr,t_arr\n",
    "\n",
    "def create_lifetime_vs_mass_tables():\n",
    "    z_arr = get_zarr()\n",
    "    mh_arr = np.log10(z_arr/0.01524)\n",
    "\n",
    "    for mh in mh_arr:\n",
    "        m_arr,t_arr = lifetime_vs_mass(mh)\n",
    "        tbl = Table({'mass':m_arr,'lifetime':t_arr})\n",
    "        tbl.write(path.join('..','data','MS_lifetime','parsec_V1.2S',f'lifetime_vs_mass{mh:.2f}.csv'),overwrite=True)\n",
    "\n",
    "    return ''\n",
    "\n",
    "def get_initial_mass(age,mh):\n",
    "    ## age in Myr\n",
    "    ## returns mass in solar mass\n",
    "    basedir = path.join('..','data','MS_lifetime','parsec_V1.2S')\n",
    "    z_arr = get_zarr()\n",
    "    mh_arr = np.log10(z_arr/0.01524)\n",
    "    mh = mh_arr[np.argmin(np.abs(mh_arr - mh))]\n",
    "    filename = f'lifetime_vs_mass{mh:.2f}.csv'   \n",
    "    df = pd.read_csv(path.join(basedir,filename))\n",
    "    idx = np.argmin(np.abs(df['lifetime'] - age*1e6))\n",
    "    return df['mass'][idx]\n",
    "\n",
    "def get_wd_cooling_age(m2,t2):\n",
    "    # in Myr\n",
    "    model = WD_models.load_model(low_mass_model='Bedard2020',\n",
    "                             middle_mass_model='Bedard2020',\n",
    "                             high_mass_model='ONe',\n",
    "                             atm_type='H',\n",
    "                             HR_bands=('FUV-NUV', 'NUV'))\n",
    "\n",
    "    m_logteff_to_agecool = WD_models.interp_xy_z_func(x=model['mass_array'],\n",
    "                                                  y=model['logteff'],\n",
    "                                                  z=model['age_cool'],\n",
    "                                                  interp_type='linear')\n",
    "    return m_logteff_to_agecool(m2, np.log10(t2)) * 1e3\n",
    "\n",
    "# clstr_age = 762\n",
    "# m2 = 0.81\n",
    "# mh = 0.195\n",
    "# omega = 0.0\n",
    "\n",
    "# teff_lo = 12000\n",
    "# teff_bst = 12500\n",
    "# teff_hi = 13000\n",
    "\n",
    "# wd_age_hi = get_wd_cooling_age(m2,teff_lo)\n",
    "# wd_age_bst = get_wd_cooling_age(m2,teff_bst)\n",
    "# wd_age_lo = get_wd_cooling_age(m2,teff_hi)\n",
    "# ms_age_hi = clstr_age - wd_age_lo\n",
    "# ms_age_bst = clstr_age - wd_age_bst\n",
    "# ms_age_lo = clstr_age - wd_age_hi\n",
    "# m1_hi = get_initial_mass(ms_age_lo,mh,omega)\n",
    "# m1_bst = get_initial_mass(ms_age_bst,mh,omega)\n",
    "# m1_lo = get_initial_mass(ms_age_hi,mh,omega)\n",
    "\n",
    "# print(f'WD cooling age ~{int(wd_age_bst)} ({int(wd_age_lo)} to {int(wd_age_hi)})')\n",
    "# print(f'Initial mass ~{m1_bst:.2f} ({m1_lo:.2f} to {m1_hi:.2f})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WD_models.load_model(low_mass_model='Bedard2020',\n",
    "                             middle_mass_model='Bedard2020',\n",
    "                             high_mass_model='ONe',\n",
    "                             atm_type='H',\n",
    "                             HR_bands=('V-NUV', 'NUV'))\n",
    "\n",
    "m_teff_to_mag = WD_models.interp_xy_z_func(x=model['mass_array'],y=model['logteff'],z=model['Mag'],interp_type='linear')\n",
    "m_teff_to_color = WD_models.interp_xy_z_func(x=model['mass_array'],y=model['logteff'],z=model['color'],interp_type='linear')\n",
    "\n",
    "from astropy.coordinates import SkyCoord \n",
    "from astropy import units as u\n",
    "for i in range(len(sources)):\n",
    "    idx = sources[i]['idx'] \n",
    "    m2 = sources[i]['m2']\n",
    "    t2 = sources[i]['teff2_min']\n",
    "    ra = sources[i]['ra'] * u.deg\n",
    "    dec = sources[i]['dec'] * u.deg\n",
    "    parallax = sources[i]['parallax']\n",
    "    logt2 = np.log10(t2)\n",
    "\n",
    "    nuv = m_teff_to_mag(m2,logt2)\n",
    "    fuv = m_teff_to_color(m2,logt2) + nuv\n",
    "\n",
    "    nuv_apparent = nuv + 5 * np.log10(1000/parallax) - 5\n",
    "    v_apparent = fuv + 5 * np.log10(1000/parallax) - 5\n",
    "    if v_apparent < 19.5:\n",
    "        print(f'idx {idx}, NUV = {nuv_apparent:.2f}, V = {v_apparent:.2f}, ' + SkyCoord(ra,dec).to_string('hmsdms'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
