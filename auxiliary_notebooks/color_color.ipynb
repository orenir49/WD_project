{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from astropy import table\n",
    "from astroquery.gaia import Gaia\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import scoreatpercentile\n",
    "import stam\n",
    "from tqdm import tqdm\n",
    "import WD_models\n",
    "from os import path\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "# clusters = Table.read('../data/hunt_clusters/clusters.csv')\n",
    "# members = Table.read('../data/hunt_clusters/members.csv')\n",
    "sources = Table.read('../table_merged.fits', format='fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.vizier import Vizier\n",
    "clstrs = Vizier(catalog='J/MNRAS/504/356',columns=['Cluster','N','logage','e_logage','[Fe/H]','e_[Fe/H]','Av','e_Av','FileName'],row_limit=-1).query_constraints()[0]\n",
    "\n",
    "clstrs.rename_columns(clstrs.colnames,['Cluster','N','logage','e_logage','Fe/H','e_Fe/H','Av','e_Av','FileName'])\n",
    "# sources = Table.read('../table_extra.fits')\n",
    "sources['idx'] = np.full(len(sources),'---',dtype=object)\n",
    "\n",
    "cut = (sources['nss_solution_type'] == 'Orbital') | (sources['nss_solution_type'] == 'AstroSpectroSB1')\n",
    "sources = sources[cut]\n",
    "\n",
    "nms = np.unique(sources['cluster'])\n",
    "for n in nms:\n",
    "    for i, s in enumerate(sources[sources['cluster'] == n]):\n",
    "        j = np.where(sources['source_id'] == s['source_id'])[0][0]\n",
    "        sources[j]['idx'] = n+'_'+str(i)\n",
    "\n",
    "sources['idx'] = sources['idx'].astype(str)\n",
    "# sources['age'] = np.full(len(sources),np.nan)\n",
    "# sources['[Fe/H]'] = np.full(len(sources),np.nan)\n",
    "# sources['Av'] = np.full(len(sources),np.nan)\n",
    "\n",
    "# for j in range(len(sources)):\n",
    "#     if sources[j]['cluster'] == 'Hyades':\n",
    "#         sources[j]['age'] = 680\n",
    "#         sources[j]['[Fe/H]'] = 0.14\n",
    "#         sources[j]['Av'] = 0.01 * 3.1\n",
    "#     if sources[j]['cluster'] == 'IC_2602':\n",
    "#         sources[j]['age'] = 60\n",
    "#         sources[j]['[Fe/H]'] = -0.02\n",
    "#         sources[j]['Av'] = 0.05 * 3.1\n",
    "#     if sources[j]['cluster'] == 'NGC_2287':\n",
    "#         sources[j]['age'] = 200\n",
    "#         sources[j]['[Fe/H]'] = -0.11\n",
    "#         sources[j]['Av'] = 0.03 * 3.1\n",
    "#     if sources[j]['cluster'] == 'NGC_2547':\n",
    "#         sources[j]['mh'] = 60\n",
    "#         sources[j]['[Fe/H]'] = 0.01\n",
    "#         sources[j]['Av'] = 0.06 * 3.1\n",
    "\n",
    "# for j in range(len(sources)):\n",
    "#     clstr = sources[j]['cluster']\n",
    "#     if clstr in clstrs['cluster']:\n",
    "#         i = np.where(clstrs['cluster'] == clstr)[0][0]\n",
    "#         sources[j]['age'] = clstrs[i]['age']\n",
    "#         sources[j]['[Fe/H]'] = clstrs[i]['Fe_H']\n",
    "#         sources[j]['Av'] = clstrs[i]['ebv'] * 3.1\n",
    "    \n",
    "sources.sort('idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARSEC functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "\n",
    "def choose_model(mh):\n",
    "    if (-0.6 <= mh) and (mh <= 0.05):\n",
    "        PARSEC_path = '../data/PARSECv2.0/w_i=0.6/'\n",
    "        models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "    else:\n",
    "        PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "        models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "    return PARSEC_path,models\n",
    "\n",
    "def get_tracks(mh,age):\n",
    "    if PARSEC_path == '../data/PARSEC v1.2S/Gaia_lin/':\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation\n",
    "        if age <= 100:\n",
    "            age_res = 2.5e-3 # [Gyr]\n",
    "        elif age <= 925:\n",
    "            age_res = 1.5e-2\n",
    "        else:\n",
    "            age_res = 5.0e-2\n",
    "    else:\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP_i45\", \"G_RP_i45\", \"G_i45\" ## rotation with 45 deg inclination\n",
    "        if age <= 45:\n",
    "            age_res = 5e-4\n",
    "        elif age <= 100:\n",
    "            age_res = 1e-3\n",
    "        else:\n",
    "            age_res = 2.5e-2\n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 10  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 20  # [Msun]\n",
    "    tracks = stam.gentracks.get_isotrack(models, [age * 1e-3, mh], params=(\"age\", \"mh\"), return_table=True,\n",
    "                                    age_res=age_res, mass_min=mass_min, mass_max=mass_max, mh_res = 0.03,\n",
    "                                    stage=None, stage_min=stage_min, stage_max=stage_max, sort_by=\"age\", color_filter1=color_fil_1, color_filter2=color_fil_2,\n",
    "                mag_filter=mag_fil)\n",
    "    return tracks\n",
    "\n",
    "def get_track_idx(mh,age):\n",
    "    if PARSEC_path == '../data/PARSEC v1.2S/Gaia_lin/':\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation\n",
    "        if age <= 100:\n",
    "            age_res = 2.5e-3 # [Gyr]\n",
    "        elif age <= 925:\n",
    "            age_res = 1.5e-2\n",
    "        else:\n",
    "            age_res = 5.0e-2\n",
    "    else:\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP_i45\", \"G_RP_i45\", \"G_i45\" ## rotation with 45 deg inclination\n",
    "        if age <= 45:\n",
    "            age_res = 5e-4\n",
    "        elif age <= 100:\n",
    "            age_res = 1e-3\n",
    "        else:\n",
    "            age_res = 2.5e-2\n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 10  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 20  # [Msun]\n",
    "    track_idx = stam.gentracks.get_isotrack(models, [age * 1e-3, mh], params=(\"age\", \"mh\"), return_idx=True,\n",
    "                                    age_res=age_res, mass_min=mass_min, mass_max=mass_max, mh_res = 0.03,\n",
    "                                    stage=None, stage_min=stage_min, stage_max=stage_max, sort_by=\"age\", color_filter1=color_fil_1, color_filter2=color_fil_2,\n",
    "                mag_filter=mag_fil)   \n",
    "    return track_idx\n",
    "\n",
    "\n",
    "def get_age_mh_grid():\n",
    "    if PARSEC_path == '../data/PARSEC v1.2S/Gaia_lin/':\n",
    "            age = np.concatenate([np.arange(1,100,5),np.arange(100,950,25)])\n",
    "            mh = np.arange(-2.0,0.3,0.05)\n",
    "    else:\n",
    "        age = np.concatenate([np.arange(10,45,1),np.arange(45,100,5),np.arange(100,1001,50)])\n",
    "        mh = np.arange(-0.6,0.07,0.05)\n",
    "    \n",
    "    age,mh = np.meshgrid(age,mh)\n",
    "    return age,mh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster parameters and primary mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the (empirical) model color-color relation to be compared with the data\n",
    "## The fit will determine the best value of E(B-V) (at B-V=0) to minimize the chi^2\n",
    "\n",
    "data = pd.read_csv('../data/other/color_relations.csv')\n",
    "\n",
    "eta = lambda bv0: 0.97 - 0.09 * bv0\n",
    "\n",
    "e_bv = lambda bv0,e_bv0: eta(bv0)/eta(0) * e_bv0 \n",
    "\n",
    "e_ub = lambda e_bv,alpha,beta,gamma: alpha * e_bv + beta * e_bv**2 + gamma * e_bv**3\n",
    "\n",
    "def redden_f70(e_bv0):\n",
    "    bv0_arr = data['(B-V)0'].values\n",
    "    ub0_arr = data['(U-B)0'].values\n",
    "    alpha_arr = data['alpha'].values\n",
    "    beta_arr = data['beta'].values\n",
    "    gamma_arr = data['gamma'].values\n",
    "    \n",
    "    e_bv_arr = e_bv(bv0_arr,e_bv0)\n",
    "    e_ub_arr = e_ub(e_bv_arr,alpha_arr,beta_arr,gamma_arr)\n",
    "\n",
    "    bv0_arr_reddened = bv0_arr + e_bv_arr\n",
    "    ub0_arr_reddened = ub0_arr + e_ub_arr\n",
    "    \n",
    "    return bv0_arr_reddened,ub0_arr_reddened\n",
    "\n",
    "def chi_2_ccd(e_bv0,bv_arr,ub_arr):\n",
    "    bv0_arr_reddened,ub0_arr_reddened = redden_f70(e_bv0)\n",
    "    \n",
    "    cut = (bv_arr > bv0_arr_reddened[0]) & (bv_arr < bv0_arr_reddened[-1])\n",
    "    bv_arr = bv_arr[cut]\n",
    "    ub_arr = ub_arr[cut]\n",
    "\n",
    "    ub0_f70 = np.interp(bv_arr,bv0_arr_reddened,ub0_arr_reddened)\n",
    "    chi_2 = np.sum((ub_arr - ub0_f70)**2)\n",
    "    return chi_2\n",
    "\n",
    "def f70_lims(e_bv0):\n",
    "    bv_f70,ub_f70 = redden_f70(e_bv0)\n",
    "    up_lim = ub_f70 + 0.017\n",
    "    low_lim = np.interp(bv_f70-0.020,bv_f70,ub_f70)\n",
    "    return up_lim,low_lim\n",
    "\n",
    "def in_f70_lims(tbl,bv_f70,up_lim,low_lim):\n",
    "    up_lim = np.interp(tbl['bv'],bv_f70,up_lim)\n",
    "    low_lim = np.interp(tbl['bv'],bv_f70,low_lim)\n",
    "    cut = (tbl['ub'] < up_lim) & (tbl['ub'] > low_lim) & (tbl['bv'] < bv_f70[-1]) & (tbl['bv'] > bv_f70[0])\n",
    "    return tbl[cut]\n",
    "\n",
    "def fit_and_plot(idx, plot = False, save = False):\n",
    "    # clstr_id = sources[sources['idx']== idx]['id'][0]\n",
    "    # clstr = clusters[clusters['id']==clstr_id]\n",
    "    # memb = members[members['id']==clstr_id]\n",
    "    # cut = (memb['probability'] > 0.99) & (memb['parallax']/memb['parallax_error'] > 10)\n",
    "    # memb = memb[cut]\n",
    "    clstr = sources[sources['idx'] == idx]['cluster'][0]\n",
    "    memb = Table.read(path.join('..','data','clusters',clstr+'.fits'),format='fits')\n",
    "\n",
    "\n",
    "    query = f'''SELECT source_id, u_jkc_mag, v_jkc_mag, b_jkc_mag FROM gaiadr3.synthetic_photometry_gspc WHERE source_id IN {tuple(memb['source_id'])}'''\n",
    "    job = Gaia.launch_job(query)\n",
    "    r = job.get_results()\n",
    "\n",
    "    cut = (~r['u_jkc_mag'].mask) & (~r['v_jkc_mag'].mask) & (~r['b_jkc_mag'].mask)\n",
    "    r = r[cut]\n",
    "    if len(r) == 0:\n",
    "        print(f'No photometry for candidate {idx}')\n",
    "        return np.nan,Table({})\n",
    "    if 'SOURCE_ID' in r.colnames:\n",
    "        r.rename_column('SOURCE_ID','source_id')\n",
    "    tbl = table.join(memb,r,keys='source_id')\n",
    "    tbl['mg'] = tbl['phot_g_mean_mag'] - 5 * np.log10(1000/tbl['parallax']) + 5\n",
    "    tbl['bv'] = tbl['b_jkc_mag'] - tbl['v_jkc_mag']\n",
    "    tbl['ub'] = tbl['u_jkc_mag'] - tbl['b_jkc_mag']\n",
    "    tbl = tbl['source_id','mg','bp_rp','bv','ub']\n",
    "\n",
    "    # ebv_guess = clstr['a_v_50'][0] / 3.1\n",
    "    ebv_guess = sources[sources['idx'] == idx]['Av'][0] / 3.1\n",
    "    tbl.sort('bv')\n",
    "\n",
    "    res = minimize(chi_2_ccd,ebv_guess,args=(tbl['bv'],tbl['ub']),bounds=[(0,0.3)])\n",
    "    ebv = res.x[0]\n",
    "\n",
    "    fig,(ax1,ax2) = plt.subplots(nrows=2,dpi=200,gridspec_kw={'height_ratios':[3,1]})\n",
    "    bv_f70,ub_f70 = redden_f70(ebv)\n",
    "    cut = tbl['bv'] < bv_f70[-1]\n",
    "    bv_plot = tbl['bv'][cut]\n",
    "    ub_plot = tbl['ub'][cut]\n",
    "\n",
    "    up_lim,low_lim = f70_lims(ebv)\n",
    "    tbl_mtso = in_f70_lims(tbl,bv_f70,up_lim,low_lim)\n",
    "    tbl_mtso = tbl_mtso[tbl_mtso['mg'] < 7]\n",
    "\n",
    "    ax1.plot(bv_f70,ub_f70,'k-',label=f'F70 ebv={ebv:.3f}')\n",
    "    ax1.fill_between(bv_f70,up_lim,low_lim,alpha=0.5,color='Gold')\n",
    "    ax1.scatter(bv_plot,ub_plot,s=10,c='r',label='Data')\n",
    "    ax1.scatter(tbl_mtso['bv'],tbl_mtso['ub'],s=30,c='g',label='Good MSTO',marker='x')\n",
    "    ax1.set_xlabel('B-V',fontsize=14)\n",
    "    ax1.set_ylabel('U-B',fontsize=14)\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.legend(fontsize=15)\n",
    "    ax1.set_title(f'cluster '+ clstr,fontsize=12)\n",
    "    # textstr = f'{len(memb)} reliable cluster members\\n {len(tbl_mtso)} good MSTO stars'\n",
    "    # props = dict(boxstyle='round', facecolor='k', alpha=0.5)\n",
    "    # ax1.text(0.05, 0.23, textstr, transform=ax1.transAxes, fontsize=15,\n",
    "    #         verticalalignment='top', bbox=props)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax2.set_xlabel('U-B',fontsize=14)\n",
    "    ax2.set_ylabel(r'$\\Delta$ (U-B)',fontsize=14)\n",
    "    ax2.scatter(ub_plot,ub_plot-np.interp(bv_plot,bv_f70,ub_f70),s=10,c='r')\n",
    "    ax2.scatter(tbl_mtso['ub'],tbl_mtso['ub']-np.interp(tbl_mtso['bv'],bv_f70,ub_f70),s=30,c='g',marker='x')\n",
    "    ax2.fill_between(ub_f70,up_lim-ub_f70,low_lim-ub_f70,alpha=0.5,color='Gold')\n",
    "    ax2.invert_yaxis()\n",
    "    fig.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(f'../img/ccd/ccd'+clstr+'.png')\n",
    "    if not plot:\n",
    "        plt.close()\n",
    "    return ebv,tbl_mtso\n",
    "\n",
    "def chi_2_cmd(age,mh,bp_rp,mg,ebv):\n",
    "    tracks = get_tracks(mh,age)\n",
    "    x = np.array(tracks[\"bp_rp\"])\n",
    "    y = np.array(tracks[\"mg\"])\n",
    "    xx,yy = [a for _,a in sorted(zip(y,x))], np.sort(y)\n",
    "    \n",
    "    e_bprp, A_G = stam.gaia.get_extinction_in_band(ebv,mag_filter=\"G\",color_filter1='G_BP',color_filter2='G_RP')\n",
    "    bp_rp_corrected = bp_rp - e_bprp\n",
    "    mg_corrected = mg - A_G\n",
    "    bp_rp_model = np.interp(mg_corrected,yy,xx)\n",
    "    chi_2 = np.sum((bp_rp_corrected - bp_rp_model)**2)\n",
    "    return chi_2/len(bp_rp_corrected)\n",
    "\n",
    "def fit_cluster_cmd(idx, plot = False, save = False):\n",
    "    ebv,tbl_mtso = fit_and_plot(idx, plot = plot, save = save)\n",
    "    ebv = sources[sources['idx'] == idx]['Av'][0] / 3.1 ## FIX E(B-V) BASED ON CLUSTER CATALOG for testing\n",
    "    if len(tbl_mtso) >= 4:\n",
    "        age,mh = get_age_mh_grid()\n",
    "        mh0 = sources[sources['idx']== idx]['[Fe/H]'][0]\n",
    "        if mh0 > mh.max():\n",
    "            mh0 = mh.max()\n",
    "        if mh0 < mh.min():\n",
    "            mh0 = mh.min()\n",
    "        mh = np.full_like(mh,mh0) #### FIX METALLICITY BASED ON CLUSTER CATALOG\n",
    "        chi2_mat = np.zeros((mh.shape[0],age.shape[1]))\n",
    "        for i in range(age.shape[1]):\n",
    "            for j in range(mh.shape[0]):\n",
    "                chi2_mat[j,i] = chi_2_cmd(age[j,i],mh[j,i],tbl_mtso['bp_rp'],tbl_mtso['mg'],ebv)\n",
    "\n",
    "        j,i = np.unravel_index(np.argmin(chi2_mat), chi2_mat.shape)\n",
    "        age_best = age[j,i]\n",
    "        mh_best = mh[j,i]\n",
    "        tracks = get_tracks(mh_best,age_best)\n",
    "        \n",
    "        x = np.array(tracks[\"bp_rp\"])\n",
    "        y = np.array(tracks[\"mg\"])\n",
    "        xx,yy = [a for _,a in sorted(zip(y,x))], np.sort(y)\n",
    "\n",
    "        e_bprp, A_G = stam.gaia.get_extinction_in_band(ebv,mag_filter=\"G\",color_filter1='G_BP',color_filter2='G_RP')\n",
    "        bp_rp_corrected = tbl_mtso['bp_rp'] - e_bprp\n",
    "        mg_corrected = tbl_mtso['mg'] - A_G\n",
    "        mg_corrected = mg_corrected.data\n",
    "        bp_rp_model = np.interp(np.union1d(mg_corrected,yy),yy,xx)\n",
    "\n",
    "        # clstr_id = sources[sources['idx']== idx]['id'][0]\n",
    "        # memb = members[members['id']==clstr_id]\n",
    "        # cut = (memb['probability'] > 0.99) & (memb['parallax']/memb['parallax_error'] > 10)\n",
    "        # memb = memb[cut]\n",
    "        \n",
    "        clstr = sources[sources['idx'] == idx]['cluster'][0]\n",
    "        memb = Table.read(path.join('..','data','clusters',clstr + '.fits'),format='fits')\n",
    "        memb['mg'] = memb['phot_g_mean_mag'] - 5 * np.log10(1000/memb['parallax']) + 5\n",
    "\n",
    "        fig,ax = plt.subplots(dpi=300)\n",
    "        ax.scatter(bp_rp_corrected,mg_corrected,s=10,c='r',label='MSTO used for fit')\n",
    "        ax.scatter(memb['bp_rp'] - e_bprp,memb['mg'] - A_G,s=5,c='b',label='All members')\n",
    "        ax.scatter(sources[sources['idx']== idx]['bp_rp'] - e_bprp,sources[sources['idx']== idx]['mg'] - A_G,s=25,c='g',label='Candidate',zorder = 10)\n",
    "        ax.plot(bp_rp_model,np.union1d(mg_corrected,yy), 'ko', markersize=1,label=f'PARSEC age={int(age_best)} Myr, [Fe/H]={mh_best:.2f}')\n",
    "        ax.set_xlabel('BP-RP')\n",
    "        ax.set_ylabel('G')\n",
    "        ax.invert_yaxis()\n",
    "        ax.legend(loc='lower left',frameon=False)\n",
    "        ax.set_title('cluster ' + clstr)\n",
    "        if save:\n",
    "            fig.savefig(f'../img/cmd/cmd'+clstr+'.png')\n",
    "        if not plot:\n",
    "            plt.close()\n",
    "        return age_best, mh_best, ebv\n",
    "    else:\n",
    "        print(f'Candidate {idx} has only {len(tbl_mtso)} good MSTO stars, not enough to fit the isochrone.')\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "def photometric_mass(age,mh,ebv,src):    \n",
    "    src['e_bv'] = ebv\n",
    "    color_excess_key = 'e_bv'\n",
    "    n_realizations = 10000\n",
    "    correct_extinction = True\n",
    "    if PARSEC_path == '../data/PARSEC v1.2S/Gaia_lin/':\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP\", \"G_RP\", \"G\" ## no rotation\n",
    "        if age <= 100:\n",
    "            age_res = 2.5e-3 # [Gyr]\n",
    "        elif age <= 925:\n",
    "            age_res = 1.5e-2\n",
    "        else:\n",
    "            age_res = 5.0e-2\n",
    "    else:\n",
    "        color_fil_1, color_fil_2, mag_fil = \"G_BP_i45\", \"G_RP_i45\", \"G_i45\" ## rotation with 45 deg inclination\n",
    "        if age <= 45:\n",
    "            age_res = 5e-4\n",
    "        elif age <= 100:\n",
    "            age_res = 1e-3\n",
    "        else:\n",
    "            age_res = 2.5e-2\n",
    "    stage_min = 0  # pre-main sequence\n",
    "    stage_max = 10  # red giant branch\n",
    "    mass_min = 0  # [Msun]\n",
    "    mass_max = 10  # [Msun]\n",
    "        \n",
    "    m1, m1_err = stam.run.multirun(src, vals=[age * 1e-3, mh], params=(\"age\", \"mh\"), suffix=\"\", is_save=False,\n",
    "                                                track_type=\"isotrack\", assign_param=\"mass\", is_extrapolate=False, rbf_func=\"linear\",\n",
    "                                                    output_type=\"csv\", output_path=\"./stam_output/\", n_realizations=n_realizations, interp_fun=\"griddata\",\n",
    "                                                    models=models, correct_extinction=correct_extinction, color_excess_key=color_excess_key , mh_res = 0.03,\n",
    "                                                    use_reddening_key=False, mass_min=mass_min, mass_max=mass_max,stage=None, stage_min=stage_min, stage_max=stage_max, age_res=age_res,\n",
    "                                                    color_filter1=color_fil_1, color_filter2=color_fil_2, mag_filter=mag_fil)\n",
    "    return m1[0], m1_err[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photometric mass for candidate FSR_0398_0...\n",
      "Photometric mass for candidate NGC_2099_0...\n",
      "Photometric mass for candidate NGC_2632_0...\n",
      "Photometric mass for candidate NGC_6475_0...\n",
      "Photometric mass for candidate Roslund_6_2...\n",
      "Photometric mass for candidate SAI_118_0...\n",
      "Photometric mass for candidate 0...\n",
      "Photometric mass for candidate 1...\n",
      "Photometric mass for candidate 2...\n",
      "Photometric mass for candidate 3...\n",
      "Photometric mass for candidate 4...\n",
      "Photometric mass for candidate 5...\n",
      "Photometric mass for candidate 8...\n",
      "Photometric mass for candidate 9...\n",
      "Photometric mass for candidate 10...\n",
      "Photometric mass for candidate 12...\n",
      "Photometric mass for candidate 13...\n",
      "Photometric mass for candidate 17...\n",
      "Photometric mass for candidate 20...\n",
      "Photometric mass for candidate 21...\n",
      "Photometric mass for candidate 22...\n",
      "Photometric mass for candidate 23...\n",
      "Photometric mass for candidate 24...\n",
      "Photometric mass for candidate 25...\n",
      "Photometric mass for candidate 26...\n",
      "Photometric mass for candidate 27...\n",
      "Photometric mass for candidate 28...\n",
      "Photometric mass for candidate 93...\n",
      "Photometric mass for candidate 99...\n",
      "Photometric mass for candidate 142...\n"
     ]
    }
   ],
   "source": [
    "fit = False\n",
    "plot = False\n",
    "save = False\n",
    "\n",
    "new_sources = sources.copy()\n",
    "m1_col = []\n",
    "m1_err_col = []\n",
    "age_col = []\n",
    "mh_col = []\n",
    "av_col = []\n",
    "# fitting all with parsec v1.2S\n",
    "PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "for idx in new_sources['idx']:\n",
    "    if idx.split('_')[-1] == '0':\n",
    "        # The first candidate of each cluster determines the PARSEC model to be used\n",
    "        # PARSEC_path,models = choose_model(sources[sources['idx'] == idx]['[Fe/H]'][0])\n",
    "        if fit:\n",
    "            # only the first candidate of each cluster is used to fit the isochrone\n",
    "            print('Fitting cluster ' + sources[sources['idx'] == idx]['cluster'][0] + '...')\n",
    "            age,mh,ebv = fit_cluster_cmd(idx, plot = plot, save = save)\n",
    "        else:\n",
    "            # if the cluster parameters are known, use them\n",
    "            age = new_sources[new_sources['idx'] == idx]['age'][0]\n",
    "            mh = new_sources[new_sources['idx'] == idx]['[Fe/H]'][0]\n",
    "            ebv = new_sources[new_sources['idx'] == idx]['Av'][0] / 3.1\n",
    "    # else:\n",
    "    #     # use the same cluster parameters for subsequent candidates\n",
    "    #     # frst = new_sources[new_sources['idx'] == idx]['cluster'][0] + '_0'\n",
    "    #     # j = np.where(new_sources['idx'] == frst)[0][0]\n",
    "    #     j = np.where(new_sources['cluster'] == )\n",
    "    #     age = age_col[j]\n",
    "    #     mh = mh_col[j]\n",
    "    #     ebv = av_col[j] / 3.1\n",
    "    # age_col.append(age)\n",
    "    # mh_col.append(mh)\n",
    "    # av_col.append(ebv * 3.1)\n",
    "    age = new_sources[new_sources['idx'] == idx]['age'][0]\n",
    "    mh = new_sources[new_sources['idx'] == idx]['[Fe/H]'][0]\n",
    "    ebv = new_sources[new_sources['idx'] == idx]['Av'][0] / 3.1\n",
    "    if np.isnan(age):\n",
    "        # if unable to fit age, skip the candidate\n",
    "        # new_sources.remove_row(np.where(new_sources['idx'] == idx)[0][0])\n",
    "        m1_col.append(np.nan)\n",
    "        m1_err_col.append(np.nan)\n",
    "    else:\n",
    "        try:\n",
    "            print(f'Photometric mass for candidate {idx}...')\n",
    "            m1,m1_err = photometric_mass(age,mh,ebv,new_sources[new_sources['idx'] == idx])\n",
    "            m1_col.append(m1)\n",
    "            m1_err_col.append(m1_err)\n",
    "        except:\n",
    "            print(f'Error in photometric mass for candidate {idx}')\n",
    "            m1_col.append(np.nan)\n",
    "            m1_err_col.append(np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '[Fe/H]'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "new_sources['m1'] = m1_col\n",
    "new_sources['m1_err'] = m1_err_col\n",
    "# new_sources['age1'] = age_col\n",
    "# new_sources['mh1'] = mh_col\n",
    "# new_sources['av1'] = av_col\n",
    "new_sources.write('../table_merged.fits',overwrite=True)\n",
    "sources = new_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions, gaia passbands\n",
    "\n",
    "# ------------ AMRF limits ----------------\n",
    "from astropy.io import ascii\n",
    "from synphot import SourceSpectrum, ReddeningLaw\n",
    "from synphot.models import BlackBodyNorm1D\n",
    "from synphot.units import convert_flux\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "import json \n",
    "from uncertainties import unumpy as unp, ufloat\n",
    "from uncertainties import correlated_values_norm, correlation_matrix\n",
    "import warnings\n",
    "\n",
    "def blackbody(temperature, wavelength, ebv=None, extinction_model='mwavg'):\n",
    "    bb = SourceSpectrum(BlackBodyNorm1D, temperature=temperature*u.K)  # [photons s^-1 cm^-2 A^-1]\n",
    "    if ebv is not None:\n",
    "        # apply extinction\n",
    "        ext = ReddeningLaw.from_extinction_model(extinction_model).extinction_curve(ebv)\n",
    "        bb = bb * ext\n",
    "    bb = bb(wavelength)/(const.R_sun / const.kpc) ** 2  # undo synphot normalization (but leave the pi factor from integration over half a sphere)\n",
    "    bb = convert_flux(wavelength, bb, 'flam')  # [flam] = [erg s^-1 cm^-2 A^-1]\n",
    "    bb = bb.to(u.erg/u.s/u.cm**2/u.angstrom)  # express in normal astropy units\n",
    "    return bb\n",
    "\n",
    "\n",
    "def mlogg2radius(m, logg):\n",
    "    g = 10**logg*u.cm/u.s**2\n",
    "    r = np.sqrt(const.G*m/g)\n",
    "    return r.to(u.Rsun).value\n",
    "\n",
    "\n",
    "def calc_synth_phot(wavelength, flux, bandpass):\n",
    "    dlambda = np.diff(wavelength)\n",
    "    dlambda = np.concatenate([dlambda, np.array([dlambda[-1]])])\n",
    "\n",
    "    # assuming a photon-counting device\n",
    "    phot = np.sum(dlambda*bandpass*wavelength*flux)/np.sum(dlambda*bandpass*wavelength)\n",
    "    \n",
    "    return phot\n",
    "\n",
    "\n",
    "amrf = lambda q, S : q/(1+q)**(2/3)*(1 - S*(1+q)/(q*(1+S)))\n",
    "\n",
    "gaia_passband = ascii.read('../data/other/passband.dat', names=[\"wl\", \"gPb\", \"gPbError\", \"bpPb\", \"bpPbError\", \"rpPb\", \"rpPbError\"])\n",
    "\n",
    "# replace missing values with NaNs\n",
    "for col in gaia_passband.itercols():\n",
    "    col[col == 99.99] = 0\n",
    "    \n",
    "gaia_passband['wl'] *= 10  # [A]\n",
    "\n",
    "# ---------- AMRF -------------------\n",
    "\n",
    "limiting_curves = Table.read('../data/other/AMRF_limiting_curves.fits')\n",
    "# Retrieve the conservative limiting AMRF values for some primary mass\n",
    "# --------------\n",
    "def Atr(m1):\n",
    "    j = np.argmin(np.abs(m1 - limiting_curves['m1'].data))\n",
    "    return limiting_curves['Atr'][j]\n",
    "def Ams(m1):\n",
    "    j = np.argmin(np.abs(m1 - limiting_curves['m1'].data))\n",
    "    return limiting_curves['Ams'][j]\n",
    "\n",
    "# =============================================================================\n",
    "#                Auxil routines to obtain the covariance matrix\n",
    "# =============================================================================\n",
    "\n",
    "# 1) get the list of parameters from the solution type\n",
    "def get_par_list(solution_type=None):\n",
    "    if (solution_type is None) or (solution_type=='Orbital'):\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'eccentricity', 'period', 't_periastron')\n",
    "\n",
    "    elif (solution_type=='OrbitalAlternative') or (solution_type=='OrbitalAlternativeValidated') \\\n",
    "            or (solution_type=='OrbitalTargetedSearch') or (solution_type=='OrbitalTargetedSearchValidated'):\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'period', 'eccentricity', 't_periastron')\n",
    "\n",
    "    elif solution_type=='AstroSpectroSB1':\n",
    "        return ('ra', 'dec', 'parallax', 'pmra', 'pmdec', 'a_thiele_innes',\n",
    "                'b_thiele_innes', 'f_thiele_innes', 'g_thiele_innes',\n",
    "                'c_thiele_innes', 'h_thiele_innes', 'center_of_mass_velocity',\n",
    "                'eccentricity', 'period', 't_periastron')\n",
    "\n",
    "\n",
    "# 2) Get the order of parameters in the covariance matrix, for a given bit index.\n",
    "def bit_index_map(bit_index):\n",
    "    if bit_index==8191:\n",
    "        return ['ra','dec','parallax','pmra','pmdec','A','B','F','G', 'e','P', 'T']\n",
    "    elif bit_index==8179:\n",
    "        return ['ra','dec','parallax','pmra','pmdec','A','B','F','P', 'T']\n",
    "    elif bit_index==65535:\n",
    "        return ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'A', 'B', 'F', 'G', 'C', 'H', 'gamma','e', 'P', 'T']\n",
    "    elif bit_index==65435:\n",
    "        return ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'A', 'B', 'F', 'H', 'gamma', 'P', 'T']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# 3) Generate the correlation matrix\n",
    "def make_corr_matrix(input_table, pars=None):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    input_table nss_two_body_orbit table.\n",
    "    pars : list\n",
    "            list of parameters for the corresponding solution of the desired\n",
    "              target, in the same order as they appear in the Gaia table.\n",
    "      \"\"\"\n",
    "    if pars is None:\n",
    "        pars = get_par_list()\n",
    "\n",
    "    # read the correlation vector\n",
    "    s1 = input_table['corr_vec'].replace('\\n','')   \n",
    "    s1 = s1.replace(' ',',')\n",
    "    s1 = s1.replace('--','0')\n",
    "    corr_vec = list(json.loads(s1))\n",
    "    # set the number of parameters in the table\n",
    "    n_pars = len(pars)\n",
    "    # define the correlation matrix.\n",
    "    corr_mat = np.ones([n_pars, n_pars], dtype=float)\n",
    "\n",
    "    # Read the matrix (lower triangle)\n",
    "    ind = 0\n",
    "    for i in range(n_pars):\n",
    "        for j in range(i):\n",
    "            corr_mat[j][i] = corr_vec[ind]\n",
    "            corr_mat[i][j] = corr_vec[ind]\n",
    "            ind += 1\n",
    "\n",
    "    return corr_mat\n",
    "\n",
    "\n",
    "# 4) Get the NSS data \n",
    "def get_nss_data(input_table, source_id):\n",
    "\n",
    "    target_idx = np.argwhere(input_table['source_id'] == source_id)[0][0]\n",
    "    pars = get_par_list(input_table['nss_solution_type'][target_idx])\n",
    "    corr_mat = make_corr_matrix(input_table[target_idx], pars=pars)\n",
    "\n",
    "    mu, std = np.zeros(len(pars)), np.zeros(len(pars))\n",
    "    for i, par in enumerate(pars):\n",
    "        try:\n",
    "            mu[i] = input_table[par][target_idx]\n",
    "            std[i] = input_table[par + '_error'][target_idx]\n",
    "        except KeyError:\n",
    "            mu[i], std[i] = np.nan, np.nan\n",
    "\n",
    "    nan_idxs = np.argwhere(np.isnan(corr_mat))\n",
    "    corr_mat[nan_idxs[:, 0], nan_idxs[:, 1]] = 0.0\n",
    "\n",
    "    return mu, std, corr_mat\n",
    "\n",
    "def multivar_sample(mu, sigma, corr, n):\n",
    "    cov = corr*(sigma[:, None] * sigma[None, :])\n",
    "    # l = spla.cholesky(cov)\n",
    "    # z = np.random.normal(size=(n, mu.shape[0]))\n",
    "    # return z.dot(l) + mu\n",
    "    return np.random.multivariate_normal(mu, cov, size=n)\n",
    "\n",
    "# =============================================================================\n",
    "#                      calc parameters.\n",
    "# =============================================================================\n",
    "# Here we calculate the AMRF, qmin, etc, assuming that the mass of the luminous star \n",
    "# is exactly one solar mass. This is just for the red-clump stars...\n",
    "def calc_AMRF(par_in, par_in_errors, corr_matrix, m1, bit_index=8191):\n",
    "    \"\"\"\n",
    "    For the given set of orbital parameters by Gaia, this function calculates\n",
    "    the standard geometrical elements (a, omega, Omega, and i). If the error\n",
    "    estimates and covariance matrix are prodived, the error estimates on the\n",
    "    calculated parameters are returned as well.\n",
    "\n",
    "    Input: thiele_innes: Thiele Innes parameters [A,B,F,G] in milli-arcsec\n",
    "           thiele_innes_errors : Corresponding errors.\n",
    "           corr_matrix : Corresponding  4X4 correlation matrix.\n",
    "\n",
    "  Output: class-III probability via monte carlo\n",
    "    \"\"\"\n",
    "    # Read the coefficients and assign the correlation matrix.\n",
    "    # Create correlated quantities. If the error is nan we assume 1e-6...\n",
    "    par_in_errors[np.isnan(par_in_errors)] = 1e-6\n",
    "    par_list = correlated_values_norm([(par_in[i], par_in_errors[i]) for i in np.arange(len(par_in))], corr_matrix)\n",
    "    key_list = bit_index_map(bit_index)\n",
    "\n",
    "    par = {key_list[i]: par_list[i] for i in np.arange(len(key_list))}\n",
    "    par['mass'] = m1\n",
    "\n",
    "    # Add the G Thiele-Innes parameter if needed.\n",
    "    if (bit_index == 8179) | (bit_index == 65435):\n",
    "        G = -par['A']*par['F']/par['B']\n",
    "    else:\n",
    "        G = par['G']\n",
    "\n",
    "    # This in an intermediate step in the formulae...\n",
    "    p = (par['A'] ** 2 + par['B'] ** 2 + G ** 2 + par['F'] ** 2) / 2.\n",
    "    q = par['A'] * G - par['B'] * par['F']\n",
    "\n",
    "    # Calculate the angular semimajor axis (already in mas)\n",
    "    a_mas = unp.sqrt(p + unp.sqrt(p ** 2 - q ** 2))\n",
    "\n",
    "    # Calculate the inclination and convert from radians to degrees\n",
    "    i_deg = unp.arccos(q / (a_mas ** 2.)) * (180 / np.pi)\n",
    "    \n",
    "    try:\n",
    "        if par.get(\"d\") is not None:\n",
    "            K_kms = 4.74372*unp.sqrt(par['C'] ** 2 + par['H'] ** 2)*(2*np.pi)/(par['P']/ 365.25)/np.sqrt(1-par['e']**2)\n",
    "            acc   = 2*K_kms/par['P']\n",
    "        else:\n",
    "            K_kms = 4.74372*unp.sqrt(par['C'] ** 2 + par['H'] ** 2)*(2*np.pi)/(par['P']/ 365.25)\n",
    "            acc   = K_kms/par['P']/4\n",
    "    except:\n",
    "        K_kms = ufloat(999, 999) \n",
    "        acc   = ufloat(999,999)\n",
    "\n",
    "    # Calculate the AMRF\n",
    "    try:\n",
    "        AMRF = a_mas / par['parallax'] * par['mass'] ** (-1 / 3)  * (par['P']/ 365.25) ** (-2 / 3)\n",
    "\n",
    "        # Calculate AMRF q\n",
    "        y = AMRF ** 3\n",
    "        h = (y/2 + (y**2)/3 + (y**3)/27\n",
    "             + np.sqrt(3)/18*y*unp.sqrt(4*y+27))**(1/3)\n",
    "        q = h + (2*y/3 + (y**2)/9)/h + y/3\n",
    "    except:\n",
    "        AMRF = ufloat(np.nan, np.inf) \n",
    "        q    = ufloat(np.nan, np.inf) \n",
    "        \n",
    "    # Extract expectancy values and standard deviations\n",
    "    pars = np.array([unp.nominal_values(AMRF),\n",
    "                         unp.nominal_values(q),\n",
    "                         unp.nominal_values(a_mas),\n",
    "                         unp.nominal_values(i_deg),\n",
    "                         unp.nominal_values(K_kms),\n",
    "                         unp.nominal_values(acc)])\n",
    "\n",
    "    pars_error = np.array([unp.std_devs(AMRF),\n",
    "                               unp.std_devs(q),\n",
    "                               unp.std_devs(a_mas),\n",
    "                               unp.std_devs(i_deg),\n",
    "                               unp.std_devs(K_kms),\n",
    "                               unp.std_devs(acc)])\n",
    "\n",
    "    return pars, pars_error\n",
    "\n",
    "def class_probs(Atr,Ams,par_in, par_in_errors,\n",
    "                  m1, m1_error, corr_matrix, bit_index=8191, n=1e2, factor=1.0):\n",
    "    \"\"\"\n",
    "    For the given set of orbital parameters by Gaia, this function calculates\n",
    "    the standard geometrical elements (a, omega, Omega, and i). If the error\n",
    "    estimates and covariance matrix are prodived, the error estimates on the\n",
    "    calculated parameters are returned as well.\n",
    "\n",
    "    Input: thiele_innes: Thiele Innes parameters [A,B,F,G] in milli-arcsec\n",
    "           thiele_innes_errors : Corresponding errors.\n",
    "           corr_matrix : Corresponding  4X4 correlation matrix.\n",
    "\n",
    "  Output: physical and geometrical parameters\n",
    "    \"\"\"\n",
    "    r_3 = 0\n",
    "    r_2 = 0\n",
    "    par_in_errors[np.isnan(par_in_errors)] = 1e-6\n",
    "    vecs = multivar_sample(par_in, par_in_errors, corr_matrix, int(n))\n",
    "    key_list = bit_index_map(bit_index)\n",
    "\n",
    "    for vec in vecs:\n",
    "        par = {key_list[i]: vec[i] for i in np.arange(len(key_list))}\n",
    "        par['mass'] = m1_error*np.random.randn() + m1\n",
    "\n",
    "        # Add the G Thiele-Innes parameter if needed.\n",
    "        if (bit_index == 8179) | (bit_index == 65435):\n",
    "            par['G'] = -par['A'] * par['F'] / par['B']\n",
    "\n",
    "        # This in an intermediate step in the formulae...\n",
    "        p = (par['A'] ** 2 + par['B'] ** 2 + par['G'] ** 2 + par['F'] ** 2) / 2.\n",
    "        q = par['A'] * par['G'] - par['B'] * par['F']\n",
    "\n",
    "        # Calculate the semimajor axis (already in mas)\n",
    "        a_mas = np.sqrt(p + np.sqrt(p ** 2 - q ** 2))\n",
    "\n",
    "        # Calculate the AMRF\n",
    "        AMRF = a_mas / par['parallax'] * par['mass'] ** (-1 / 3) * (par['P']/ 365.25) ** (-2 / 3)\n",
    "\n",
    "        try:\n",
    "            if 0 < par['e'] < 1:\n",
    "                if AMRF > Atr * factor:\n",
    "                    r_3 += 1\n",
    "                elif Ams * factor < AMRF < Atr * factor:\n",
    "                    r_2 += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return (n-r_2-r_3)/n, r_2/n, r_3/n #(no_detections + detections)\n",
    "\n",
    "# =============================================================================\n",
    "#                       Read the data from the NSS table\n",
    "# =============================================================================\n",
    "def add_astrometric_parameters(data):\n",
    "    # Here we only calculate (but don't assign class 3 probabilities!\n",
    "    # We get the data table, arrange the arrays, calculate the astrometric\n",
    "    # coefficients and plug it all back into the table.\n",
    "\n",
    "    # Initialize the arrays\n",
    "    # ---------------------\n",
    "    # We need to calculate the AMRF, mass ratio, angular semi-major axis, orbtial inclination\n",
    "    # and order-of-magnitude acceleration. We also want their uncertainties.\n",
    "    count_good, count_bad = 0, 0\n",
    "    A, q, a_mas, i_deg, K_kms, acc, P1, P2, P3 = np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan), np.full(len(data), np.nan), \\\n",
    "                              np.full(len(data), np.nan), np.full(len(data), np.nan), np.full(len(data), np.nan) \n",
    "\n",
    "    Ae, qe, a_mase, i_dege, K_kmse, acce = np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                                   np.full(len(data), np.nan),  np.full(len(data), np.nan), \\\n",
    "                                   np.full(len(data), np.nan),  np.full(len(data), np.nan)\n",
    "\n",
    "    # Now go one by one and calculate the AMRF\n",
    "    # ----------------------------------------\n",
    "    for idx in tqdm(range(len(data['source_id']))):\n",
    "        if data[idx]['nss_solution_type'] not in ['Orbital','AstroSpectroSB1']:\n",
    "            continue\n",
    "        # Read the NSS solutin values.\n",
    "        sid = data['source_id'][idx]\n",
    "        mu, std, corr_mat = get_nss_data(data, sid)\n",
    "        m1 = data['m1'][idx]\n",
    "        m1_error = data['m1_err'][idx]\n",
    "        if np.ma.is_masked(m1):\n",
    "            print(idx)\n",
    "            pass\n",
    "        Ams_idx = data['Ams'][idx]\n",
    "        Atr_idx = data['Atr'][idx]\n",
    "        if np.ma.is_masked(Ams_idx) | np.ma.is_masked(Atr_idx):\n",
    "            Ams_idx = Ams(m1)\n",
    "            Atr_idx = Atr(m1)\n",
    "            \n",
    "        vals, stds = calc_AMRF(mu, std, corr_mat, m1, bit_index=data['bit_index'][idx])\n",
    "        p1, p2, p3 = class_probs(data['Atr'][idx],data['Ams'][idx],mu, std, m1, m1_error, corr_mat, bit_index=data['bit_index'][idx], n = 1e4)\n",
    "        try:\n",
    "            A[idx], Ae[idx]  = vals[0], stds[0]\n",
    "            q[idx], qe[idx]  = vals[1], stds[1]\n",
    "            a_mas[idx], a_mase[idx]  = vals[2], stds[2]\n",
    "            i_deg[idx], i_dege[idx]  = vals[3], stds[3]\n",
    "            K_kms[idx], K_kmse[idx]  = vals[4], stds[4]\n",
    "            acc[idx],   acce[idx]    = vals[5], stds[5]\n",
    "            P1[idx], P2[idx], P3[idx] = p1, p2, p3\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Store it all back in the original data structure.\n",
    "    data['AMRF'], data['AMRF_error'] = A, Ae\n",
    "    data['AMRF_q'], data['AMRF_q_error'] = q, qe\n",
    "    data['a_mas'], data['a_mas_error'] = a_mas, a_mase\n",
    "    data['i_deg'], data['i_deg_error'] = i_deg, i_dege\n",
    "    data['K_kms'], data['K_kms_error'] = K_kms, K_kmse\n",
    "    data['acc_kmsd'], data['acc_kmsd_error'] = acc, acce\n",
    "    data['classI_prob'] = P1\n",
    "    data['classII_prob'] = P2\n",
    "    data['classIII_prob'] = P3\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:35<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calc AMRF limits\n",
    "\n",
    "sources['Ams'] = np.full(len(sources),np.nan)\n",
    "sources['Atr'] = np.full(len(sources),np.nan)\n",
    "\n",
    "## calculating for all sources\n",
    "\n",
    "stage_min = 0  # pre-main sequence\n",
    "stage_max = 3  # red giant branch\n",
    "mass_min = 0  # [Msun]\n",
    "mass_max = 8  # [Msun]\n",
    "\n",
    "m2_vec = np.arange(0.1, 10, 0.1)\n",
    "\n",
    "wavelength = gaia_passband['wl'].value  # [A]\n",
    "\n",
    "Gflux1 = np.zeros(len(sources))\n",
    "Gflux2 = np.zeros((len(sources), len(m2_vec)))\n",
    "q = np.zeros((len(sources), len(m2_vec)))\n",
    "PARSEC_path = '../data/PARSEC v1.2S/Gaia_lin/'\n",
    "models = stam.getmodels.read_parsec(path=PARSEC_path)\n",
    "for i in tqdm(range(len(sources))):\n",
    "    idx = sources['idx'][i]\n",
    "    if idx.split('_')[-1] == '0':\n",
    "        # The first candidate of each cluster determines the PARSEC model to be used\n",
    "        # PARSEC_path,models = choose_model(sources[sources['idx'] == idx]['[Fe/H]'][0])\n",
    "        ''\n",
    "    if sources[i]['nss_solution_type'] not in ['Orbital','AstroSpectroSB1']:\n",
    "        continue\n",
    "    mh = sources['[Fe/H]'][i]\n",
    "    age = sources['age'][i]\n",
    "    ebv = sources['Av'][i]/3.1\n",
    "    m1 = sources['m1'][i]\n",
    "    \n",
    "    try:\n",
    "        track_idx = get_track_idx(mh,age)[-1]\n",
    "        tracks = models[track_idx].copy()\n",
    "        tracks.sort('Mini')\n",
    "        idx = np.argmin(np.abs(tracks['Mass'] - m1))\n",
    "\n",
    "        teff1 = 10**tracks['logTe'][idx]  # [K]\n",
    "        logg1 = tracks['logg'][idx]\n",
    "        r1 = mlogg2radius(m1*u.Msun, logg1)  # [Rsun]\n",
    "        flux1 = blackbody(teff1, wavelength, ebv=ebv)*4*np.pi*r1**2\n",
    "        Gflux1[i] = calc_synth_phot(wavelength, flux1, gaia_passband['gPb'].value).value\n",
    "\n",
    "        q[i, :] = m2_vec/m1  # mass ratio\n",
    "\n",
    "        for j in range(len(m2_vec)):\n",
    "            m2 = m2_vec[j]\n",
    "            idx = np.argmin(np.abs(tracks['Mass'] - m2))\n",
    "            teff2 = 10**tracks['logTe'][idx]  # [K]\n",
    "            logg2 = tracks['logg'][idx]\n",
    "            r2 = mlogg2radius(m2*u.Msun, logg2)  # [Rsun]\n",
    "            flux2 = blackbody(teff2, wavelength, ebv=ebv)*4*np.pi*r2**2\n",
    "            Gflux2[i,j] = calc_synth_phot(wavelength, flux2, gaia_passband['gPb'].value).value\n",
    "\n",
    "        Sms = Gflux2[i,:]/Gflux1[i]\n",
    "        Ams = amrf(q[i, :], Sms)\n",
    "        valid_idx = Sms < 1\n",
    "        Ams = np.max(Ams[valid_idx]) \n",
    "        sources['Ams'][i] = Ams\n",
    "        Str = 2*Gflux2[i,:]/Gflux1[i]\n",
    "        Atr = amrf(2*q[i, :], Str)\n",
    "        valid_idx = Str < 1\n",
    "        Atr = np.max(Atr[valid_idx])\n",
    "        sources['Atr'][i] = Atr\n",
    "    except:\n",
    "        print(f'i = {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [00:01<00:00, 13.57it/s]/tmp/ipykernel_2722404/2063429063.py:283: RuntimeWarning: invalid value encountered in scalar power\n",
      "  AMRF = a_mas / par['parallax'] * par['mass'] ** (-1 / 3) * (par['P']/ 365.25) ** (-2 / 3)\n",
      "100%|██████████| 30/30 [00:02<00:00, 13.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calc AMRF and class probabilities\n",
    "new_sources = add_astrometric_parameters(sources)\n",
    "new_sources['m2'] = new_sources['m1'] * new_sources['AMRF_q']\n",
    "new_sources['m2_err'] = ((new_sources['m1_err'] * new_sources['AMRF_q'])**2 + (new_sources['m1'] * new_sources['AMRF_q_error'])**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&lt;Column name=&apos;idx&apos; dtype=&apos;bytes15&apos; length=30&gt;\n",
       "<table>\n",
       "<tr><td>FSR_0398_0</td></tr>\n",
       "<tr><td>NGC_2099_0</td></tr>\n",
       "<tr><td>NGC_2632_0</td></tr>\n",
       "<tr><td>NGC_6475_0</td></tr>\n",
       "<tr><td>Roslund_6_2</td></tr>\n",
       "<tr><td>SAI_118_0</td></tr>\n",
       "<tr><td>0</td></tr>\n",
       "<tr><td>1</td></tr>\n",
       "<tr><td>2</td></tr>\n",
       "<tr><td>3</td></tr>\n",
       "<tr><td>4</td></tr>\n",
       "<tr><td>5</td></tr>\n",
       "<tr><td>...</td></tr>\n",
       "<tr><td>20</td></tr>\n",
       "<tr><td>21</td></tr>\n",
       "<tr><td>22</td></tr>\n",
       "<tr><td>23</td></tr>\n",
       "<tr><td>24</td></tr>\n",
       "<tr><td>25</td></tr>\n",
       "<tr><td>26</td></tr>\n",
       "<tr><td>27</td></tr>\n",
       "<tr><td>28</td></tr>\n",
       "<tr><td>93</td></tr>\n",
       "<tr><td>99</td></tr>\n",
       "<tr><td>142</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Column name='idx' dtype='bytes15' length=30>\n",
       " FSR_0398_0\n",
       " NGC_2099_0\n",
       " NGC_2632_0\n",
       " NGC_6475_0\n",
       "Roslund_6_2\n",
       "  SAI_118_0\n",
       "          0\n",
       "          1\n",
       "          2\n",
       "          3\n",
       "          4\n",
       "          5\n",
       "        ...\n",
       "         20\n",
       "         21\n",
       "         22\n",
       "         23\n",
       "         24\n",
       "         25\n",
       "         26\n",
       "         27\n",
       "         28\n",
       "         93\n",
       "         99\n",
       "        142"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut1 = sources['significance'] > 158 * sources['period'].data**(-0.5)\n",
    "cut2 = (sources['parallax_over_error'] > 20,000 *sources['period']**(-1))[0]\n",
    "cut3 = sources['eccentricity_error'] < 0.079 * np.log(sources['period'].data) - 0.244\n",
    "\n",
    "cut = cut1 & cut2 & cut3\n",
    "\n",
    "sources[cut]['idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooling time and progenitor mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_life vs m from evolutionary tracks/M_i from t_cluster, t_cool\n",
    "from os import walk,path\n",
    "\n",
    "def get_zarr():\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = []\n",
    "    for n in filenames:\n",
    "        z = n.split('Y')[0]\n",
    "        z_arr.append(float(z[1:]))\n",
    "    return np.unique(z_arr)\n",
    "\n",
    "def get_mdict(mh):\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = get_zarr()\n",
    "    z = 0.01524 * 10**mh\n",
    "    z_nearest = z_arr[np.argmin(np.abs(z_arr - z))]\n",
    "    z_str = 'Z'+f'{z_nearest}'\n",
    "\n",
    "    m_arr = []\n",
    "    s_arr = []\n",
    "    for n in filenames:\n",
    "        if z_str in n:\n",
    "            m = n.split('M')[1].removesuffix('.DAT')\n",
    "            if m.endswith('.HB'):\n",
    "                m = m.removesuffix('.HB')\n",
    "            m_arr.append(float(m))\n",
    "            s_arr.append(m)\n",
    "    tbl = Table({'mass':m_arr,'str':s_arr})\n",
    "    tbl = tbl[tbl['mass'] <= 8]\n",
    "    return tbl\n",
    "\n",
    "def get_marr(mh):\n",
    "    return np.unique(get_mdict(mh)['mass'])\n",
    "\n",
    "def get_lifetime(mass,mh):\n",
    "    ## lifetime for m>0.8\n",
    "    basedir = path.join('..','data','PARSEC v1.2S','evol_tracks')\n",
    "    filenames = walk(basedir).__next__()[2]\n",
    "    z_arr = get_zarr()\n",
    "\n",
    "    z = 0.01524 * 10**mh\n",
    "    z_nearest = z_arr[np.argmin(np.abs(z_arr - z))]\n",
    "    m_dict = get_mdict(mh)\n",
    "    mass_str = m_dict[m_dict['mass'] == mass]['str']\n",
    "    z_str = 'Z'+f'{z_nearest}'\n",
    "\n",
    "    trackpath = ''\n",
    "    for n in filenames:\n",
    "        m1 = n.split('M')[1].removesuffix('.DAT')\n",
    "        if m1.endswith('HB'):\n",
    "            continue\n",
    "        for m2 in mass_str:\n",
    "            if m1 == m2 and z_str in n:\n",
    "                trackpath = path.join(basedir,n)\n",
    "                break\n",
    "\n",
    "    if trackpath == '':\n",
    "        print(f'No track found for '+m2+' '+z_str)\n",
    "\n",
    "    trck = Table(np.genfromtxt(trackpath,names=True,dtype=None))\n",
    "    return trck[trck['MODELL'] == 600 ]['AGE'][0]\n",
    "\n",
    "def lifetime_vs_mass(mh):\n",
    "    m_arr = get_marr(mh)\n",
    "    m_arr = m_arr[m_arr > 0.8]\n",
    "    t_arr = []\n",
    "    for m in m_arr:\n",
    "        t_arr.append(get_lifetime(m,mh))\n",
    "    return m_arr,t_arr\n",
    "\n",
    "def create_lifetime_vs_mass_tables():\n",
    "    z_arr = get_zarr()\n",
    "    mh_arr = np.log10(z_arr/0.01524)\n",
    "\n",
    "    for mh in mh_arr:\n",
    "        m_arr,t_arr = lifetime_vs_mass(mh)\n",
    "        tbl = Table({'mass':m_arr,'lifetime':t_arr})\n",
    "        tbl.write(path.join('..','data','MS_lifetime','parsec_V1.2S',f'lifetime_vs_mass{mh:.2f}.csv'),overwrite=True)\n",
    "\n",
    "    return ''\n",
    "\n",
    "def get_initial_mass(age,mh):\n",
    "    ## age in Myr\n",
    "    ## returns mass in solar mass\n",
    "    basedir = path.join('..','data','MS_lifetime','parsec_V1.2S')\n",
    "    z_arr = get_zarr()\n",
    "    mh_arr = np.log10(z_arr/0.01524)\n",
    "    mh = mh_arr[np.argmin(np.abs(mh_arr - mh))]\n",
    "    filename = f'lifetime_vs_mass{mh:.2f}.csv'   \n",
    "    df = pd.read_csv(path.join(basedir,filename))\n",
    "    idx = np.argmin(np.abs(df['lifetime'] - age*1e6))\n",
    "    return df['mass'][idx]\n",
    "\n",
    "def get_wd_cooling_age(m2,t2):\n",
    "    # in Myr\n",
    "    model = WD_models.load_model(low_mass_model='Bedard2020',\n",
    "                             middle_mass_model='Bedard2020',\n",
    "                             high_mass_model='ONe',\n",
    "                             atm_type='H',\n",
    "                             HR_bands=('FUV-NUV', 'NUV'))\n",
    "\n",
    "    m_logteff_to_agecool = WD_models.interp_xy_z_func(x=model['mass_array'],\n",
    "                                                  y=model['logteff'],\n",
    "                                                  z=model['age_cool'],\n",
    "                                                  interp_type='linear')\n",
    "    return m_logteff_to_agecool(m2, np.log10(t2)) * 1e3\n",
    "\n",
    "# clstr_age = 762\n",
    "# m2 = 0.81\n",
    "# mh = 0.195\n",
    "# omega = 0.0\n",
    "\n",
    "# teff_lo = 12000\n",
    "# teff_bst = 12500\n",
    "# teff_hi = 13000\n",
    "\n",
    "# wd_age_hi = get_wd_cooling_age(m2,teff_lo)\n",
    "# wd_age_bst = get_wd_cooling_age(m2,teff_bst)\n",
    "# wd_age_lo = get_wd_cooling_age(m2,teff_hi)\n",
    "# ms_age_hi = clstr_age - wd_age_lo\n",
    "# ms_age_bst = clstr_age - wd_age_bst\n",
    "# ms_age_lo = clstr_age - wd_age_hi\n",
    "# m1_hi = get_initial_mass(ms_age_lo,mh,omega)\n",
    "# m1_bst = get_initial_mass(ms_age_bst,mh,omega)\n",
    "# m1_lo = get_initial_mass(ms_age_hi,mh,omega)\n",
    "\n",
    "# print(f'WD cooling age ~{int(wd_age_bst)} ({int(wd_age_lo)} to {int(wd_age_hi)})')\n",
    "# print(f'Initial mass ~{m1_bst:.2f} ({m1_lo:.2f} to {m1_hi:.2f})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
