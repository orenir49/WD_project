{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1751,"status":"ok","timestamp":1682235618939,"user":{"displayName":"Oren Ironi","userId":"01729731674548048942"},"user_tz":-180},"id":"x-sHRwH6Ez-n"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from astropy.io import fits\n","import astropy.table as table\n","from astropy.table import Table\n","import astropy.units as u\n","from astroquery.gaia import Gaia\n","from astroquery.mast import Catalogs\n","from astropy.coordinates import SkyCoord\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# table_B = Table.read('table_B.fits', format='fits')"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# table_0 = Table.read('table_cut.fits', format='fits')\n","table_0 = Table.read('table_cut.fits', format='fits')\n","members = Table.read('./data/hunt_clusters/members.csv', format='csv')\n","clusters = Table.read('./data/hunt_clusters/clusters.csv', format='csv')\n","# uv_excess = [7,9,13,20,21,23,28]\n","# no_excess = [8,10,12,16,24]\n","# no_galex = [0,1,2,3,4,5,6,11,14,15,17,18,19,22,25,26,27]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## query gaia for all sources in table_0- get relevant columns\n","\n","query1 = '''SELECT source_id, ra , dec, ra_error ,dec_error,parallax,parallax_error, astrometric_excess_noise, astrometric_excess_noise_sig,\n"," astrometric_params_solved, pseudocolour, visibility_periods_used, astrometric_sigma5d_max, ruwe, phot_g_mean_flux, phot_g_mean_flux_error, phot_g_mean_mag,\n","   phot_g_mean_flux_over_error, phot_bp_mean_flux, phot_bp_mean_flux_error, phot_bp_mean_flux_over_error, phot_bp_mean_mag, phot_rp_mean_flux,\n","     phot_rp_mean_flux_error, phot_rp_mean_flux_over_error, phot_rp_mean_mag, bp_rp, bp_g, g_rp, radial_velocity, radial_velocity_error, l, b,\n","       ecl_lon, ecl_lat, has_xp_continuous, has_xp_sampled, has_rvs, has_epoch_photometry, has_epoch_rv\n","    FROM gaiadr3.gaia_source\n","    WHERE source_id IN {id_lst}\n","    '''.format(id_lst = tuple(table_0['source_id'].data))\n","job1 = Gaia.launch_job(query= query1)\n","table_1 = job1.get_results()\n","\n","## query nss for all soruces in table_0 - get relevant columns\n","\n","query2 = '''SELECT source_id, parallax, parallax_error , pmra, pmra_error,\n"," pmdec, pmdec_error, a_thiele_innes, a_thiele_innes_error, b_thiele_innes, b_thiele_innes_error, f_thiele_innes, f_thiele_innes_error,\n","  g_thiele_innes, g_thiele_innes_error, c_thiele_innes, c_thiele_innes_error, h_thiele_innes, h_thiele_innes_error, period, period_error,\n","   t_periastron, t_periastron_error, eccentricity, eccentricity_error, center_of_mass_velocity, center_of_mass_velocity_error,\n","    semi_amplitude_primary, semi_amplitude_primary_error, semi_amplitude_secondary, semi_amplitude_secondary_error, mass_ratio,\n","     mass_ratio_error, fill_factor_primary, fill_factor_primary_error, fill_factor_secondary, fill_factor_secondary_error, inclination,\n","      inclination_error, arg_periastron, arg_periastron_error, temperature_ratio, temperature_ratio_error, temperature_ratio_definition, \n","      bit_index, corr_vec, goodness_of_fit, efficiency, significance, flags, g_luminosity_ratio, astrometric_jitter, nss_solution_type\n","    FROM gaiadr3.nss_two_body_orbit\n","    WHERE source_id IN {id_lst}\n","    '''.format(id_lst = tuple(table_0['source_id'].data))\n","job2 = Gaia.launch_job(query= query2)\n","table_2 = job2.get_results()\n","\n","## join tables, reorder columns by importance\n","\n","table_0 = table.join(table_2,table_1,keys=['source_id'],join_type='left')\n","\n","## take parallax from NSS if available, otherwise take from Gaia source\n","par_col = [pgaia if np.ma.is_masked(pnss) else pnss for pnss,pgaia in zip(table_0['parallax_1'],table_0['parallax_2'])]\n","par_err = [egaia if np.ma.is_masked(enss) else enss for enss,egaia in zip(table_0['parallax_error_1'],table_0['parallax_error_2'])]\n","par_col = Table.Column(par_col, name='parallax',unit='mas')\n","par_err = Table.Column(par_err, name='parallax_error',unit='mas')\n","table_0.add_columns([par_col,par_err])\n","table_0.remove_columns(['parallax_1','parallax_2','parallax_error_1','parallax_error_2'])\n","\n","table_0['parallax_over_error'] = table_0['parallax']/table_0['parallax_error']\n","table_0['mg'] = table_0[\"phot_g_mean_mag\"] + 5 * np.log10(table_0[\"parallax\"]) - 10\n","cols = table_0.colnames\n","first_cols = ['source_id','ra','dec','parallax','phot_g_mean_mag','bp_rp']\n","for c in first_cols:\n","    cols.remove(c)\n","cols = first_cols + cols\n","table_0 = table_0[cols]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["## convert metallicity catalog h5 files to fits\n","\n","import h5py \n","from astropy.table import Table\n","import os\n","from glob import glob\n","\n","# Input location\n","# catalog_h5_list = glob('c:/Users/ASUS/Dropbox (Weizmann Institute)/AMRF IFMR/data/metallicity/stellar_params_catalog_*.h5')\n","catalog_h5_list = glob('/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/metallicity/stellar_params_catalog_*.h5')\n","catalog_h5_list.sort()\n","\n","for catalog_h5_loc in catalog_h5_list:\n","    print(f\"Loading {catalog_h5_loc}\")\n","    output_fits = Table()\n","    with h5py.File(catalog_h5_loc, 'r') as f:\n","        for i, key in enumerate(f.keys()):\n","            print(f\"Loading {i+1}/{len(f.keys())}: {key}\")\n","            output_fits[key] = f[key][:]\n","    base_fn,_ = os.path.splitext(catalog_h5_loc)\n","    catalog_fits_loc = base_fn + '.fits'\n","    print(f\"Saving to {catalog_fits_loc}\")\n","    output_fits.write(catalog_fits_loc)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## read first metallicity catalog file, create metallicity column, remove other columns\n","\n","# ColDefs(name = 'chi2_opt'; format = 'E'\n","#     name = 'dec'; format = 'E'\n","#     name = 'feh_confidence'; format = 'E'\n","#     name = 'gdr3_source_id'; format = 'K'\n","#     name = 'ln_prior'; format = 'E'\n","#     name = 'logg_confidence'; format = 'E'\n","#     name = 'quality_flags'; format = 'B'\n","#     name = 'ra'; format = 'E'\n","#     name = 'stellar_params_err'; format = '5E'; dim = '(5)'\n","#     name = 'stellar_params_est'; format = '5E'; dim = '(5)'\n","#     name = 'teff_confidence'; format = 'E') \n","\n","\n","hdul_7 = fits.open('c:/Users/ASUS/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity/stellar_params_catalog_00.fits')\n","coldef = fits.ColDefs([hdul_7[1].columns[3],hdul_7[1].columns[8],hdul_7[1].columns[9],hdul_7[1].columns[6]])\n","table_7 = Table(hdul_7[1].from_columns(coldef).data)\n","table_7.add_column(table_7['stellar_params_est'][:,1]*u.dex,name='Fe_H_est')\n","table_7.add_column(table_7['stellar_params_err'][:,1]*u.dex,name='Fe_H_error')\n","table_7.remove_columns(['stellar_params_err','stellar_params_est'])\n","table_7.rename_column('gdr3_source_id','source_id')\n","hdul_7.close()\n","\n","## read all metallicity catalog files, create metallicity column, remove other columns, append to table_7\n","for i in range(1,10):\n","    filename = f'c:/Users/ASUS/Dropbox (Weizmann Institute)/AMRF IFMR/data/metallicity/stellar_params_catalog_0{i}.fits'\n","    print(filename)\n","    hdul_temp = fits.open(filename)\n","    coldef = fits.ColDefs([hdul_temp[1].columns[3],hdul_temp[1].columns[8],hdul_temp[1].columns[9],hdul_temp[1].columns[6]])\n","    table_temp = Table(hdul_temp[1].from_columns(coldef).data)\n","    hdul_temp.close()\n","    table_temp.add_column(table_temp['stellar_params_est'][:,1]*u.dex,name='Fe_H_est')\n","    table_temp.add_column(table_temp['stellar_params_err'][:,1]*u.dex,name='Fe_H_error')\n","    table_temp.remove_columns(['stellar_params_err','stellar_params_est'])\n","    table_temp.rename_column('gdr3_source_id','source_id')\n","    table_7 = table.vstack([table_7,table_temp])\n","\n","table_0 = table.join(table_0,table_7,keys=['source_id'],join_type='left')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## get metallicity for all cluster members, take median\n","\n","# hdul_7 = fits.open('c:/Users/ASUS/Dropbox (Weizmann Institute)/AMRF IFMR/old/data/catalogs/metallicity/stellar_params_catalog_00.fits')\n","hdul_7 = fits.open('/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/old/data/catalogs/metallicity/stellar_params_catalog_00.fits')\n","coldef = fits.ColDefs([hdul_7[1].columns[3],hdul_7[1].columns[8],hdul_7[1].columns[9],hdul_7[1].columns[6]])\n","table_7 = Table(hdul_7[1].from_columns(coldef).data)\n","table_7.add_column(table_7['stellar_params_est'][:,1]*u.dex,name='Fe_H_est')\n","table_7.add_column(table_7['stellar_params_err'][:,1]*u.dex,name='Fe_H_error')\n","table_7.remove_columns(['stellar_params_err','stellar_params_est'])\n","table_7.rename_column('gdr3_source_id','source_id')\n","hdul_7.close()\n","\n","## read all metallicity catalog files, create metallicity column, remove other columns, append to table_7\n","for i in range(1,10):\n","    # filename = f'c:/Users/ASUS/Dropbox (Weizmann Institute)/AMRF IFMR/old/data/catalogs/metallicity/stellar_params_catalog_0{i}.fits'\n","    filename = f'/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/old/data/catalogs/metallicity/stellar_params_catalog_0{i}.fits'\n","    print(filename)\n","    hdul_temp = fits.open(filename)\n","    coldef = fits.ColDefs([hdul_temp[1].columns[3],hdul_temp[1].columns[8],hdul_temp[1].columns[9],hdul_temp[1].columns[6]])\n","    table_temp = Table(hdul_temp[1].from_columns(coldef).data)\n","    hdul_temp.close()\n","    table_temp.add_column(table_temp['stellar_params_est'][:,1]*u.dex,name='Fe_H_est')\n","    table_temp.add_column(table_temp['stellar_params_err'][:,1]*u.dex,name='Fe_H_error')\n","    table_temp.remove_columns(['stellar_params_err','stellar_params_est'])\n","    table_temp.rename_column('gdr3_source_id','source_id')\n","    table_7 = table.vstack([table_7,table_temp])\n","\n","table_7 = table_7[table_7['quality_flags'] < 8]\n","table_0['Fe_H_cluster'] = np.full(len(table_0),np.nan)\n","table_0['Fe_H_cluster_std'] = np.full(len(table_0),np.nan)\n","\n","for i,id in tqdm(enumerate(table_0['id']),total=len(table_0['id'])):\n","    nbr = members[members['id']==id]\n","    fh_arr = table_7[np.isin(table_7['source_id'],nbr['source_id'])]['Fe_H_est']\n","    table_0[i]['Fe_H_cluster'] = np.median(fh_arr)\n","    table_0[i]['Fe_H_cluster_std'] = np.std(fh_arr)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["## Get cluster data for each source\n","members = Table.from_pandas(pd.read_csv('./data/hunt_clusters/members.csv',usecols=['source_id','id','probability']))\n","clusters = Table.from_pandas(pd.read_csv('./data/hunt_clusters/clusters.csv',usecols=['id','log_age_16','log_age_50','log_age_84','a_v_16','a_v_50','a_v_84','n_stars']))\n","\n","table_0 = table.join(table_0, members, keys='source_id', join_type='left')\n","table_0 = table.join(table_0, clusters, keys='id', join_type='left')"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1677/1677 [26:45<00:00,  1.04it/s]\n"]}],"source":["## Astroquery GALEX data\n","# i = 40\n","# ra = table_0[i]['ra']\n","# dec = table_0[i]['dec']\n","# r_arcsec = 10\n","# r_deg = r_arcsec/3600\n","# catalog_data = Catalogs.query_object(f'{ra} {dec}',catalog='Galex',radius = r_deg)\n","\n","# print(np.min(catalog_data['distance_arcmin'].data)*60)\n","\n","\n","for c in ['distance_arcmin','nuv_mag','nuv_magerr','fuv_mag','fuv_magerr']:\n","    table_0[c] = np.full(len(table_0),np.nan)\n","\n","\n","for i in tqdm(range(len(table_0))):\n","    ra = table_0[i]['ra']\n","    dec = table_0[i]['dec']\n","    r_arcsec = 2\n","    r_deg = r_arcsec/3600\n","    catalog_data = Catalogs.query_object(f'{ra} {dec}',catalog='Galex',radius = r_deg)\n","\n","    if len(catalog_data)>0:\n","        for c in ['distance_arcmin','nuv_mag','nuv_magerr','fuv_mag','fuv_magerr']:\n","            table_0[c][i] = catalog_data[c][0]"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["## deal with problematic data types\n","\n","col = table.Column([str(cvec) for cvec in table_0['corr_vec']],name = 'corr_vec',dtype = str)\n","table_0['nss_solution_type'] = table_0['nss_solution_type'].astype(str)\n","table_0['corr_vec'] = col"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["## sort columns by importance\n","\n","cols = table_0.colnames\n","first_cols = ['source_id','ra','dec','parallax','mg','phot_g_mean_mag','bp_rp','log_age_50','av_bayestar','av_acrist','Fe_H_est','probability','nuv_mag']\n","for c in first_cols:\n","    cols.remove(c)\n","cols = first_cols + cols\n","table_0 = table_0[cols]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## query extinction (northern)\n","\n","# from dustmaps.config import config\n","# config['data_dir'] = '/path/to/store/maps/in'\n","\n","# import dustmaps.bayestar\n","# dustmaps.bayestar.fetch()\n","\n","# from dustmaps.bayestar import BayestarQuery\n","\n","# bayestar = BayestarQuery(max_samples=2, version='bayestar2015')\n","# l = table_0['l']\n","# b = table_0['b']\n","# d = np.abs(1000/table_0['parallax'])\n","# coord = SkyCoord(l=l*u.deg, b=b*u.deg, distance=d*u.pc, frame='galactic')\n","# ebv = 0.884 * bayestar(coord, mode='median')"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1677 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1677/1677 [10:48<00:00,  2.58it/s]\n"]}],"source":["## query extinction (southern)\n","# from urllib import request\n","# av = []\n","# with tqdm(total=len(table_0)) as pbar:\n","#     for ra,dec,par in zip(table_0['ra'],table_0['dec'],table_0['parallax']):\n","#         d = np.abs(1000/par)\n","#         with  request.urlopen(f'https://astro.acri-st.fr/gaia_dev/extinction?frame=icrs&vlong={ra}&ulong=deg&vlat={dec}&ulat=deg&distance={d}') as response:\n","#             html = response.read()\n","#             av.append(float(html.split(b'\\n')[1].split(b',')[1]))\n","#         pbar.update(1)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["## save table\n","table_0.write('table.fits', format='fits',overwrite=True)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["## cut table_B from 660 to relevant non class I sources\n","\n","# table_0 = Table.read('table_B.fits', format='fits')\n","\n","# cond = (table_0['probability'].data>=0.99) & (table_0['m1'].data/table_0['m1_err'].data>=10) &  (table_0['classI_prob'].data <= 0.1)\n","\n","# table_1 = table_0[cond]\n","\n","# table_1.write('table_cut.fits', format='fits',overwrite=True)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPAZMVrAy7ItB6tR38RT92q","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
