{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1751,"status":"ok","timestamp":1682235618939,"user":{"displayName":"Oren Ironi","userId":"01729731674548048942"},"user_tz":-180},"id":"x-sHRwH6Ez-n"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from astropy.io import fits\n","import astropy.table as table\n","from astropy.table import Table\n","import astropy.units as u\n","from astroquery.gaia import Gaia\n","from astroquery.vizier import Vizier\n","from astroquery.mast import Catalogs\n","from astropy.coordinates import SkyCoord\n","from tqdm import tqdm\n","import os\n","from os import walk\n","import pyvo"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>A0</th>\n","      <th>teffnorm</th>\n","      <th>A0^2</th>\n","      <th>A0 teffnorm</th>\n","      <th>teffnorm^2</th>\n","      <th>A0^3</th>\n","      <th>A0^2 teffnorm</th>\n","      <th>A0 teffnorm^2</th>\n","      <th>teffnorm^3</th>\n","      <th>mae</th>\n","      <th>rmse</th>\n","      <th>mean_residuals</th>\n","      <th>std_residuals</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Generic_Johnson.V</th>\n","      <td>1.027896</td>\n","      <td>-0.004452</td>\n","      <td>0.038565</td>\n","      <td>-0.00003</td>\n","      <td>0.000102</td>\n","      <td>-0.007615</td>\n","      <td>1.039121e-07</td>\n","      <td>-4.598864e-07</td>\n","      <td>-0.000008</td>\n","      <td>0.000451</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          1        A0  teffnorm     A0^2  A0 teffnorm  \\\n","Generic_Johnson.V  1.027896 -0.004452  0.038565 -0.00003     0.000102   \n","\n","                   teffnorm^2          A0^3  A0^2 teffnorm  A0 teffnorm^2  \\\n","Generic_Johnson.V   -0.007615  1.039121e-07  -4.598864e-07      -0.000008   \n","\n","                   teffnorm^3  mae  rmse  mean_residuals  std_residuals  \n","Generic_Johnson.V    0.000451  NaN   NaN             NaN            NaN  "]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["from dustapprox.models import PrecomputedModel\n","\n","\n","lib = PrecomputedModel()\n","\n","fname = lib.find(passband='johnson')[0]['filename']\n","\n","lib.load_model(fname)[2].to_pandas()\n","# print([method for method in dir(lib.load_model(fname)[0]) if callable(getattr(lib.load_model(fname)[0],method))])"]},{"cell_type":"markdown","metadata":{},"source":["# Dias cluster tables\n","* Create cluster member tables using FTP\n","* Cross match with NSS to create candidate pool\n","* Query cluster parameters from Vizier"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 478/478 [10:13<00:00,  1.28s/it]\n"]},{"data":{"text/plain":["'221 Goodbye.'"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["## Constructing Dias cluster member tables using FTP/Vizier\n","\n","# from ftplib import FTP\n","\n","# clusters = Vizier(catalog='J/MNRAS/504/356',columns=['Cluster','N','logage','e_loagage','[Fe/H]','e_[Fe/H]','Av','e_Av','FileName'],row_limit=-1).query_constraints()[0]\n","\n","# cut1 = [fname.startswith('clusters1') for fname in clusters['FileName']]\n","# cut2 = [fname.startswith('clusters2') for fname in clusters['FileName']]\n","\n","# ftp = FTP('cdsarc.u-strasbg.fr')\n","# ftp.login()\n","# ftp.cwd('pub/cats/J/MNRAS/504/356/clusters2')\n","# for fname in tqdm(clusters[cut2]['FileName'],total=len(clusters[cut2])):\n","#     dirname,fname = fname.split('/') \n","#     with open(os.path.join('data','clusters2',fname), 'wb') as f:\n","#         ftp.retrbinary('RETR ' + fname, f.write)\n","#     if dirname == 'clusters1':\n","#         new_names= [\n","#             \"pmRApmDEcor\",\n","#             \"PlxpmRAcor\",\n","#             \"PlxpmDEcor\",\n","#             \"RFG\",\n","#             \"RFBP\",\n","#             \"RFRP\",\n","#             \"E(BR/RP)\",\n","#             \"Nper\",\n","#             \"[Fe/H]temp\",\n","#             \"RAdeg\",\n","#             \"e_RAdeg\",\n","#             \"DEdeg\",\n","#             \"e_DEdeg\",\n","#             \"Source\",\n","#             \"Plx\",\n","#             \"e_Plx\",\n","#             \"pmRA\",\n","#             \"e_pmRA\",\n","#             \"pmDE\",\n","#             \"e_pmDE\",\n","#             \"Dup\",\n","#             \"FG\",\n","#             \"e_FG\",\n","#             \"Gmag\",\n","#             \"e_Gmag\",\n","#             \"FBP\",\n","#             \"e_FBP\",\n","#             \"BPmag\",\n","#             \"e_BPmag\",\n","#             \"FRP\",\n","#             \"e_FRP\",\n","#             \"RPmag\",\n","#             \"e_RPmag\",\n","#             \"BP-RP\",\n","#             \"RV\",\n","#             \"e_RV\",\n","#             \"Teff\",\n","#             \"AG\",\n","#             \"E(BR-RP)\",\n","#             \"Rad\",\n","#             \"Lum\",\n","#             \"Pmemb\",\n","#             \"Cluster\"\n","#         ]\n","#     elif dirname == 'clusters2':\n","#         new_names = [\n","#             \"pmRApmDEcor\",\n","#             \"PlxpmRAcor\",\n","#             \"PlxpmDEcor\",\n","#             \"RFG\",\n","#             \"RFBP\",\n","#             \"RFRP\",\n","#             \"E(BR/RP)\",\n","#             \"Nper\",\n","#             \"RAdeg\",\n","#             \"e_RAdeg\",\n","#             \"DEdeg\",\n","#             \"e_DEdeg\",\n","#             \"Source\",\n","#             \"Plx\",\n","#             \"e_Plx\",\n","#             \"pmRA\",\n","#             \"e_pmRA\",\n","#             \"pmDE\",\n","#             \"e_pmDE\",\n","#             \"Dup\",\n","#             \"FG\",\n","#             \"e_FG\",\n","#             \"Gmag\",\n","#             \"e_Gmag\",\n","#             \"FBP\",\n","#             \"e_FBP\",\n","#             \"BPmag\",\n","#             \"e_BPmag\",\n","#             \"FRP\",\n","#             \"e_FRP\",\n","#             \"RPmag\",\n","#             \"e_RPmag\",\n","#             \"BP-RP\",\n","#             \"RV\",\n","#             \"e_RV\",\n","#             \"Teff\",\n","#             \"AG\",\n","#             \"E(BR-RP)\",\n","#             \"Rad\",\n","#             \"Lum\",\n","#             \"Pmemb\"\n","#         ]\n","#     memb = pd.read_fwf(os.path.join('data','clusters2',fname),header=None)\n","#     if memb.shape[1] != len(new_names):\n","#         continue\n","#     memb.columns = new_names\n","#     memb = Table.from_pandas(memb)\n","#     memb.keep_columns(['Source','Pmemb'])\n","#     cname = fname.split('.')[0]\n","#     os.remove(os.path.join('data','clusters2',fname))\n","\n","#     memb = memb[memb['Pmemb'] >= 0.9]\n","#     if len(memb) > 1:\n","#         query = '''SELECT source_id, ra , dec, ra_error ,dec_error,parallax,parallax_error, ruwe, phot_g_mean_flux, phot_g_mean_flux_error, phot_g_mean_mag,\n","#         phot_g_mean_flux_over_error, phot_bp_mean_flux, phot_bp_mean_flux_error, phot_bp_mean_flux_over_error, phot_bp_mean_mag, phot_rp_mean_flux,\n","#             phot_rp_mean_flux_error, phot_rp_mean_flux_over_error, phot_rp_mean_mag, bp_rp, bp_g, g_rp, radial_velocity, radial_velocity_error, l, b,\n","#             has_xp_sampled, has_rvs, has_epoch_photometry, has_epoch_rv, non_single_star, pmra, pmra_error, pmdec, pmdec_error\n","#             FROM gaiadr3.gaia_source\n","#             WHERE source_id IN {id_lst}\n","#             '''.format(id_lst = tuple(memb['Source'].data))\n","#         job = Gaia.launch_job(query= query)\n","#         memb1 = job.get_results()\n","#         if 'SOURCE_ID' in memb1.colnames:\n","#             memb1.rename_column('SOURCE_ID','source_id')\n","#         memb.rename_column('Source','source_id')\n","#         memb = table.join(memb,memb1,keys='source_id',join_type='inner')\n","#         cut = memb['parallax']/memb['parallax_error'] > 10\n","#         memb = memb[cut]\n","#         memb.write(os.path.join('data','clusters2',cname + '.fits'),format='fits',overwrite=True)\n","# ftp.quit()\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1550/1550 [00:37<00:00, 41.48it/s]\n"]}],"source":["## Creating a NSS table from Dias cluster members\n","\n","\n","\n","basedir = './data/clusters2/'\n","filenames = next(walk(basedir), (None, None, []))[2]\n","# filenames.remove('cluster_ages.fits')\n","# filenames.remove('cluster_ages.dat')\n","\n","clstr_lst = []\n","id_lst = []\n","pmemb_lst = []\n","for f in tqdm(filenames):\n","    if f.endswith('.dat'):\n","        continue\n","    clstrname = f.split('.')[0]\n","    tbl = Table.read(os.path.join(basedir,f), format='fits')\n","    tbl = tbl[tbl['non_single_star'] > 0]\n","    clstr_lst.extend(np.full(len(tbl), clstrname))\n","    id_lst.extend(tbl['source_id'].data)\n","    pmemb_lst.extend(tbl['Pmemb'].data)\n","table_0 = Table({'source_id': id_lst, 'cluster': clstr_lst, 'Pmemb': pmemb_lst})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Adding cluster ages, metallicities and extinctions to the NSS table\n"," \n","# clusters = Vizier(catalog='J/MNRAS/504/356',columns=['Cluster','N','logage','e_logage','[Fe/H]','e_[Fe/H]','Av','e_Av','FileName'],row_limit=-1).query_constraints()[0]\n","\n","# clusters.rename_columns(clusters.colnames,['Cluster','N','logage','e_logage','Fe/H','e_Fe/H','Av','e_Av','FileName'])\n","\n","# table_0['age'] = np.full(len(table_0),np.nan)\n","# table_0['age_err'] = np.full(len(table_0),np.nan)\n","# table_0['mh_for_mass_interp'] = np.full(len(table_0),np.nan)\n","# table_0['mh_err'] = np.full(len(table_0),np.nan)\n","# table_0['av_for_mass_interp'] = np.full(len(table_0),np.nan)\n","# table_0['av_err'] = np.full(len(table_0),np.nan)\n","\n","# for i in range(len(table_0)):\n","#     cname = table_0[i]['cluster']\n","#     if cname not in clusters['Cluster']:\n","#         continue\n","#     age = 10**clusters[clusters['Cluster'] == cname]['logage']*1e-6\n","#     age_err = clusters[clusters['Cluster'] == cname]['e_logage'][0] * age / np.log(10)\n","#     feh = clusters[clusters['Cluster'] == cname]['Fe/H'][0]\n","#     feh_err = clusters[clusters['Cluster'] == cname]['e_Fe/H'][0]\n","#     av = clusters[clusters['Cluster'] == cname]['Av'][0]\n","#     av_err = clusters[clusters['Cluster'] == cname]['e_Av'][0]\n","\n","#     table_0[i]['age'] = age\n","#     table_0[i]['age_err'] = age_err\n","#     table_0[i]['mh_for_mass_interp'] = feh\n","#     table_0[i]['mh_err'] = feh_err\n","#     table_0[i]['av_for_mass_interp'] = av\n","#     table_0[i]['av_err'] = av_err\n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Hunt cluster table\n","* Cross match Hunt and NSS\n","* Apply cuts to the tables (membership prob,parallax over error, cluster reliability)\n","* Rename columns for compatibility with Dias"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Load hunt tables, apply cuts, \n","\n","members = Table.from_pandas(pd.read_csv('./data/hunt_clusters/members.csv',usecols=['source_id','name','probability','non_single_star','parallax','parallax_error']))\n","clusters = Table.from_pandas(pd.read_csv('./data/hunt_clusters/clusters.csv',usecols=['name','cst','class_50']))\n","\n","cut = (clusters['cst'] > 5) & (clusters['class_50'] > 0.5)\n","clusters = clusters[cut]\n","members = members[np.isin(members['name'],clusters['name'])]\n","cut1 = members['non_single_star'] > 0\n","cut2 = members['probability'] >= 0.9\n","cut3 = members['parallax']/members['parallax_error'] > 10\n","cut = cut1 & cut2 & cut3\n","members = members[cut]\n","members.keep_columns(['source_id','name','probability'])\n","members.rename_columns(['name','probability'],['cluster','Pmemb'])\n","table_0 = members.copy()\n","# table_0 = table.join(table_0, members, keys='source_id', join_type='left')\n","# table_0 = table.join(table_0, clusters, keys='id', join_type='left')"]},{"cell_type":"markdown","metadata":{},"source":["# Gaia and NSS parameters\n","* Add Gaia/NSS parameters to the candidate table\n","* table_A cuts:\n","    - parallax/error > 10\n","    - astrometric fidelity > 0.5\n","    - Pmemb >=0.9\n","    - nss_solution_type: 'orbital'/'astrospectroSB1'\n","    - nss cuts on eccentricity error, significance, parallax over error"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: MergeConflictWarning: Cannot merge meta key 'ucd' types <class 'str'> and <class 'str'>, choosing ucd='meta.id' [astropy.utils.metadata]\n","WARNING: MergeConflictWarning: In merged column 'source_id' the 'description' attribute does not match (Source Identifier != Unique source identifier (unique within a particular Data Release)).  Using Unique source identifier (unique within a particular Data Release) for merged output [astropy.utils.metadata]\n","WARNING: MergeConflictWarning: Cannot merge meta key 'ucd' types <class 'str'> and <class 'str'>, choosing ucd='meta.id;meta.main' [astropy.utils.metadata]\n","WARNING: MergeConflictWarning: In merged column 'source_id' the 'description' attribute does not match (Unique source identifier (unique within a particular Data Release) != Gaia DR3 unique source identifier. Note that this *cannot* be matched against the DR1 or DR2 source_ids.).  Using Gaia DR3 unique source identifier. Note that this *cannot* be matched against the DR1 or DR2 source_ids. for merged output [astropy.utils.metadata]\n"]}],"source":["## query gaia for all sources in table_0- get relevant columns\n","\n","query1 = '''SELECT source_id, ra , dec, ra_error ,dec_error,parallax,parallax_error, astrometric_excess_noise, astrometric_excess_noise_sig,\n"," astrometric_params_solved, pseudocolour, visibility_periods_used, astrometric_sigma5d_max, ruwe, phot_g_mean_flux, phot_g_mean_flux_error, phot_g_mean_mag,\n","   phot_g_mean_flux_over_error, phot_bp_mean_flux, phot_bp_mean_flux_error, phot_bp_mean_flux_over_error, phot_bp_mean_mag, phot_rp_mean_flux,\n","     phot_rp_mean_flux_error, phot_rp_mean_flux_over_error, phot_rp_mean_mag, bp_rp, bp_g, g_rp, radial_velocity, radial_velocity_error, l, b,\n","       ecl_lon, ecl_lat, has_xp_continuous, has_xp_sampled, has_rvs, has_epoch_photometry, has_epoch_rv, non_single_star, pmra, pmra_error, pmdec, pmdec_error\n","    FROM gaiadr3.gaia_source\n","    WHERE source_id IN {id_lst}\n","    '''.format(id_lst = tuple(table_0['source_id'].data))\n","job1 = Gaia.launch_job(query= query1)\n","table_1 = job1.get_results()\n","if 'SOURCE_ID' in table_1.colnames:\n","    table_1.rename_column('SOURCE_ID','source_id')\n","\n","table_1 = table.join(table_0,table_1,keys=['source_id'],join_type='left')\n","\n","## query nss for all soruces in table_0 - get relevant columns\n","\n","query2 = '''SELECT source_id, parallax, parallax_error , pmra, pmra_error,\n"," pmdec, pmdec_error, a_thiele_innes, a_thiele_innes_error, b_thiele_innes, b_thiele_innes_error, f_thiele_innes, f_thiele_innes_error,\n","  g_thiele_innes, g_thiele_innes_error, c_thiele_innes, c_thiele_innes_error, h_thiele_innes, h_thiele_innes_error, period, period_error,\n","   t_periastron, t_periastron_error, eccentricity, eccentricity_error, center_of_mass_velocity, center_of_mass_velocity_error,\n","    semi_amplitude_primary, semi_amplitude_primary_error, semi_amplitude_secondary, semi_amplitude_secondary_error, mass_ratio,\n","     mass_ratio_error, fill_factor_primary, fill_factor_primary_error, fill_factor_secondary, fill_factor_secondary_error, inclination,\n","      inclination_error, arg_periastron, arg_periastron_error, temperature_ratio, temperature_ratio_error, temperature_ratio_definition, \n","      bit_index, corr_vec, goodness_of_fit, efficiency, significance, flags, g_luminosity_ratio, astrometric_jitter, nss_solution_type\n","    FROM gaiadr3.nss_two_body_orbit\n","    WHERE source_id IN {id_lst}\n","    '''.format(id_lst = tuple(table_0['source_id'].data))\n","job2 = Gaia.launch_job(query= query2)\n","table_2 = job2.get_results()\n","if 'SOURCE_ID' in table_2.colnames:\n","    table_2.rename_column('SOURCE_ID','source_id')\n","\n","## join tables, reorder columns by importance\n","\n","table_0 = table.join(table_2,table_1,keys=['source_id'],join_type='left')\n","\n","# ## take parallax from NSS if available, otherwise take from Gaia source\n","par_col = [pgaia if np.ma.is_masked(pnss) else pnss for pnss,pgaia in zip(table_0['parallax_1'],table_0['parallax_2'])]\n","par_err = [egaia if np.ma.is_masked(enss) else enss for enss,egaia in zip(table_0['parallax_error_1'],table_0['parallax_error_2'])]\n","pmra_col = [pgaia if np.ma.is_masked(pnss) else pnss for pnss,pgaia in zip(table_0['pmra_1'],table_0['pmra_2'])]\n","pmra_err = [egaia if np.ma.is_masked(enss) else enss for enss,egaia in zip(table_0['pmra_error_1'],table_0['pmra_error_2'])]\n","pmdec_col = [pgaia if np.ma.is_masked(pnss) else pnss for pnss,pgaia in zip(table_0['pmdec_1'],table_0['pmdec_2'])]\n","pmdec_err = [egaia if np.ma.is_masked(enss) else enss for enss,egaia in zip(table_0['pmdec_error_1'],table_0['pmdec_error_2'])]\n","par_col = Table.Column(par_col, name='parallax',unit='mas')\n","par_err = Table.Column(par_err, name='parallax_error',unit='mas')\n","pmra_col = Table.Column(pmra_col, name='pmra',unit='mas/yr')\n","pmra_err = Table.Column(pmra_err, name='pmra_error',unit='mas/yr')\n","pmdec_col = Table.Column(pmdec_col, name='pmdec',unit='mas/yr')\n","pmdec_err = Table.Column(pmdec_err, name='pmdec_error',unit='mas/yr')\n","table_0.add_columns([par_col,par_err,pmra_col,pmra_err,pmdec_col,pmdec_err])\n","table_0.remove_columns(['parallax_1','parallax_2','parallax_error_1','parallax_error_2','pmra_1','pmra_2','pmra_error_1','pmra_error_2','pmdec_1','pmdec_2','pmdec_error_1','pmdec_error_2'])\n","\n","table_0['parallax_over_error'] = table_0['parallax']/table_0['parallax_error']\n","table_0['mg'] = table_0[\"phot_g_mean_mag\"] + 5 * np.log10(table_0[\"parallax\"]) - 10\n","cols = table_0.colnames\n","first_cols = ['source_id','cluster','ra','dec','parallax','phot_g_mean_mag','bp_rp']\n","for c in first_cols:\n","    cols.remove(c)\n","cols = first_cols + cols\n","table_0 = table_0[cols]\n","\n","## astrometric fidelity\n","\n","tap_service = pyvo.dal.TAPService(\"http://dc.g-vo.org/tap\")\n","ex_query = f\"\"\"SELECT source_id, fidelity_v2 FROM gedr3spur.main WHERE source_id IN {tuple(table_0['source_id'].data)}\"\"\"\n","result = tap_service.search(ex_query).to_table()\n","table_0 = table.join(table_0,result,keys='source_id',join_type='left')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["## apply cuts for table_A stage\n","cut1 = table_0['parallax_over_error'] > 10\n","cut2 = table_0['fidelity_v2'] > 0.5\n","cut3 = table_0['Pmemb'] >= 0.9\n","cut4 = np.isin(table_0['nss_solution_type'],['Orbital','AstroSpectroSB1'])\n","cut5 = table_0['significance'] > 158 * table_0['period'].data**(-0.5)\n","cut6 = (table_0['parallax_over_error'] > 20,000 *table_0['period']**(-1))[0]\n","cut7 = table_0['eccentricity_error'] < 0.079 * np.log(table_0['period'].data) - 0.244\n","\n","cut = cut1 & cut2 & cut3 & cut4 & cut5 & cut6 & cut7\n","table_0 = table_0[cut]"]},{"cell_type":"markdown","metadata":{},"source":["# Metallicity\n","* Convert Zhang metallicity catalog h5 files to fits\n","* Look for our candidates in the metallicity catalog\n","* Also calculate the cluster metallicity from the catalog"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["## convert metallicity catalog h5 files to fits\n","\n","# import h5py \n","# from astropy.table import Table\n","# import os\n","# from glob import glob\n","\n","# # Input location\n","# # catalog_h5_list = glob('c:/Users/ASUS/Dropbox (Weizmann Institute)/AMRF IFMR/data/metallicity/stellar_params_catalog_*.h5')\n","# catalog_h5_list = glob('/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/metallicity/stellar_params_catalog_*.h5')\n","# catalog_h5_list.sort()\n","\n","# for catalog_h5_loc in catalog_h5_list:\n","#     print(f\"Loading {catalog_h5_loc}\")\n","#     output_fits = Table()\n","#     with h5py.File(catalog_h5_loc, 'r') as f:\n","#         for i, key in enumerate(f.keys()):\n","#             print(f\"Loading {i+1}/{len(f.keys())}: {key}\")\n","#             output_fits[key] = f[key][:]\n","#     base_fn,_ = os.path.splitext(catalog_h5_loc)\n","#     catalog_fits_loc = base_fn + '.fits'\n","#     print(f\"Saving to {catalog_fits_loc}\")\n","#     output_fits.write(catalog_fits_loc)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity/stellar_params_catalog_01.fits\n","/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity/stellar_params_catalog_02.fits\n","/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity/stellar_params_catalog_03.fits\n","/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity/stellar_params_catalog_04.fits\n","/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity/stellar_params_catalog_05.fits\n","/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity/stellar_params_catalog_06.fits\n","/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity/stellar_params_catalog_07.fits\n","/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity/stellar_params_catalog_08.fits\n","/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity/stellar_params_catalog_09.fits\n"]}],"source":["## read first metallicity catalog file, create metallicity column, remove other columns\n","\n","# ColDefs(name = 'chi2_opt'; format = 'E'\n","#     name = 'dec'; format = 'E'\n","#     name = 'feh_confidence'; format = 'E'\n","#     name = 'gdr3_source_id'; format = 'K'\n","#     name = 'ln_prior'; format = 'E'\n","#     name = 'logg_confidence'; format = 'E'\n","#     name = 'quality_flags'; format = 'B'\n","#     name = 'ra'; format = 'E'\n","#     name = 'stellar_params_err'; format = '5E'; dim = '(5)'\n","#     name = 'stellar_params_est'; format = '5E'; dim = '(5)'\n","#     name = 'teff_confidence'; format = 'E') \n","\n","# linux_path = '/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity'\n","# win_path = 'c:/Users/ASUS/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity'\n","\n","# filepath = os.path.join(linux_path,'stellar_params_catalog_00.fits')\n","# # filepath = os.path.join(win_path,'stellar_params_catalog_00.fits')\n","\n","# hdul_7 = fits.open(filepath)\n","# coldef = fits.ColDefs([hdul_7[1].columns[3],hdul_7[1].columns[8],hdul_7[1].columns[9],hdul_7[1].columns[6]])\n","# table_7 = Table(hdul_7[1].from_columns(coldef).data)\n","# table_7.add_column(table_7['stellar_params_est'][:,1]*u.dex,name='Fe_H_est')\n","# table_7.add_column(table_7['stellar_params_err'][:,1]*u.dex,name='Fe_H_error')\n","# table_7.remove_columns(['stellar_params_err','stellar_params_est'])\n","# table_7.rename_column('gdr3_source_id','source_id')\n","# hdul_7.close()\n","\n","# ## read all metallicity catalog files, create metallicity column, remove other columns, append to table_7\n","# for i in range(1,10):\n","#     filename = os.path.join(linux_path,f'stellar_params_catalog_0{i}.fits')\n","#     # filename = os.path.join(win_path,f'stellar_params_catalog_0{i}.fits')\n","#     print(filename)\n","#     hdul_temp = fits.open(filename)\n","#     coldef = fits.ColDefs([hdul_temp[1].columns[3],hdul_temp[1].columns[8],hdul_temp[1].columns[9],hdul_temp[1].columns[6]])\n","#     table_temp = Table(hdul_temp[1].from_columns(coldef).data)\n","#     hdul_temp.close()\n","#     table_temp.add_column(table_temp['stellar_params_est'][:,1]*u.dex,name='Fe_H_est')\n","#     table_temp.add_column(table_temp['stellar_params_err'][:,1]*u.dex,name='Fe_H_error')\n","#     table_temp.remove_columns(['stellar_params_err','stellar_params_est'])\n","#     table_temp.rename_column('gdr3_source_id','source_id')\n","#     table_7 = table.vstack([table_7,table_temp])\n","\n","# table_0 = table.join(table_0,table_7,keys=['source_id'],join_type='left')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ## get metallicity for all cluster members, take median\n","\n","# linux_path = '/home/oreni/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity'\n","# win_path = 'c:/Users/ASUS/Dropbox (Weizmann Institute)/AMRF IFMR/data/catalogs/metallicity'\n","\n","# filepath = os.path.join(linux_path,'stellar_params_catalog_00.fits')\n","# # filepath = os.path.join(win_path,'stellar_params_catalog_00.fits')\n","\n","# hdul_7 = fits.open(filepath)\n","# coldef = fits.ColDefs([hdul_7[1].columns[3],hdul_7[1].columns[8],hdul_7[1].columns[9],hdul_7[1].columns[6]])\n","# table_7 = Table(hdul_7[1].from_columns(coldef).data)\n","# table_7.add_column(table_7['stellar_params_est'][:,1]*u.dex,name='Fe_H_est')\n","# table_7.add_column(table_7['stellar_params_err'][:,1]*u.dex,name='Fe_H_error')\n","# table_7.remove_columns(['stellar_params_err','stellar_params_est'])\n","# table_7.rename_column('gdr3_source_id','source_id')\n","# hdul_7.close()\n","\n","# ## read all metallicity catalog files, create metallicity column, remove other columns, append to table_7\n","# for i in range(1,10):\n","#     filename = os.path.join(linux_path,f'stellar_params_catalog_0{i}.fits')\n","#     # filename = os.path.join(win_path,f'stellar_params_catalog_0{i}.fits')\n","#     print(filename)\n","#     hdul_temp = fits.open(filename)\n","#     coldef = fits.ColDefs([hdul_temp[1].columns[3],hdul_temp[1].columns[8],hdul_temp[1].columns[9],hdul_temp[1].columns[6]])\n","#     table_temp = Table(hdul_temp[1].from_columns(coldef).data)\n","#     hdul_temp.close()\n","#     table_temp.add_column(table_temp['stellar_params_est'][:,1]*u.dex,name='Fe_H_est')\n","#     table_temp.add_column(table_temp['stellar_params_err'][:,1]*u.dex,name='Fe_H_error')\n","#     table_temp.remove_columns(['stellar_params_err','stellar_params_est'])\n","#     table_temp.rename_column('gdr3_source_id','source_id')\n","#     table_7 = table.vstack([table_7,table_temp])\n","\n","# table_7 = table_7[table_7['quality_flags'] < 8]\n","# table_0['Fe_H_cluster'] = np.full(len(table_0),np.nan)\n","# table_0['Fe_H_cluster_std'] = np.full(len(table_0),np.nan)\n","\n","# for i,id in tqdm(enumerate(table_0['id']),total=len(table_0['id'])):\n","#     nbr = members[members['id']==id]\n","#     nbr = nbr[nbr['probability'] > 0.99]\n","#     fh_arr = table_7[np.isin(table_7['source_id'],nbr['source_id'])]['Fe_H_est']\n","#     table_0[i]['Fe_H_cluster'] = np.median(fh_arr)\n","#     table_0[i]['Fe_H_cluster_std'] = np.std(fh_arr)"]},{"cell_type":"markdown","metadata":{},"source":["# Extinction\n","* Query dust maps for reddening estimates\n","* Northern targets- Bayestar 3D map\n","* Southern targets- Stilism 3D map"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## query extinction (northern)\n","\n","# from dustmaps.config import config\n","# config['data_dir'] = '/path/to/store/maps/in'\n","\n","# import dustmaps.bayestar\n","# dustmaps.bayestar.fetch()\n","\n","# from dustmaps.bayestar import BayestarQuery\n","\n","# bayestar = BayestarQuery(max_samples=2, version='bayestar2019')\n","# l = table_0['l']\n","# b = table_0['b']\n","# d = np.abs(1000/table_0['parallax'])\n","# coord = SkyCoord(l=l*u.deg, b=b*u.deg, distance=d*u.pc, frame='galactic')\n","# ebv = 0.884 * bayestar(coord, mode='median')"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1743/1743 [09:38<00:00,  3.01it/s]\n"]}],"source":["## query extinction (southern)\n","# from urllib import request\n","# import ssl \n","\n","# context = ssl._create_unverified_context()\n","# av = []\n","\n","# ra = table_0['ra']\n","# dec = table_0['dec']\n","# par = table_0['parallax']\n","# tot = len(table_0)\n","\n","# with tqdm(total=tot) as pbar:\n","#     for ra,dec,par in zip(ra,dec,par):\n","#         d = np.abs(1000/par)\n","#         with  request.urlopen(f'https://astro.acri-st.fr/gaia_dev/extinction?frame=icrs&vlong={ra}&ulong=deg&vlat={dec}&ulat=deg&distance={d}',context=context) as response:\n","#             html = response.read()\n","#             av.append(float(html.split(b'\\n')[1].split(b',')[1]))\n","        # pbar.update(1)"]},{"cell_type":"markdown","metadata":{},"source":["# Galex\n","* Cross match with galex to get NUV,FUV mag where available"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/212 [00:00<?, ?it/s]/home/oreni/Documents/WD_project/.venv/lib/python3.10/site-packages/astropy/table/column.py:1362: UserWarning: Warning: converting a masked element to nan.\n","  self.data[index] = value\n","  0%|          | 1/212 [00:01<05:32,  1.58s/it]WARNING: NoResultsWarning: Query returned no results. [astroquery.mast.discovery_portal]\n","100%|██████████| 212/212 [03:20<00:00,  1.06it/s]\n"]}],"source":["## Astroquery GALEX data\n","# i = 40\n","# ra = table_0[i]['ra']\n","# dec = table_0[i]['dec']\n","# r_arcsec = 10\n","# r_deg = r_arcsec/3600\n","# catalog_data = Catalogs.query_object(f'{ra} {dec}',catalog='Galex',radius = r_deg)\n","\n","# print(np.min(catalog_data['distance_arcmin'].data)*60)\n","\n","for c in ['distance_arcmin','nuv_mag','nuv_magerr','fuv_mag','fuv_magerr']:\n","    table_0[c] = np.full(len(table_0),np.nan)\n","\n","\n","for i in tqdm(range(len(table_0))):\n","    ra = table_0[i]['ra']\n","    dec = table_0[i]['dec']\n","    r_arcsec = 2\n","    r_deg = r_arcsec/3600\n","    catalog_data = Catalogs.query_object(f'{ra} {dec}',catalog='Galex',radius = r_deg)\n","\n","    if len(catalog_data)>0:\n","        for c in ['distance_arcmin','nuv_mag','nuv_magerr','fuv_mag','fuv_magerr']:\n","            table_0[c][i] = catalog_data[c][0]"]},{"cell_type":"markdown","metadata":{},"source":["# Aesthetics\n","* Deal with problematic data types in the table (so we can save it as .fits file)\n","* Rearrange columns\n","* Write to .fits"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["## deal with problematic data types\n","\n","col = table.Column([str(cvec) for cvec in table_0['corr_vec']],name = 'corr_vec',dtype = str)\n","table_0['nss_solution_type'] = table_0['nss_solution_type'].astype(str)\n","table_0['corr_vec'] = col"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["## sort columns by importance\n","\n","cols = table_0.colnames\n","first_cols = ['source_id','ra','dec','parallax','mg','phot_g_mean_mag','bp_rp','nuv_mag']\n","for c in first_cols:\n","    cols.remove(c)\n","cols = first_cols + cols\n","table_0 = table_0[cols]"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: The unit 'electron / s' could not be saved in native FITS format and cannot be recovered in reading. It can roundtrip within astropy by using QTable both to write and read back, though one has to enable the unit before reading. [astropy.io.fits.convenience]\n"]}],"source":["## save table\n","table_0.write('table_A_Hunt.fits', format='fits',overwrite=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Dias membership tables for OCFit\n","* save membership tables as .dat, ready for isochrone fitting\n","* merge table_A_hunt and table_A_dias to make table_B (which will include all AMRF results regardless of class prob)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["## create table with all Hunt cluster members, for same clusters as in table_A (excluding already fitted)\n","\n","members = Table.from_pandas(pd.read_csv('./data/hunt_clusters/members.csv',usecols=['source_id','name','probability','non_single_star','parallax','parallax_error']))\n","members.rename_columns(['name','probability'],['cluster','Pmemb'])\n","\n","table_A_hunt = Table.read('table_A_Hunt.fits')\n","fitted_clusters = next(walk('./OCFit/gaiaDR2/results/'), (None, None, []))[1]\n","\n","cut = np.isin(members['cluster'],table_A_hunt['cluster'])\n","members = members[cut]\n","cut1 = members['parallax']/members['parallax_error'] > 10\n","cut2 = ~np.isin(members['cluster'],fitted_clusters) ## exclude clusters already fitted\n","cut = cut1 & cut2\n","members = members[cut]\n","\n","hunt = members.copy()\n","hunt.keep_columns(['source_id','cluster','Pmemb'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## create .dat files for each Hunt cluster\n","\n","from scipy.stats import scoreatpercentile\n","from urllib import request\n","import ssl \n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# hunt = Table.read('hunt_members.fits', format='fits')\n","# hunt.rename_columns(['probability'],['Pmemb'])\n","# clusternames = hunt['name']\n","clusternames = np.unique(hunt['cluster'])\n","\n","ebv_tbl = Table({'source_id':[],'ebv':[],'e_ebv_min':[],'e_ebv_max':[],'distance':[],'dist':[]},dtype=[str,float,float,float,float,float])\n","\n","for cluster in tqdm(np.unique(clusternames),total=len(np.unique(clusternames))):\n","    memb = hunt[hunt['cluster'] == cluster]\n","    memb = memb[memb['Pmemb'] >= 0.5]\n","    memb.remove_columns(['cluster'])\n","\n","    idlst = memb['source_id'].data\n","    query = f'''SELECT source_id, ra as RA_ICRS, dec as DE_ICRS, parallax as Plx, parallax_error as e_Plx, \n","            phot_g_mean_mag as Gmag, phot_bp_mean_mag as BPmag, phot_rp_mean_mag as RPmag, bp_rp as BPRP,\n","            phot_g_mean_flux ,phot_g_mean_flux_error, phot_bp_mean_flux, phot_bp_mean_flux_error, phot_rp_mean_flux, phot_rp_mean_flux_error,\n","                phot_bp_rp_excess_factor as E_BR_RP_, visibility_periods_used as Nper, radial_velocity as RV, radial_velocity_error as e_RV\n","            FROM gaiadr3.gaia_source WHERE SOURCE_ID IN {tuple(idlst)}'''\n","    job = Gaia.launch_job(query)\n","    result = job.get_results()\n","    result['RFG'] = result['phot_g_mean_flux'] / result['phot_g_mean_flux_error']\n","    result['RFBP'] = result['phot_bp_mean_flux'] / result['phot_bp_mean_flux_error']\n","    result['RFRP'] = result['phot_rp_mean_flux'] / result['phot_rp_mean_flux_error']\n","    result['e_Gmag'] = 2.5*np.log(10)/result['RFG']\n","    result['e_BPmag'] = 2.5*np.log(10)/result['RFBP']\n","    result['e_RPmag'] = 2.5*np.log(10)/result['RFRP']    \n","    result.rename_column('SOURCE_ID','source_id')\n","    result.remove_columns(['phot_g_mean_flux','phot_g_mean_flux_error','phot_bp_mean_flux','phot_bp_mean_flux_error','phot_rp_mean_flux','phot_rp_mean_flux_error'])\n","    memb = table.join(memb,result,keys='source_id')\n","\n","\n","    tap_service = pyvo.dal.TAPService(\"http://dc.g-vo.org/tap\")\n","    query = f'''SELECT source_id, fidelity_v2 FROM gedr3spur.main WHERE source_id IN {tuple(idlst)}'''\n","    result = tap_service.search(query).to_table()\n","    memb = table.join(memb,result,keys='source_id')\n","\n","    memb['distance'] = np.abs(1000/memb['Plx'])\n","    memb['dist'] = np.full_like(memb['distance'],np.nan)\n","    memb['ebv'] = np.full_like(memb['distance'],np.nan)\n","    context = ssl._create_unverified_context()\n","\n","    dist_col = []\n","    ebv_col = []\n","\n","    ra = memb['RA_ICRS']\n","    dec = memb['DE_ICRS']\n","    par = memb['Plx']\n","\n","    for ra,dec,par in zip(ra,dec,par):\n","        d = np.abs(1000/par)\n","        if np.ma.is_masked(d):\n","            dist_col.append(np.nan)\n","            ebv_col.append(np.nan)\n","            continue\n","        with  request.urlopen(f'https://astro.acri-st.fr/gaia_dev/extinction?frame=icrs&vlong={ra}&ulong=deg&vlat={dec}&ulat=deg&distance={d}',context=context) as response:\n","            html = response.read()\n","            dist_col.append(float(html.split(b'\\n')[1].split(b',')[0]))\n","            ebv_col.append(float(html.split(b'\\n')[1].split(b',')[1])/3.1)\n","    memb['dist'] = dist_col\n","    memb['ebv'] = ebv_col\n","    memb['dist'] = dist_col\n","    memb['ebv'] = ebv_col\n","    memb.write(os.path.join('.','OCFit','gaiaDR2','data',cluster +'.dat'),format='csv',overwrite=True)\n","    ebv = np.mean(memb['ebv'])\n","    distance = np.median(memb[memb['distance'] > 0]['distance'])\n","    dist = np.median(memb[memb['distance'] > 0]['dist'])\n","    e_ebv_max = scoreatpercentile(memb['ebv'],84) - ebv\n","    e_ebv_min = ebv - scoreatpercentile(memb['ebv'],16)\n","    ebv_tbl.add_row([cluster,ebv,e_ebv_min,e_ebv_max,distance,dist])\n","ebv_tbl.write('OCFit/gaiaDR2/extinction_hunt.dat',format='csv',overwrite=True)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1 [00:00<?, ?it/s]WARNING: MergeConflictWarning: Cannot merge meta key 'ucd' types <class 'str'> and <class 'str'>, choosing ucd='meta.id;meta.main' [astropy.utils.metadata]\n","WARNING: MergeConflictWarning: In merged column 'source_id' the 'description' attribute does not match (Unique source identifier (unique within a particular Data Release) != Gaia DR3 unique source identifier. Note that this *cannot* be matched against the DR1 or DR2 source_ids.).  Using Gaia DR3 unique source identifier. Note that this *cannot* be matched against the DR1 or DR2 source_ids. for merged output [astropy.utils.metadata]\n","/home/oreni/Documents/WD_project/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:771: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedColumn.\n","  a.partition(kth, axis=axis, kind=kind, order=order)\n","100%|██████████| 1/1 [00:24<00:00, 24.41s/it]\n"]}],"source":["## create .dat files for each Dias cluster\n","\n","from scipy.stats import scoreatpercentile\n","from ftplib import FTP\n","from urllib import request\n","import ssl \n","\n","dias = Table.read('table_A_Dias.fits', format='fits')\n","dias = dias[~np.isin(dias['cluster'],fitted_clusters)] ## remove already fitted clusters\n","clusters = Vizier(catalog='J/MNRAS/504/356',columns=['Cluster','FileName'],row_limit=-1).query_constraints()[0]\n","clusters = clusters[np.isin(clusters['Cluster'],dias['cluster'].astype(str))]\n","cut1 = [fname.startswith('clusters1') for fname in clusters['FileName']]\n","cut2 = [fname.startswith('clusters2') for fname in clusters['FileName']]\n","\n","ftp = FTP('cdsarc.u-strasbg.fr')\n","ftp.login()\n","ftp.cwd('pub/cats/J/MNRAS/504/356/clusters1')\n","\n","ebv_tbl = Table({'source_id':[],'ebv':[],'e_ebv_min':[],'e_ebv_max':[],'distance':[],'dist':[]},dtype=[str,float,float,float,float,float])\n","\n","for fname in tqdm(clusters[cut1]['FileName'],total=len(clusters[cut1])):\n","    dirname,fname = fname.split('/') \n","    \n","    if fname.split('.')[0] in hunt['cluster']: ## duplicate clusters between Dias and Hunt\n","        fname = fname.split('.')[0] + '_D.dat'\n","\n","    with open(os.path.join('OCFit','gaiaDR2','data',fname), 'wb') as f:\n","        if fname.endswith('_D.dat'): ## the ftp file doesn't have the _D suffix, so in duplicates we remove it\n","            ftp.retrbinary('RETR ' + fname.replace('_D',''), f.write)\n","        else:\n","            ftp.retrbinary('RETR ' + fname, f.write)\n","    if dirname == 'clusters1':\n","        new_names= [\n","            \"pmRApmDEcor\",\n","            \"PlxpmRAcor\",\n","            \"PlxpmDEcor\",\n","            \"RFG\",\n","            \"RFBP\",\n","            \"RFRP\",\n","            \"E(BR/RP)\",\n","            \"Nper\",\n","            \"[Fe/H]temp\",\n","            \"RAdeg\",\n","            \"e_RAdeg\",\n","            \"DEdeg\",\n","            \"e_DEdeg\",\n","            \"Source\",\n","            \"Plx\",\n","            \"e_Plx\",\n","            \"pmRA\",\n","            \"e_pmRA\",\n","            \"pmDE\",\n","            \"e_pmDE\",\n","            \"Dup\",\n","            \"FG\",\n","            \"e_FG\",\n","            \"Gmag\",\n","            \"e_Gmag\",\n","            \"FBP\",\n","            \"e_FBP\",\n","            \"BPmag\",\n","            \"e_BPmag\",\n","            \"FRP\",\n","            \"e_FRP\",\n","            \"RPmag\",\n","            \"e_RPmag\",\n","            \"BP-RP\",\n","            \"RV\",\n","            \"e_RV\",\n","            \"Teff\",\n","            \"AG\",\n","            \"E(BR-RP)\",\n","            \"Rad\",\n","            \"Lum\",\n","            \"Pmemb\",\n","            \"Cluster\"\n","        ]\n","    elif dirname == 'clusters2':\n","        new_names = [\n","            \"pmRApmDEcor\",\n","            \"PlxpmRAcor\",\n","            \"PlxpmDEcor\",\n","            \"RFG\",\n","            \"RFBP\",\n","            \"RFRP\",\n","            \"E(BR/RP)\",\n","            \"Nper\",\n","            \"RAdeg\",\n","            \"e_RAdeg\",\n","            \"DEdeg\",\n","            \"e_DEdeg\",\n","            \"Source\",\n","            \"Plx\",\n","            \"e_Plx\",\n","            \"pmRA\",\n","            \"e_pmRA\",\n","            \"pmDE\",\n","            \"e_pmDE\",\n","            \"Dup\",\n","            \"FG\",\n","            \"e_FG\",\n","            \"Gmag\",\n","            \"e_Gmag\",\n","            \"FBP\",\n","            \"e_FBP\",\n","            \"BPmag\",\n","            \"e_BPmag\",\n","            \"FRP\",\n","            \"e_FRP\",\n","            \"RPmag\",\n","            \"e_RPmag\",\n","            \"BP-RP\",\n","            \"RV\",\n","            \"e_RV\",\n","            \"Teff\",\n","            \"AG\",\n","            \"E(BR-RP)\",\n","            \"Rad\",\n","            \"Lum\",\n","            \"Pmemb\"\n","        ]\n","    memb = pd.read_fwf(os.path.join('OCFit','gaiaDR2','data',fname),header=None)\n","    memb.columns = new_names\n","    memb = memb[memb['Pmemb'] >=0.5]\n","    memb = Table.from_pandas(memb)\n","\n","    idlst = memb['Source'].data\n","    query = f'''SELECT source_id, ra as RA_ICRS, dec as DE_ICRS, parallax as Plx, parallax_error as e_Plx, \n","            phot_g_mean_mag as Gmag, phot_bp_mean_mag as BPmag, phot_rp_mean_mag as RPmag, bp_rp as BPRP,\n","            phot_g_mean_flux ,phot_g_mean_flux_error, phot_bp_mean_flux, phot_bp_mean_flux_error, phot_rp_mean_flux, phot_rp_mean_flux_error,\n","                phot_bp_rp_excess_factor as E_BR_RP_, visibility_periods_used as Nper, radial_velocity as RV, radial_velocity_error as e_RV\n","            FROM gaiadr3.gaia_source WHERE SOURCE_ID IN {tuple(idlst)}'''\n","    job = Gaia.launch_job(query)\n","    result = job.get_results()\n","    result['RFG'] = result['phot_g_mean_flux'] / result['phot_g_mean_flux_error']\n","    result['RFBP'] = result['phot_bp_mean_flux'] / result['phot_bp_mean_flux_error']\n","    result['RFRP'] = result['phot_rp_mean_flux'] / result['phot_rp_mean_flux_error']\n","    result['e_Gmag'] = 2.5*np.log(10)/result['RFG']\n","    result['e_BPmag'] = 2.5*np.log(10)/result['RFBP']\n","    result['e_RPmag'] = 2.5*np.log(10)/result['RFRP']\n","    memb.rename_column('Source','source_id')\n","    result.rename_column('SOURCE_ID','source_id')\n","    memb.keep_columns(['source_id','Pmemb'])\n","    result.remove_columns(['phot_g_mean_flux','phot_g_mean_flux_error','phot_bp_mean_flux','phot_bp_mean_flux_error','phot_rp_mean_flux','phot_rp_mean_flux_error'])\n","    memb = table.join(memb,result,keys='source_id')\n","\n","    tap_service = pyvo.dal.TAPService(\"http://dc.g-vo.org/tap\")\n","    query = f'''SELECT source_id, fidelity_v2 FROM gedr3spur.main WHERE source_id IN {tuple(idlst)}'''\n","    result = tap_service.search(query).to_table()\n","    memb = table.join(memb,result,keys='source_id')\n","\n","\n","    memb['distance'] = np.abs(1000/memb['Plx'])\n","    memb['dist'] = np.full_like(memb['distance'],np.nan)\n","    memb['ebv'] = np.full_like(memb['distance'],np.nan)\n","\n","    context = ssl._create_unverified_context()\n","\n","    dist_col = []\n","    ebv_col = []\n","\n","    ra = memb['RA_ICRS']\n","    dec = memb['DE_ICRS']\n","    par = memb['Plx']\n","\n","    for ra,dec,par in zip(ra,dec,par):\n","        d = np.abs(1000/par)\n","        if np.ma.is_masked(d):\n","            dist_col.append(np.nan)\n","            ebv_col.append(np.nan)\n","            continue\n","        with  request.urlopen(f'https://astro.acri-st.fr/gaia_dev/extinction?frame=icrs&vlong={ra}&ulong=deg&vlat={dec}&ulat=deg&distance={d}',context=context) as response:\n","            html = response.read()\n","            dist_col.append(float(html.split(b'\\n')[1].split(b',')[0]))\n","            ebv_col.append(float(html.split(b'\\n')[1].split(b',')[1])/3.1)\n","    memb['dist'] = dist_col\n","    memb['ebv'] = ebv_col\n","    \n","    memb.write(os.path.join('.','OCFit','gaiaDR2','data',fname),format='csv',overwrite=True)\n","    ebv = np.mean(memb['ebv'])\n","    distance = np.median(memb[memb['distance'] > 0]['distance'])\n","    dist = np.median(memb[memb['distance'] > 0]['dist'])\n","    e_ebv_max = scoreatpercentile(memb['ebv'],84) - ebv\n","    e_ebv_min = ebv - scoreatpercentile(memb['ebv'],16)\n","    ebv_tbl.add_row([fname.split('.')[0],ebv,e_ebv_min,e_ebv_max,distance,dist])\n","\n","ftp.quit()\n","ebv_tbl.write('OCFit/gaiaDR2/extinction_dias2.dat',format='csv',overwrite=True)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["## merge extinction tables\n","\n","# m = np.genfromtxt('./OCFit/gaiaDR2/data/FSR_0398.dat',delimiter=',',dtype=None,names=True)\n","e1 = np.genfromtxt('./OCFit/gaiaDR2/extinction_dias.dat',delimiter=',',dtype=None,names=True,encoding=None)\n","e2 = np.genfromtxt('./OCFit/gaiaDR2/extinction_hunt.dat',delimiter=',',dtype=None,names=True,encoding=None)\n","e3 = np.genfromtxt('./OCFit/gaiaDR2/extinction_dias2.dat',delimiter=',',dtype=None,names=True,encoding=None)\n","\n","e1 = Table(e1)\n","e2 = Table(e2)\n","# e3 = Table(e3)\n","e4 = table.vstack([e1,e2])\n","e4.add_row(e3.tolist())\n","\n","e4.write('OCFit/gaiaDR2/extinction_prior_tbl.dat',format='csv',overwrite=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["table_A_hunt = Table.read('table_A_Hunt.fits')\n","table_A_dias = Table.read('table_A_Dias.fits')\n","table_B = table.vstack([table_A_hunt,table_A_dias])\n","table_B = table.unique(table_B,keys=['source_id','cluster'])"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPAZMVrAy7ItB6tR38RT92q","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
